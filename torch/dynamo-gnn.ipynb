{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import _dynamo\n",
    "from torch._dynamo import config\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.log_level = logging.DEBUG\n",
    "config.output_code = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python constant in control-flow\n",
    "\n",
    "Some if-else conditions is **constant** in a JIT module, such control-flow will be removed during the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_kernel(x):\n",
    "    y = x\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        y = x + 1\n",
    "    return y * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = torch.compile(some_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:07:36,967] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /usr/lib/python3.8/contextlib.py\n",
      "[2023-03-16 17:07:36,968] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /usr/lib/python3.8/contextlib.py\n",
      "[2023-03-16 17:07:36,969] torch._dynamo.eval_frame: [DEBUG] skipping __init__ /usr/lib/python3.8/contextlib.py\n",
      "[2023-03-16 17:07:36,969] torch._dynamo.eval_frame: [DEBUG] skipping __enter__ /usr/lib/python3.8/contextlib.py\n",
      "[2023-03-16 17:07:36,969] torch._dynamo.eval_frame: [DEBUG] skipping enable_dynamic /home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-03-16 17:07:37,021] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing some_kernel\n",
      "[2023-03-16 17:07:37,023] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2329204500.py:2\n",
      "[2023-03-16 17:07:37,024] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:37,024] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-03-16 17:07:37,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2329204500.py:3\n",
      "[2023-03-16 17:07:37,025] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL isinstance []\n",
      "[2023-03-16 17:07:37,026] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [BuiltinVariable(isinstance)]\n",
      "[2023-03-16 17:07:37,026] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch [BuiltinVariable(isinstance), TensorVariable()]\n",
      "[2023-03-16 17:07:37,027] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR Tensor [BuiltinVariable(isinstance), TensorVariable(), TorchVariable(<module 'torch' from '/home/chunwei/trienv/lib/python3.8/site-packages/torch/__init__.py'>)]\n",
      "[2023-03-16 17:07:37,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [BuiltinVariable(isinstance), TensorVariable(), TorchVariable(<class 'torch.Tensor'>)]\n",
      "[2023-03-16 17:07:37,028] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 24 [ConstantVariable(bool)]\n",
      "[2023-03-16 17:07:37,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2329204500.py:4\n",
      "[2023-03-16 17:07:37,029] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:37,030] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "[2023-03-16 17:07:37,030] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:37,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST y [TensorVariable()]\n",
      "[2023-03-16 17:07:37,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2329204500.py:5\n",
      "[2023-03-16 17:07:37,034] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-03-16 17:07:37,035] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2023-03-16 17:07:37,035] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:37,037] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:37,037] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing some_kernel (RETURN_VALUE)\n",
      "[2023-03-16 17:07:37,037] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:37,038] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/2329204500.py, line 5 in some_kernel>])\n",
      "[2023-03-16 17:07:37,134] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:38,196] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0\n",
      "[2023-03-16 17:07:40,844] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/xx/cxxz6xiv4ig7n2pf7ui43xi6k6y6q4tyorre4rlji5cogcm73orl.py\n",
      "[2023-03-16 17:07:40,846] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0\n",
      "[2023-03-16 17:07:40,847] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:40,850] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_0 <eval_with_key>.5 opcode         name    target                   args       kwargs\n",
      "-------------  ------  -----------------------  ---------  --------\n",
      "placeholder    x       x                        ()         {}\n",
      "call_function  add     <built-in function add>  (x, 1)     {}\n",
      "call_function  mul     <built-in function mul>  (add, 2)   {}\n",
      "output         output  output                   ((mul,),)  {}\n",
      "\n",
      "[2023-03-16 17:07:40,851] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE some_kernel /tmp/ipykernel_171109/2329204500.py line 1 \n",
      "  2           0 LOAD_FAST                0 (x)\n",
      "              2 STORE_FAST               1 (y)\n",
      "\n",
      "  3           4 LOAD_GLOBAL              0 (isinstance)\n",
      "              6 LOAD_FAST                0 (x)\n",
      "              8 LOAD_GLOBAL              1 (torch)\n",
      "             10 LOAD_ATTR                2 (Tensor)\n",
      "             12 CALL_FUNCTION            2\n",
      "             14 POP_JUMP_IF_FALSE       24\n",
      "\n",
      "  4          16 LOAD_FAST                0 (x)\n",
      "             18 LOAD_CONST               1 (1)\n",
      "             20 BINARY_ADD\n",
      "             22 STORE_FAST               1 (y)\n",
      "\n",
      "  5     >>   24 LOAD_FAST                1 (y)\n",
      "             26 LOAD_CONST               2 (2)\n",
      "             28 BINARY_MULTIPLY\n",
      "             30 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:40,851] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE some_kernel /tmp/ipykernel_171109/2329204500.py line 1 \n",
      "  1           0 LOAD_GLOBAL              3 (__compiled_fn_0)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:40,852] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35ee950; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'torch' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'isinstance' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:07:40,853] torch._dynamo.eval_frame: [DEBUG] skipping _fn /home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-03-16 17:07:40,854] torch._dynamo.eval_frame: [DEBUG] skipping nothing /home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py\n",
      "[2023-03-16 17:07:40,854] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /usr/lib/python3.8/contextlib.py\n",
      "[2023-03-16 17:07:40,855] torch._dynamo.eval_frame: [DEBUG] skipping __exit__ /usr/lib/python3.8/contextlib.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(10)\n",
    "mod(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable in a control flow would force a graph break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_kernel(x: torch.Tensor):\n",
    "    if x.sum() > 0: # this should be constant for a JIT module\n",
    "        return -x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:07:40,934] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing some_kernel\n",
      "[2023-03-16 17:07:40,934] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3944027839.py:2\n",
      "[2023-03-16 17:07:40,935] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:40,936] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable()]\n",
      "[2023-03-16 17:07:40,937] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:07:40,939] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TensorVariable()]\n",
      "[2023-03-16 17:07:40,940] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:40,942] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 18 [TensorVariable()]\n",
      "[2023-03-16 17:07:40,943] torch._dynamo.symbolic_convert: [DEBUG] generic_jump triggered compile\n",
      "[2023-03-16 17:07:40,943] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='generic_jump TensorVariable()', user_stack=[<FrameSummary file /tmp/ipykernel_171109/3944027839.py, line 2 in some_kernel>])\n",
      "[2023-03-16 17:07:40,945] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:40,952] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1\n",
      "[2023-03-16 17:07:40,961] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/cv/ccvkthaz2wfpyha47u3bxzxxqwsirk3xwvhfna66zls5aagwcwtw.py\n",
      "[2023-03-16 17:07:40,961] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1\n",
      "[2023-03-16 17:07:40,962] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:40,963] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_1 <eval_with_key>.11 opcode         name    target                  args        kwargs\n",
      "-------------  ------  ----------------------  ----------  --------\n",
      "placeholder    x       x                       ()          {}\n",
      "call_method    sum_1   sum                     (x,)        {}\n",
      "call_function  gt      <built-in function gt>  (sum_1, 0)  {}\n",
      "output         output  output                  ((gt,),)    {}\n",
      "\n",
      "[2023-03-16 17:07:40,963] torch._dynamo.symbolic_convert: [INFO] __resume_at_12_2 function\n",
      "[2023-03-16 17:07:40,964] torch._dynamo.symbolic_convert: [INFO] __resume_at_18_3 function\n",
      "[2023-03-16 17:07:40,965] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE some_kernel /tmp/ipykernel_171109/3944027839.py line 1 \n",
      "  2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_METHOD              0 (sum)\n",
      "              4 CALL_METHOD              0\n",
      "              6 LOAD_CONST               1 (0)\n",
      "              8 COMPARE_OP               4 (>)\n",
      "             10 POP_JUMP_IF_FALSE       18\n",
      "\n",
      "  3          12 LOAD_FAST                0 (x)\n",
      "             14 UNARY_NEGATIVE\n",
      "             16 RETURN_VALUE\n",
      "        >>   18 LOAD_CONST               0 (None)\n",
      "             20 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:40,966] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE some_kernel /tmp/ipykernel_171109/3944027839.py line 1 \n",
      "  1           0 LOAD_GLOBAL              1 (__compiled_fn_1)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 POP_JUMP_IF_FALSE       18\n",
      "             10 LOAD_GLOBAL              2 (__resume_at_12_2)\n",
      "             12 LOAD_FAST                0 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 RETURN_VALUE\n",
      "        >>   18 LOAD_GLOBAL              3 (__resume_at_18_3)\n",
      "             20 CALL_FUNCTION            0\n",
      "             22 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:40,966] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35ee950; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:07:40,968] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in some_kernel>\n",
      "[2023-03-16 17:07:40,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 14 []\n",
      "[2023-03-16 17:07:40,969] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3944027839.py:3\n",
      "[2023-03-16 17:07:40,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:40,970] torch._dynamo.symbolic_convert: [DEBUG] TRACE UNARY_NEGATIVE None [TensorVariable()]\n",
      "[2023-03-16 17:07:40,971] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:40,971] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in some_kernel> (RETURN_VALUE)\n",
      "[2023-03-16 17:07:40,972] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:40,972] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/3944027839.py, line 3 in <graph break in some_kernel>>])\n",
      "[2023-03-16 17:07:40,973] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:40,977] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2\n",
      "[2023-03-16 17:07:40,983] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/jc/cjczm5cnejzq2ol5wbizo6lyzl25hxznfbepmydgztwashehj3vd.py\n",
      "[2023-03-16 17:07:40,983] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2\n",
      "[2023-03-16 17:07:40,984] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:40,984] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_4 <eval_with_key>.17 opcode         name    target                   args       kwargs\n",
      "-------------  ------  -----------------------  ---------  --------\n",
      "placeholder    x       x                        ()         {}\n",
      "call_function  neg     <built-in function neg>  (x,)       {}\n",
      "output         output  output                   ((neg,),)  {}\n",
      "\n",
      "[2023-03-16 17:07:40,985] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE <graph break in some_kernel> /tmp/ipykernel_171109/3944027839.py line 2 \n",
      "  2           0 JUMP_ABSOLUTE           14\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       20\n",
      "\n",
      "  3     >>   14 LOAD_FAST                0 (x)\n",
      "             16 UNARY_NEGATIVE\n",
      "             18 RETURN_VALUE\n",
      "        >>   20 LOAD_CONST               0 (None)\n",
      "             22 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:40,985] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE <graph break in some_kernel> /tmp/ipykernel_171109/3944027839.py line 2 \n",
      "  2           0 LOAD_GLOBAL              1 (__compiled_fn_4)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:40,986] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35ee950; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__resume_at_12_2:\n",
      "  2           0 JUMP_ABSOLUTE           14\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       20\n",
      "\n",
      "  3     >>   14 LOAD_FAST                0 (x)\n",
      "             16 UNARY_NEGATIVE\n",
      "             18 RETURN_VALUE\n",
      "        >>   20 LOAD_CONST               0 (None)\n",
      "             22 RETURN_VALUE\n",
      "__resume_at_18_3:\n",
      "  2           0 JUMP_ABSOLUTE           20\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       20\n",
      "             14 LOAD_FAST                0 (x)\n",
      "             16 UNARY_NEGATIVE\n",
      "             18 RETURN_VALUE\n",
      "\n",
      "  3     >>   20 LOAD_CONST               0 (None)\n",
      "             22 RETURN_VALUE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = torch.compile(some_kernel)\n",
    "mod(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows that the `POP_JUMP_IF_FALSE` cannot be pruned for we need the runtime value of the `x.sum()`, which is only accessible after it is executed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function call and Frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python VM, a function call will generate a new  frame, but this is not always true in Dynamo. \n",
    "Dynamo could alter the Code Object to inline some function call if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_fn(x: torch.Tensor):\n",
    "    return x + 1\n",
    "\n",
    "def main_fn(x: torch.Tensor, y:torch.Tensor):\n",
    "    tmp = third_fn(x) # inline call here?\n",
    "    return y + tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dynamo.reset()\n",
    "main_fn_ = torch.compile(main_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small function call, Dynamo will inline it directly, and that would save a frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:07:41,080] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing main_fn\n",
      "[2023-03-16 17:07:41,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/285673021.py:5\n",
      "[2023-03-16 17:07:41,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL third_fn []\n",
      "[2023-03-16 17:07:41,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:07:41,083] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:41,084] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object third_fn at 0x7fe1bd34ca80, file \"/tmp/ipykernel_171109/285673021.py\", line 1> \n",
      "   2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_CONST               1 (1)\n",
      "              4 BINARY_ADD\n",
      "              6 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:07:41,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/285673021.py:2\n",
      "[2023-03-16 17:07:41,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:41,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "[2023-03-16 17:07:41,085] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:41,087] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:41,088] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object third_fn at 0x7fe1bd34ca80, file \"/tmp/ipykernel_171109/285673021.py\", line 1>\n",
      "[2023-03-16 17:07:41,088] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST tmp [TensorVariable()]\n",
      "[2023-03-16 17:07:41,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/285673021.py:6\n",
      "[2023-03-16 17:07:41,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-03-16 17:07:41,089] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST tmp [TensorVariable()]\n",
      "[2023-03-16 17:07:41,090] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:41,092] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:41,092] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing main_fn (RETURN_VALUE)\n",
      "[2023-03-16 17:07:41,092] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:41,093] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/285673021.py, line 6 in main_fn>])\n",
      "[2023-03-16 17:07:41,094] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,106] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3\n",
      "[2023-03-16 17:07:41,115] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/3t/c3tttcaxt46p6svdhpi6oj5kziop2nomhwptqthaudwpruvxkqxs.py\n",
      "[2023-03-16 17:07:41,116] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3\n",
      "[2023-03-16 17:07:41,116] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,117] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_5 <eval_with_key>.23 opcode         name    target                   args         kwargs\n",
      "-------------  ------  -----------------------  -----------  --------\n",
      "placeholder    x       x                        ()           {}\n",
      "placeholder    y       y                        ()           {}\n",
      "call_function  add     <built-in function add>  (x, 1)       {}\n",
      "call_function  add_1   <built-in function add>  (y, add)     {}\n",
      "output         output  output                   ((add_1,),)  {}\n",
      "\n",
      "[2023-03-16 17:07:41,118] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE main_fn /tmp/ipykernel_171109/285673021.py line 4 \n",
      "  5           0 LOAD_GLOBAL              0 (third_fn)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               2 (tmp)\n",
      "\n",
      "  6           8 LOAD_FAST                1 (y)\n",
      "             10 LOAD_FAST                2 (tmp)\n",
      "             12 BINARY_ADD\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,119] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE main_fn /tmp/ipykernel_171109/285673021.py line 4 \n",
      "  4           0 LOAD_GLOBAL              1 (__compiled_fn_5)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_FAST                1 (y)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,119] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35399a0; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35399a0; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'third_fn' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_fn_(x,x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a function that cannot be inlined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_fn(x: torch.Tensor):\n",
    "    if x.sum() > 0:\n",
    "        return x + 1\n",
    "    return x\n",
    "\n",
    "def main_fn(x: torch.Tensor, y:torch.Tensor):\n",
    "    tmp = third_fn(x) # inline call here?\n",
    "    return y + tmp\n",
    "\n",
    "main_fn_1 = torch.compile(main_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:07:41,181] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing main_fn\n",
      "[2023-03-16 17:07:41,182] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2932769143.py:7\n",
      "[2023-03-16 17:07:41,182] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL third_fn []\n",
      "[2023-03-16 17:07:41,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:07:41,183] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:41,184] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object third_fn at 0x7fe1bb1cf0e0, file \"/tmp/ipykernel_171109/2932769143.py\", line 1> \n",
      "   2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_METHOD              0 (sum)\n",
      "              4 CALL_METHOD              0\n",
      "              6 LOAD_CONST               1 (0)\n",
      "              8 COMPARE_OP               4 (>)\n",
      "             10 POP_JUMP_IF_FALSE       20\n",
      "\n",
      "  3          12 LOAD_FAST                0 (x)\n",
      "             14 LOAD_CONST               2 (1)\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "\n",
      "  4     >>   20 LOAD_FAST                0 (x)\n",
      "             22 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:07:41,184] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2932769143.py:2\n",
      "[2023-03-16 17:07:41,185] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:41,185] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable()]\n",
      "[2023-03-16 17:07:41,186] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:07:41,188] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TensorVariable()]\n",
      "[2023-03-16 17:07:41,188] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:41,189] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 20 [TensorVariable()]\n",
      "[2023-03-16 17:07:41,190] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object third_fn at 0x7fe1bb1cf0e0, file \"/tmp/ipykernel_171109/2932769143.py\", line 1>\n",
      "[2023-03-16 17:07:41,190] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 2 nodes\n",
      "[2023-03-16 17:07:41,190] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 344, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 986, in CALL_FUNCTION\n",
      "    self.call_function(fn, args, {})\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 489, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 259, in call_function\n",
      "    return super().call_function(tx, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 92, in call_function\n",
      "    return tx.inline_user_function_return(\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 525, in inline_user_function_return\n",
      "    result = InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1831, in inline_call\n",
      "    return cls.inline_call_(parent, func, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1887, in inline_call_\n",
      "    tracer.run()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 597, in run\n",
      "    and self.step()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 561, in step\n",
      "    getattr(self, inst.opname)(inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 329, in inner\n",
      "    unimplemented(f\"generic_jump {typestr(value)}\")\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/exc.py\", line 71, in unimplemented\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: generic_jump TensorVariable()\n",
      "[2023-03-16 17:07:41,191] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2023-03-16 17:07:41,192] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='generic_jump TensorVariable()', user_stack=[<FrameSummary file /tmp/ipykernel_171109/2932769143.py, line 7 in main_fn>, <FrameSummary file /tmp/ipykernel_171109/2932769143.py, line 2 in third_fn>])\n",
      "[2023-03-16 17:07:41,193] torch._dynamo.symbolic_convert: [INFO] __resume_at_6_6 function\n",
      "[2023-03-16 17:07:41,193] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE main_fn /tmp/ipykernel_171109/2932769143.py line 6 \n",
      "  7           0 LOAD_GLOBAL              0 (third_fn)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               2 (tmp)\n",
      "\n",
      "  8           8 LOAD_FAST                1 (y)\n",
      "             10 LOAD_FAST                2 (tmp)\n",
      "             12 BINARY_ADD\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,194] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE main_fn /tmp/ipykernel_171109/2932769143.py line 6 \n",
      "  6           0 LOAD_GLOBAL              0 (third_fn)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "\n",
      "  7           4 CALL_FUNCTION            1\n",
      "              6 LOAD_GLOBAL              1 (__resume_at_6_6)\n",
      "              8 ROT_TWO\n",
      "             10 LOAD_FAST                1 (y)\n",
      "             12 CALL_FUNCTION            2\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,194] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35399a0; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35399a0; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'third_fn' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:07:41,195] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing third_fn\n",
      "[2023-03-16 17:07:41,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2932769143.py:2\n",
      "[2023-03-16 17:07:41,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:41,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable()]\n",
      "[2023-03-16 17:07:41,196] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:07:41,198] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TensorVariable()]\n",
      "[2023-03-16 17:07:41,198] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:41,199] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 20 [TensorVariable()]\n",
      "[2023-03-16 17:07:41,199] torch._dynamo.symbolic_convert: [DEBUG] generic_jump triggered compile\n",
      "[2023-03-16 17:07:41,200] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='generic_jump TensorVariable()', user_stack=[<FrameSummary file /tmp/ipykernel_171109/2932769143.py, line 2 in third_fn>])\n",
      "[2023-03-16 17:07:41,201] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,207] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4\n",
      "[2023-03-16 17:07:41,215] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/cv/ccvkthaz2wfpyha47u3bxzxxqwsirk3xwvhfna66zls5aagwcwtw.py\n",
      "[2023-03-16 17:07:41,215] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4\n",
      "[2023-03-16 17:07:41,216] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,217] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_7 <eval_with_key>.29 opcode         name    target                  args        kwargs\n",
      "-------------  ------  ----------------------  ----------  --------\n",
      "placeholder    x       x                       ()          {}\n",
      "call_method    sum_1   sum                     (x,)        {}\n",
      "call_function  gt      <built-in function gt>  (sum_1, 0)  {}\n",
      "output         output  output                  ((gt,),)    {}\n",
      "\n",
      "[2023-03-16 17:07:41,217] torch._dynamo.symbolic_convert: [INFO] __resume_at_12_8 function\n",
      "[2023-03-16 17:07:41,218] torch._dynamo.symbolic_convert: [INFO] __resume_at_20_9 function\n",
      "[2023-03-16 17:07:41,219] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE third_fn /tmp/ipykernel_171109/2932769143.py line 1 \n",
      "  2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_METHOD              0 (sum)\n",
      "              4 CALL_METHOD              0\n",
      "              6 LOAD_CONST               1 (0)\n",
      "              8 COMPARE_OP               4 (>)\n",
      "             10 POP_JUMP_IF_FALSE       20\n",
      "\n",
      "  3          12 LOAD_FAST                0 (x)\n",
      "             14 LOAD_CONST               2 (1)\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "\n",
      "  4     >>   20 LOAD_FAST                0 (x)\n",
      "             22 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,219] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE third_fn /tmp/ipykernel_171109/2932769143.py line 1 \n",
      "  1           0 LOAD_GLOBAL              1 (__compiled_fn_7)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 POP_JUMP_IF_FALSE       18\n",
      "             10 LOAD_GLOBAL              2 (__resume_at_12_8)\n",
      "             12 LOAD_FAST                0 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 RETURN_VALUE\n",
      "        >>   18 LOAD_GLOBAL              3 (__resume_at_20_9)\n",
      "             20 LOAD_FAST                0 (x)\n",
      "             22 CALL_FUNCTION            1\n",
      "             24 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,220] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35399a0; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:07:41,221] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in third_fn>\n",
      "[2023-03-16 17:07:41,222] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 14 []\n",
      "[2023-03-16 17:07:41,222] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2932769143.py:3\n",
      "[2023-03-16 17:07:41,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:41,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "[2023-03-16 17:07:41,223] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:41,225] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:41,225] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in third_fn> (RETURN_VALUE)\n",
      "[2023-03-16 17:07:41,226] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:41,226] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/2932769143.py, line 3 in <graph break in third_fn>>])\n",
      "[2023-03-16 17:07:41,227] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,232] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5\n",
      "[2023-03-16 17:07:41,238] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/in/cinwjy4w37ctkic2rwzneqbiyrntxppmikrybpetnnpdagtbyno2.py\n",
      "[2023-03-16 17:07:41,238] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5\n",
      "[2023-03-16 17:07:41,239] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,240] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_10 <eval_with_key>.35 opcode         name    target                   args       kwargs\n",
      "-------------  ------  -----------------------  ---------  --------\n",
      "placeholder    x       x                        ()         {}\n",
      "call_function  add     <built-in function add>  (x, 1)     {}\n",
      "output         output  output                   ((add,),)  {}\n",
      "\n",
      "[2023-03-16 17:07:41,241] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE <graph break in third_fn> /tmp/ipykernel_171109/2932769143.py line 2 \n",
      "  2           0 JUMP_ABSOLUTE           14\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       22\n",
      "\n",
      "  3     >>   14 LOAD_FAST                0 (x)\n",
      "             16 LOAD_CONST               2 (1)\n",
      "             18 BINARY_ADD\n",
      "             20 RETURN_VALUE\n",
      "\n",
      "  4     >>   22 LOAD_FAST                0 (x)\n",
      "             24 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,241] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE <graph break in third_fn> /tmp/ipykernel_171109/2932769143.py line 2 \n",
      "  2           0 LOAD_GLOBAL              1 (__compiled_fn_10)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,242] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35399a0; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:07:41,244] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in main_fn>\n",
      "[2023-03-16 17:07:41,244] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2023-03-16 17:07:41,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 10 [TensorVariable()]\n",
      "[2023-03-16 17:07:41,245] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST tmp [TensorVariable()]\n",
      "[2023-03-16 17:07:41,246] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2932769143.py:8\n",
      "[2023-03-16 17:07:41,246] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-03-16 17:07:41,247] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST tmp [TensorVariable()]\n",
      "[2023-03-16 17:07:41,247] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:41,249] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:41,249] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in main_fn> (RETURN_VALUE)\n",
      "[2023-03-16 17:07:41,249] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:41,250] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/2932769143.py, line 8 in <graph break in main_fn>>])\n",
      "[2023-03-16 17:07:41,251] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,258] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6\n",
      "[2023-03-16 17:07:41,265] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/dh/cdhp73wrsdttbcjonwvc2ri3hjvbq2p4dtqohj2byq6x7z34yexm.py\n",
      "[2023-03-16 17:07:41,265] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6\n",
      "[2023-03-16 17:07:41,266] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:41,267] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_11 <eval_with_key>.41 opcode         name     target                   args          kwargs\n",
      "-------------  -------  -----------------------  ------------  --------\n",
      "placeholder    _stack0  _stack0                  ()            {}\n",
      "placeholder    y        y                        ()            {}\n",
      "call_function  add      <built-in function add>  (y, _stack0)  {}\n",
      "output         output   output                   ((add,),)     {}\n",
      "\n",
      "[2023-03-16 17:07:41,268] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE <graph break in main_fn> /tmp/ipykernel_171109/2932769143.py line 7 \n",
      "  7           0 LOAD_FAST                0 (___stack0)\n",
      "              2 JUMP_ABSOLUTE           10\n",
      "              4 LOAD_GLOBAL              0 (third_fn)\n",
      "              6 LOAD_FAST                2 (x)\n",
      "              8 CALL_FUNCTION            1\n",
      "        >>   10 STORE_FAST               3 (tmp)\n",
      "\n",
      "  8          12 LOAD_FAST                1 (y)\n",
      "             14 LOAD_FAST                3 (tmp)\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,268] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE <graph break in main_fn> /tmp/ipykernel_171109/2932769143.py line 7 \n",
      "  7           0 LOAD_GLOBAL              1 (__compiled_fn_11)\n",
      "              2 LOAD_FAST                0 (___stack0)\n",
      "              4 LOAD_FAST                1 (y)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:41,269] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f35399a0; to 'Tensor' at 0x7fe07c0eb310>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local '___stack0' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0f354b400; to 'Tensor' at 0x7fe0f35399f0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:07:41,270] torch._dynamo.eval_frame: [DEBUG] skipping __call__ /usr/lib/python3.8/weakref.py\n",
      "[2023-03-16 17:07:41,270] torch._dynamo.eval_frame: [DEBUG] skipping del_ten /home/chunwei/trienv/lib/python3.8/site-packages/torch/_subclasses/meta_utils.py\n",
      "[2023-03-16 17:07:41,271] torch._dynamo.eval_frame: [DEBUG] skipping pop /usr/lib/python3.8/weakref.py\n",
      "[2023-03-16 17:07:41,271] torch._dynamo.eval_frame: [DEBUG] skipping __hash__ /home/chunwei/trienv/lib/python3.8/site-packages/torch/utils/weak.py\n",
      "[2023-03-16 17:07:41,272] torch._dynamo.eval_frame: [DEBUG] skipping expired /home/chunwei/trienv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\n",
      "[2023-03-16 17:07:41,273] torch._dynamo.eval_frame: [DEBUG] skipping _expired /home/chunwei/trienv/lib/python3.8/site-packages/torch/storage.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inline UserFunctionVariable() failed\n",
      "__resume_at_6_6:\n",
      "  7           0 LOAD_FAST                0 (___stack0)\n",
      "              2 JUMP_ABSOLUTE           10\n",
      "              4 LOAD_GLOBAL              0 (third_fn)\n",
      "              6 LOAD_FAST                2 (x)\n",
      "              8 CALL_FUNCTION            1\n",
      "        >>   10 STORE_FAST               3 (tmp)\n",
      "\n",
      "  8          12 LOAD_FAST                1 (y)\n",
      "             14 LOAD_FAST                3 (tmp)\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "__resume_at_12_8:\n",
      "  2           0 JUMP_ABSOLUTE           14\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       22\n",
      "\n",
      "  3     >>   14 LOAD_FAST                0 (x)\n",
      "             16 LOAD_CONST               2 (1)\n",
      "             18 BINARY_ADD\n",
      "             20 RETURN_VALUE\n",
      "\n",
      "  4     >>   22 LOAD_FAST                0 (x)\n",
      "             24 RETURN_VALUE\n",
      "__resume_at_20_9:\n",
      "  2           0 JUMP_ABSOLUTE           22\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       22\n",
      "             14 LOAD_FAST                0 (x)\n",
      "             16 LOAD_CONST               2 (1)\n",
      "             18 BINARY_ADD\n",
      "             20 RETURN_VALUE\n",
      "\n",
      "  4     >>   22 LOAD_FAST                0 (x)\n",
      "             24 RETURN_VALUE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_fn_1(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:07:42,260] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing fn\n",
      "[2023-03-16 17:07:42,261] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/1965302006.py:2\n",
      "[2023-03-16 17:07:42,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST a []\n",
      "[2023-03-16 17:07:42,262] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable()]\n",
      "[2023-03-16 17:07:42,263] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:07:42,264] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [GetAttrVariable(TensorVariable(), sum), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:42,266] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST b [TensorVariable()]\n",
      "[2023-03-16 17:07:42,267] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:42,267] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TensorVariable(), GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:07:42,268] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [TensorVariable(), GetAttrVariable(TensorVariable(), sum), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:42,269] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:42,270] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:42,271] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing fn (RETURN_VALUE)\n",
      "[2023-03-16 17:07:42,271] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:42,272] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/1965302006.py, line 2 in fn>])\n",
      "[2023-03-16 17:07:42,273] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:42,282] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7\n",
      "[2023-03-16 17:07:42,292] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0'), SchedulerNode(name='buf1'), <class 'torch._inductor.codegen.triton.DisableReduction'>, SchedulerNode(name='buf2'), <class 'torch._inductor.codegen.triton.EnableReduction'>]\n",
      "[2023-03-16 17:07:42,296] torch._inductor.scheduler: [DEBUG] remove_buffer('buf1')\n",
      "[2023-03-16 17:07:42,557] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/fo/cfoahsrzm2nf5unapsmymyh2ifq6uymt3dixt7aucbpn3vqxmbnu.py\n",
      "[2023-03-16 17:07:42,558] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7\n",
      "[2023-03-16 17:07:42,559] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:42,560] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_12 <eval_with_key>.47 opcode         name    target                   args            kwargs\n",
      "-------------  ------  -----------------------  --------------  --------\n",
      "placeholder    a       a                        ()              {}\n",
      "placeholder    b       b                        ()              {}\n",
      "call_method    sum_1   sum                      (a, 0)          {}\n",
      "call_method    sum_2   sum                      (b, 0)          {}\n",
      "call_function  add     <built-in function add>  (sum_1, sum_2)  {}\n",
      "output         output  output                   ((add,),)       {}\n",
      "\n",
      "[2023-03-16 17:07:42,561] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE fn /tmp/ipykernel_171109/1965302006.py line 1 \n",
      "  2           0 LOAD_FAST                0 (a)\n",
      "              2 LOAD_METHOD              0 (sum)\n",
      "              4 LOAD_CONST               1 (0)\n",
      "              6 CALL_METHOD              1\n",
      "              8 LOAD_FAST                1 (b)\n",
      "             10 LOAD_METHOD              0 (sum)\n",
      "             12 LOAD_CONST               1 (0)\n",
      "             14 CALL_METHOD              1\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:42,562] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE fn /tmp/ipykernel_171109/1965302006.py line 1 \n",
      "  1           0 LOAD_GLOBAL              1 (__compiled_fn_12)\n",
      "              2 LOAD_FAST                0 (a)\n",
      "              4 LOAD_FAST                1 (b)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:42,562] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'a' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0ef465e00; to 'Tensor' at 0x7fe0ef4962c0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'b' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0ef465720; to 'Tensor' at 0x7fe07d0cd900>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-10.5003,  -2.3082,   7.9250,   3.7306,  11.4371,   4.6230,   0.7037,\n",
       "          8.5890,  11.2040,  -6.0124,  -3.6523,  -5.4520,  -7.1022,   1.9420,\n",
       "         -0.8349,   0.2798,  -9.4945,  -7.4654,  -1.8288,  -9.7656,   1.7412,\n",
       "         -0.9800,  -9.9994,   7.4591,  10.4829,   6.3766,   1.9650,  -6.3278,\n",
       "         11.3239,   5.9450,  -1.2080, -11.4838,  -1.8048,   1.8252,   6.8341,\n",
       "         -5.2005,   9.8097,  -4.1489,  -1.0129,   5.3399,  -4.0586,  -2.4990,\n",
       "         -4.2183,  -3.4967], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fn(a, b):\n",
    "    return a.sum(0) + b.sum(0)\n",
    "\n",
    "_dynamo.reset()\n",
    "fn_ = torch.compile(fn)\n",
    "\n",
    "a = torch.randn((33, 44), device='cuda')\n",
    "b = torch.randn((33, 44), device='cuda')\n",
    "fn_(a,b)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dict, tuple can also be inlined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_fn1(x: torch.Tensor):\n",
    "    adic = {}\n",
    "    adic[\"out\"] = x\n",
    "    adic[\"tmp\"] = x\n",
    "    return adic\n",
    "\n",
    "def main_fn1(x: torch.Tensor, y:torch.Tensor):\n",
    "    tmp = third_fn1(x) # inline call here?\n",
    "    return y + tmp[\"out\"]\n",
    "\n",
    "_dynamo.reset()\n",
    "main_fn_2 = torch.compile(main_fn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((33, 44), device='cuda')\n",
    "b = torch.randn((33, 44), device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:07:42,661] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing main_fn1\n",
      "[2023-03-16 17:07:42,661] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2273668353.py:8\n",
      "[2023-03-16 17:07:42,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL third_fn1 []\n",
      "[2023-03-16 17:07:42,662] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:07:42,663] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:42,663] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object third_fn1 at 0x7fe07c0755b0, file \"/tmp/ipykernel_171109/2273668353.py\", line 1> \n",
      "   2           0 BUILD_MAP                0\n",
      "              2 STORE_FAST               1 (adic)\n",
      "\n",
      "  3           4 LOAD_FAST                0 (x)\n",
      "              6 LOAD_FAST                1 (adic)\n",
      "              8 LOAD_CONST               1 ('out')\n",
      "             10 STORE_SUBSCR\n",
      "\n",
      "  4          12 LOAD_FAST                0 (x)\n",
      "             14 LOAD_FAST                1 (adic)\n",
      "             16 LOAD_CONST               2 ('tmp')\n",
      "             18 STORE_SUBSCR\n",
      "\n",
      "  5          20 LOAD_FAST                1 (adic)\n",
      "             22 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:07:42,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2273668353.py:2\n",
      "[2023-03-16 17:07:42,664] torch._dynamo.symbolic_convert: [DEBUG] TRACE BUILD_MAP 0 []\n",
      "[2023-03-16 17:07:42,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST adic [ConstDictVariable()]\n",
      "[2023-03-16 17:07:42,665] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2273668353.py:3\n",
      "[2023-03-16 17:07:42,666] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:42,666] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST adic [TensorVariable()]\n",
      "[2023-03-16 17:07:42,666] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST out [TensorVariable(), ConstDictVariable()]\n",
      "[2023-03-16 17:07:42,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_SUBSCR None [TensorVariable(), ConstDictVariable(), ConstantVariable(str)]\n",
      "[2023-03-16 17:07:42,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2273668353.py:4\n",
      "[2023-03-16 17:07:42,667] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:07:42,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST adic [TensorVariable()]\n",
      "[2023-03-16 17:07:42,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST tmp [TensorVariable(), ConstDictVariable()]\n",
      "[2023-03-16 17:07:42,668] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_SUBSCR None [TensorVariable(), ConstDictVariable(), ConstantVariable(str)]\n",
      "[2023-03-16 17:07:42,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2273668353.py:5\n",
      "[2023-03-16 17:07:42,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST adic []\n",
      "[2023-03-16 17:07:42,669] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [ConstDictVariable()]\n",
      "[2023-03-16 17:07:42,669] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object third_fn1 at 0x7fe07c0755b0, file \"/tmp/ipykernel_171109/2273668353.py\", line 1>\n",
      "[2023-03-16 17:07:42,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST tmp [ConstDictVariable()]\n",
      "[2023-03-16 17:07:42,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2273668353.py:9\n",
      "[2023-03-16 17:07:42,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-03-16 17:07:42,670] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST tmp [TensorVariable()]\n",
      "[2023-03-16 17:07:42,671] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST out [TensorVariable(), ConstDictVariable()]\n",
      "[2023-03-16 17:07:42,671] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_SUBSCR None [TensorVariable(), ConstDictVariable(), ConstantVariable(str)]\n",
      "[2023-03-16 17:07:42,671] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:42,674] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:42,674] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing main_fn1 (RETURN_VALUE)\n",
      "[2023-03-16 17:07:42,675] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:42,675] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/2273668353.py, line 9 in main_fn1>])\n",
      "[2023-03-16 17:07:42,676] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:42,684] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8\n",
      "[2023-03-16 17:07:42,689] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-16 17:07:42,938] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/te/cteq4kxxnv36aiy4rys25ixz76splq6qjwiyhwjmxvanntrryf2i.py\n",
      "[2023-03-16 17:07:42,939] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8\n",
      "[2023-03-16 17:07:42,940] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:42,941] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_13 <eval_with_key>.53 opcode         name    target                   args       kwargs\n",
      "-------------  ------  -----------------------  ---------  --------\n",
      "placeholder    x       x                        ()         {}\n",
      "placeholder    y       y                        ()         {}\n",
      "call_function  add     <built-in function add>  (y, x)     {}\n",
      "output         output  output                   ((add,),)  {}\n",
      "\n",
      "[2023-03-16 17:07:42,942] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE main_fn1 /tmp/ipykernel_171109/2273668353.py line 7 \n",
      "  8           0 LOAD_GLOBAL              0 (third_fn1)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               2 (tmp)\n",
      "\n",
      "  9           8 LOAD_FAST                1 (y)\n",
      "             10 LOAD_FAST                2 (tmp)\n",
      "             12 LOAD_CONST               1 ('out')\n",
      "             14 BINARY_SUBSCR\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:42,942] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE main_fn1 /tmp/ipykernel_171109/2273668353.py line 7 \n",
      "  7           0 LOAD_GLOBAL              1 (__compiled_fn_13)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_FAST                1 (y)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:42,943] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0ef465db0; to 'Tensor' at 0x7fe0f3625db0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0ef465bd0; to 'Tensor' at 0x7fe0f35375e0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'third_fn1' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-3.7946, -0.5855,  1.0855,  ...,  0.1345, -0.1574,  2.2312],\n",
       "        [ 1.3433,  2.8785, -1.6530,  ..., -1.7912, -2.0573,  0.7959],\n",
       "        [-0.5695, -1.6292,  0.0336,  ..., -1.2363,  1.5298, -1.5409],\n",
       "        ...,\n",
       "        [ 0.2256,  0.0435,  1.8306,  ...,  1.2719,  0.9207,  0.6777],\n",
       "        [-1.3494,  0.2264,  0.8916,  ..., -1.2846, -3.4267, -0.8233],\n",
       "        [ 0.4636, -2.4870, -0.4616,  ..., -1.3939,  1.6246,  3.3484]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_fn_2(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def message(a, b):\n",
    "    return a.view(-1, 1) + b.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.config.suppress_errors = True\n",
    "def main_fn2(x: torch.Tensor, y:torch.Tensor):\n",
    "    tmp = message(x, y) # inline call here?\n",
    "    return tmp * 2\n",
    "\n",
    "_dynamo.reset()\n",
    "main_fn_2 = torch.compile(main_fn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:07:43,103] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing main_fn2\n",
      "[2023-03-16 17:07:43,104] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/1591432987.py:3\n",
      "[2023-03-16 17:07:43,105] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL message []\n",
      "[2023-03-16 17:07:43,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:07:43,106] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:43,107] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [UserFunctionVariable(), TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:43,107] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object message at 0x7fe0ef421a80, file \"/tmp/ipykernel_171109/2076900814.py\", line 1> \n",
      "   2           0 LOAD_FAST                0 (a)\n",
      "              2 LOAD_METHOD              0 (view)\n",
      "              4 LOAD_CONST               1 (-1)\n",
      "              6 LOAD_CONST               2 (1)\n",
      "              8 CALL_METHOD              2\n",
      "             10 LOAD_FAST                1 (b)\n",
      "             12 LOAD_METHOD              0 (view)\n",
      "             14 LOAD_CONST               2 (1)\n",
      "             16 LOAD_CONST               1 (-1)\n",
      "             18 CALL_METHOD              2\n",
      "             20 BINARY_ADD\n",
      "             22 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:07:43,109] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/2076900814.py:2\n",
      "[2023-03-16 17:07:43,109] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST a []\n",
      "[2023-03-16 17:07:43,110] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable()]\n",
      "[2023-03-16 17:07:43,110] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-03-16 17:07:43,111] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:43,111] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:43,113] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST b [TensorVariable()]\n",
      "[2023-03-16 17:07:43,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR view [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:43,114] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable(), GetAttrVariable(TensorVariable(), view)]\n",
      "[2023-03-16 17:07:43,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST -1 [TensorVariable(), GetAttrVariable(TensorVariable(), view), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:43,115] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 2 [TensorVariable(), GetAttrVariable(TensorVariable(), view), ConstantVariable(int), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:43,118] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:07:43,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:43,120] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object message at 0x7fe0ef421a80, file \"/tmp/ipykernel_171109/2076900814.py\", line 1>\n",
      "[2023-03-16 17:07:43,120] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST tmp [TensorVariable()]\n",
      "[2023-03-16 17:07:43,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/1591432987.py:4\n",
      "[2023-03-16 17:07:43,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST tmp []\n",
      "[2023-03-16 17:07:43,121] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 2 [TensorVariable()]\n",
      "[2023-03-16 17:07:43,122] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_MULTIPLY None [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:07:43,123] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:07:43,123] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing main_fn2 (RETURN_VALUE)\n",
      "[2023-03-16 17:07:43,124] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:07:43,124] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/1591432987.py, line 4 in main_fn2>])\n",
      "[2023-03-16 17:07:43,125] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:07:43,135] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9\n",
      "[2023-03-16 17:07:43,141] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-16 17:07:43,406] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/6k/c6kma4y3mehmhnasimzzbkm7syscyrgadiotgynfrqhfd3n55e2a.py\n",
      "[2023-03-16 17:07:43,407] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9\n",
      "[2023-03-16 17:07:43,408] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:07:43,409] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_14 <eval_with_key>.59 opcode         name    target                   args            kwargs\n",
      "-------------  ------  -----------------------  --------------  --------\n",
      "placeholder    x       x                        ()              {}\n",
      "placeholder    y       y                        ()              {}\n",
      "call_method    view    view                     (x, -1, 1)      {}\n",
      "call_method    view_1  view                     (y, 1, -1)      {}\n",
      "call_function  add     <built-in function add>  (view, view_1)  {}\n",
      "call_function  mul     <built-in function mul>  (add, 2)        {}\n",
      "output         output  output                   ((mul,),)       {}\n",
      "\n",
      "[2023-03-16 17:07:43,410] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE main_fn2 /tmp/ipykernel_171109/1591432987.py line 2 \n",
      "  3           0 LOAD_GLOBAL              0 (message)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_FAST                1 (y)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 STORE_FAST               2 (tmp)\n",
      "\n",
      "  4          10 LOAD_FAST                2 (tmp)\n",
      "             12 LOAD_CONST               1 (2)\n",
      "             14 BINARY_MULTIPLY\n",
      "             16 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:43,410] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE main_fn2 /tmp/ipykernel_171109/1591432987.py line 2 \n",
      "  2           0 LOAD_GLOBAL              1 (__compiled_fn_14)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_FAST                1 (y)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:07:43,411] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0ef465f40; to 'Tensor' at 0x7fe0f3625db0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0eefa7630; to 'Tensor' at 0x7fe0f35375e0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'message' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-7.5893, -4.1648, -5.5210,  ..., -4.8884, -2.6454,  0.0884],\n",
       "        [-4.5954, -1.1709, -2.5271,  ..., -1.8945,  0.3485,  3.0823],\n",
       "        [ 0.1027,  3.5272,  2.1710,  ...,  2.8036,  5.0466,  7.7804],\n",
       "        ...,\n",
       "        [-5.4887, -2.0643, -3.4205,  ..., -2.7879, -0.5448,  2.1889],\n",
       "        [-1.6947,  1.7298,  0.3736,  ...,  1.0062,  3.2492,  5.9830],\n",
       "        [-0.9808,  2.4436,  1.0874,  ...,  1.7200,  3.9630,  6.6968]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_fn_2(a, b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inner-most graph break will cause the call stack failed to inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_fn1(x: torch.Tensor):\n",
    "    x = x + 1\n",
    "    return x\n",
    "\n",
    "def third_fn2(x: torch.Tensor):\n",
    "    x = x + 1\n",
    "    return x\n",
    "\n",
    "def main_fn1(x: torch.Tensor, y:torch.Tensor):\n",
    "    x = third_fn2(x) # inline call here?\n",
    "    return y + x\n",
    "\n",
    "_dynamo.reset()\n",
    "main_fn_2 = torch.compile(main_fn1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `third_fn1` and `third_fn2` could be inlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:08:46,943] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing main_fn1\n",
      "[2023-03-16 17:08:46,943] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/1078405638.py:10\n",
      "[2023-03-16 17:08:46,944] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL third_fn2 []\n",
      "[2023-03-16 17:08:46,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:08:46,945] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:08:46,946] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object third_fn2 at 0x7fe0f3748920, file \"/tmp/ipykernel_171109/1078405638.py\", line 5> \n",
      "   6           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_CONST               1 (1)\n",
      "              4 BINARY_ADD\n",
      "              6 STORE_FAST               0 (x)\n",
      "\n",
      "  7           8 LOAD_FAST                0 (x)\n",
      "             10 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:08:46,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/1078405638.py:6\n",
      "[2023-03-16 17:08:46,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:08:46,947] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "[2023-03-16 17:08:46,948] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:08:46,950] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-03-16 17:08:46,950] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/1078405638.py:7\n",
      "[2023-03-16 17:08:46,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:08:46,951] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:08:46,951] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object third_fn2 at 0x7fe0f3748920, file \"/tmp/ipykernel_171109/1078405638.py\", line 5>\n",
      "[2023-03-16 17:08:46,952] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-03-16 17:08:46,952] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/1078405638.py:11\n",
      "[2023-03-16 17:08:46,952] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-03-16 17:08:46,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable()]\n",
      "[2023-03-16 17:08:46,953] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:08:46,954] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:08:46,954] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing main_fn1 (RETURN_VALUE)\n",
      "[2023-03-16 17:08:46,955] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:08:46,955] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/1078405638.py, line 11 in main_fn1>])\n",
      "[2023-03-16 17:08:46,957] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:08:46,967] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 11\n",
      "[2023-03-16 17:08:46,972] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-16 17:08:47,086] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/2b/c2bvehqksrgbmidz3mofgaqekpko6rfyi2c3h3gmd7gg4noohpcc.py\n",
      "[2023-03-16 17:08:47,087] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 11\n",
      "[2023-03-16 17:08:47,088] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:08:47,089] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_16 <eval_with_key>.71 opcode         name    target                   args         kwargs\n",
      "-------------  ------  -----------------------  -----------  --------\n",
      "placeholder    x       x                        ()           {}\n",
      "placeholder    y       y                        ()           {}\n",
      "call_function  add     <built-in function add>  (x, 1)       {}\n",
      "call_function  add_1   <built-in function add>  (y, add)     {}\n",
      "output         output  output                   ((add_1,),)  {}\n",
      "\n",
      "[2023-03-16 17:08:47,089] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE main_fn1 /tmp/ipykernel_171109/1078405638.py line 9 \n",
      " 10           0 LOAD_GLOBAL              0 (third_fn2)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               0 (x)\n",
      "\n",
      " 11           8 LOAD_FAST                1 (y)\n",
      "             10 LOAD_FAST                0 (x)\n",
      "             12 BINARY_ADD\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:08:47,090] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE main_fn1 /tmp/ipykernel_171109/1078405638.py line 9 \n",
      "  9           0 LOAD_GLOBAL              1 (__compiled_fn_16)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_FAST                1 (y)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:08:47,091] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0eef5c950; to 'Tensor' at 0x7fe0f3625db0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0e7c206d0; to 'Tensor' at 0x7fe0f35375e0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'third_fn2' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7946,  0.4145,  2.0855,  ...,  1.1345,  0.8426,  3.2312],\n",
       "        [ 2.3433,  3.8785, -0.6530,  ..., -0.7912, -1.0573,  1.7959],\n",
       "        [ 0.4305, -0.6292,  1.0336,  ..., -0.2363,  2.5298, -0.5409],\n",
       "        ...,\n",
       "        [ 1.2256,  1.0435,  2.8306,  ...,  2.2719,  1.9207,  1.6777],\n",
       "        [-0.3494,  1.2264,  1.8916,  ..., -0.2846, -2.4267,  0.1767],\n",
       "        [ 1.4636, -1.4870,  0.5384,  ..., -0.3939,  2.6246,  4.3484]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_fn_2(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_fn1(x: torch.Tensor):\n",
    "    x = x if x.sum() > 0 else x + 1 # force graph break\n",
    "    return x\n",
    "\n",
    "def third_fn2(x: torch.Tensor):\n",
    "    x = third_fn1(x)\n",
    "    return x\n",
    "\n",
    "def main_fn1(x: torch.Tensor, y:torch.Tensor):\n",
    "    x = third_fn2(x) # inline call here?\n",
    "    return y + x\n",
    "\n",
    "_dynamo.reset()\n",
    "main_fn_2 = torch.compile(main_fn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:11:57,040] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing main_fn1\n",
      "[2023-03-16 17:11:57,040] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:10\n",
      "[2023-03-16 17:11:57,041] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL third_fn2 []\n",
      "[2023-03-16 17:11:57,042] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:11:57,042] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:11:57,043] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object third_fn2 at 0x7fe0f3589870, file \"/tmp/ipykernel_171109/3616372052.py\", line 5> \n",
      "   6           0 LOAD_GLOBAL              0 (third_fn1)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               0 (x)\n",
      "\n",
      "  7           8 LOAD_FAST                0 (x)\n",
      "             10 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:11:57,043] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:6\n",
      "[2023-03-16 17:11:57,044] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL third_fn1 []\n",
      "[2023-03-16 17:11:57,045] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:11:57,045] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:11:57,046] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object third_fn1 at 0x7fe0e7c53500, file \"/tmp/ipykernel_171109/3616372052.py\", line 1> \n",
      "   2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_METHOD              0 (sum)\n",
      "              4 CALL_METHOD              0\n",
      "              6 LOAD_CONST               1 (0)\n",
      "              8 COMPARE_OP               4 (>)\n",
      "             10 POP_JUMP_IF_FALSE       16\n",
      "             12 LOAD_FAST                0 (x)\n",
      "             14 JUMP_FORWARD             6 (to 22)\n",
      "        >>   16 LOAD_FAST                0 (x)\n",
      "             18 LOAD_CONST               2 (1)\n",
      "             20 BINARY_ADD\n",
      "        >>   22 STORE_FAST               0 (x)\n",
      "\n",
      "  3          24 LOAD_FAST                0 (x)\n",
      "             26 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:11:57,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:2\n",
      "[2023-03-16 17:11:57,046] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:11:57,047] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable()]\n",
      "[2023-03-16 17:11:57,048] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:11:57,051] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,052] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:11:57,055] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,055] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object third_fn1 at 0x7fe0e7c53500, file \"/tmp/ipykernel_171109/3616372052.py\", line 1>\n",
      "[2023-03-16 17:11:57,056] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 2 nodes\n",
      "[2023-03-16 17:11:57,056] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object third_fn2 at 0x7fe0f3589870, file \"/tmp/ipykernel_171109/3616372052.py\", line 5>\n",
      "[2023-03-16 17:11:57,057] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2023-03-16 17:11:57,057] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 344, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 986, in CALL_FUNCTION\n",
      "    self.call_function(fn, args, {})\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 489, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 259, in call_function\n",
      "    return super().call_function(tx, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 92, in call_function\n",
      "    return tx.inline_user_function_return(\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 525, in inline_user_function_return\n",
      "    result = InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1831, in inline_call\n",
      "    return cls.inline_call_(parent, func, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1887, in inline_call_\n",
      "    tracer.run()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 597, in run\n",
      "    and self.step()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 561, in step\n",
      "    getattr(self, inst.opname)(inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 344, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 986, in CALL_FUNCTION\n",
      "    self.call_function(fn, args, {})\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 489, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 259, in call_function\n",
      "    return super().call_function(tx, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 92, in call_function\n",
      "    return tx.inline_user_function_return(\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 525, in inline_user_function_return\n",
      "    result = InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1831, in inline_call\n",
      "    return cls.inline_call_(parent, func, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1887, in inline_call_\n",
      "    tracer.run()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 597, in run\n",
      "    and self.step()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 561, in step\n",
      "    getattr(self, inst.opname)(inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 329, in inner\n",
      "    unimplemented(f\"generic_jump {typestr(value)}\")\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/exc.py\", line 71, in unimplemented\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: generic_jump TensorVariable()\n",
      "[2023-03-16 17:11:57,058] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2023-03-16 17:11:57,058] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='generic_jump TensorVariable()', user_stack=[<FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 10 in main_fn1>, <FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 6 in third_fn2>, <FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 2 in third_fn1>])\n",
      "[2023-03-16 17:11:57,060] torch._dynamo.symbolic_convert: [INFO] __resume_at_6_19 function\n",
      "[2023-03-16 17:11:57,060] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE main_fn1 /tmp/ipykernel_171109/3616372052.py line 9 \n",
      " 10           0 LOAD_GLOBAL              0 (third_fn2)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               0 (x)\n",
      "\n",
      " 11           8 LOAD_FAST                1 (y)\n",
      "             10 LOAD_FAST                0 (x)\n",
      "             12 BINARY_ADD\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,061] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE main_fn1 /tmp/ipykernel_171109/3616372052.py line 9 \n",
      "  9           0 LOAD_GLOBAL              0 (third_fn2)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "\n",
      " 10           4 CALL_FUNCTION            1\n",
      "              6 LOAD_GLOBAL              1 (__resume_at_6_19)\n",
      "              8 ROT_TWO\n",
      "             10 LOAD_FAST                1 (y)\n",
      "             12 CALL_FUNCTION            2\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,062] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0eef5c950; to 'Tensor' at 0x7fe0f3625db0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0e7c2cea0; to 'Tensor' at 0x7fe0f35375e0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'third_fn2' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:11:57,063] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing third_fn2\n",
      "[2023-03-16 17:11:57,063] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:6\n",
      "[2023-03-16 17:11:57,064] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL third_fn1 []\n",
      "[2023-03-16 17:11:57,064] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserFunctionVariable()]\n",
      "[2023-03-16 17:11:57,065] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserFunctionVariable(), TensorVariable()]\n",
      "[2023-03-16 17:11:57,065] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object third_fn1 at 0x7fe0e7c53500, file \"/tmp/ipykernel_171109/3616372052.py\", line 1> \n",
      "   2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_METHOD              0 (sum)\n",
      "              4 CALL_METHOD              0\n",
      "              6 LOAD_CONST               1 (0)\n",
      "              8 COMPARE_OP               4 (>)\n",
      "             10 POP_JUMP_IF_FALSE       16\n",
      "             12 LOAD_FAST                0 (x)\n",
      "             14 JUMP_FORWARD             6 (to 22)\n",
      "        >>   16 LOAD_FAST                0 (x)\n",
      "             18 LOAD_CONST               2 (1)\n",
      "             20 BINARY_ADD\n",
      "        >>   22 STORE_FAST               0 (x)\n",
      "\n",
      "  3          24 LOAD_FAST                0 (x)\n",
      "             26 RETURN_VALUE\n",
      " \n",
      "\n",
      "[2023-03-16 17:11:57,066] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:2\n",
      "[2023-03-16 17:11:57,066] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:11:57,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable()]\n",
      "[2023-03-16 17:11:57,067] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:11:57,069] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,070] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:11:57,071] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,072] torch._dynamo.symbolic_convert: [DEBUG] FAILED INLINING <code object third_fn1 at 0x7fe0e7c53500, file \"/tmp/ipykernel_171109/3616372052.py\", line 1>\n",
      "[2023-03-16 17:11:57,072] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 2 nodes\n",
      "[2023-03-16 17:11:57,073] torch._dynamo.symbolic_convert: [DEBUG] break_graph_if_unsupported triggered compile\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 344, in wrapper\n",
      "    return inner_fn(self, inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 986, in CALL_FUNCTION\n",
      "    self.call_function(fn, args, {})\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 489, in call_function\n",
      "    self.push(fn.call_function(self, args, kwargs))\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 259, in call_function\n",
      "    return super().call_function(tx, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/functions.py\", line 92, in call_function\n",
      "    return tx.inline_user_function_return(\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 525, in inline_user_function_return\n",
      "    result = InliningInstructionTranslator.inline_call(self, fn, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1831, in inline_call\n",
      "    return cls.inline_call_(parent, func, args, kwargs)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 1887, in inline_call_\n",
      "    tracer.run()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 597, in run\n",
      "    and self.step()\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 561, in step\n",
      "    getattr(self, inst.opname)(inst)\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py\", line 329, in inner\n",
      "    unimplemented(f\"generic_jump {typestr(value)}\")\n",
      "  File \"/home/chunwei/trienv/lib/python3.8/site-packages/torch/_dynamo/exc.py\", line 71, in unimplemented\n",
      "    raise Unsupported(msg)\n",
      "torch._dynamo.exc.Unsupported: generic_jump TensorVariable()\n",
      "[2023-03-16 17:11:57,073] torch._dynamo.output_graph: [DEBUG] restore_graphstate: removed 0 nodes\n",
      "[2023-03-16 17:11:57,073] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='generic_jump TensorVariable()', user_stack=[<FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 6 in third_fn2>, <FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 2 in third_fn1>])\n",
      "[2023-03-16 17:11:57,074] torch._dynamo.symbolic_convert: [INFO] __resume_at_6_20 function\n",
      "[2023-03-16 17:11:57,075] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE third_fn2 /tmp/ipykernel_171109/3616372052.py line 5 \n",
      "  6           0 LOAD_GLOBAL              0 (third_fn1)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               0 (x)\n",
      "\n",
      "  7           8 LOAD_FAST                0 (x)\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,076] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE third_fn2 /tmp/ipykernel_171109/3616372052.py line 5 \n",
      "  5           0 LOAD_GLOBAL              0 (third_fn1)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "\n",
      "  6           4 CALL_FUNCTION            1\n",
      "              6 LOAD_GLOBAL              1 (__resume_at_6_20)\n",
      "              8 ROT_TWO\n",
      "             10 CALL_FUNCTION            1\n",
      "             12 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,077] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0eef5c950; to 'Tensor' at 0x7fe0f3625db0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'third_fn1' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:11:57,078] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing third_fn1\n",
      "[2023-03-16 17:11:57,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:2\n",
      "[2023-03-16 17:11:57,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:11:57,079] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR sum [TensorVariable()]\n",
      "[2023-03-16 17:11:57,080] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [GetAttrVariable(TensorVariable(), sum)]\n",
      "[2023-03-16 17:11:57,081] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 0 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,082] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP > [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:11:57,084] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,084] torch._dynamo.symbolic_convert: [DEBUG] generic_jump triggered compile\n",
      "[2023-03-16 17:11:57,084] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='generic_jump TensorVariable()', user_stack=[<FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 2 in third_fn1>])\n",
      "[2023-03-16 17:11:57,086] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:11:57,095] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 14\n",
      "[2023-03-16 17:11:57,102] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0'), <class 'torch._inductor.codegen.triton.DisableReduction'>, SchedulerNode(name='buf1'), <class 'torch._inductor.codegen.triton.EnableReduction'>]\n",
      "[2023-03-16 17:11:57,104] torch._inductor.scheduler: [DEBUG] remove_buffer('buf0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inline UserFunctionVariable() failed\n",
      "inline UserFunctionVariable() failed\n",
      "__resume_at_6_19:\n",
      " 10           0 LOAD_FAST                0 (___stack0)\n",
      "              2 JUMP_ABSOLUTE           10\n",
      "              4 LOAD_GLOBAL              0 (third_fn2)\n",
      "              6 LOAD_FAST                2 (x)\n",
      "              8 CALL_FUNCTION            1\n",
      "        >>   10 STORE_FAST               2 (x)\n",
      "\n",
      " 11          12 LOAD_FAST                1 (y)\n",
      "             14 LOAD_FAST                2 (x)\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "inline UserFunctionVariable() failed\n",
      "__resume_at_6_20:\n",
      "  6           0 LOAD_FAST                0 (___stack0)\n",
      "              2 JUMP_ABSOLUTE           10\n",
      "              4 LOAD_GLOBAL              0 (third_fn1)\n",
      "              6 LOAD_FAST                1 (x)\n",
      "              8 CALL_FUNCTION            1\n",
      "        >>   10 STORE_FAST               1 (x)\n",
      "\n",
      "  7          12 LOAD_FAST                1 (x)\n",
      "             14 RETURN_VALUE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-16 17:11:57,357] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/hm/chmanlgj6f2724lhiyqptossmekp7giome7gykj4opjf3gqhxrjd.py\n",
      "[2023-03-16 17:11:57,358] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 14\n",
      "[2023-03-16 17:11:57,359] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:11:57,360] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_21 <eval_with_key>.89 opcode         name    target                  args        kwargs\n",
      "-------------  ------  ----------------------  ----------  --------\n",
      "placeholder    x       x                       ()          {}\n",
      "call_method    sum_1   sum                     (x,)        {}\n",
      "call_function  gt      <built-in function gt>  (sum_1, 0)  {}\n",
      "output         output  output                  ((gt,),)    {}\n",
      "\n",
      "[2023-03-16 17:11:57,361] torch._dynamo.symbolic_convert: [INFO] __resume_at_12_22 function\n",
      "[2023-03-16 17:11:57,363] torch._dynamo.symbolic_convert: [INFO] __resume_at_16_23 function\n",
      "[2023-03-16 17:11:57,364] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE third_fn1 /tmp/ipykernel_171109/3616372052.py line 1 \n",
      "  2           0 LOAD_FAST                0 (x)\n",
      "              2 LOAD_METHOD              0 (sum)\n",
      "              4 CALL_METHOD              0\n",
      "              6 LOAD_CONST               1 (0)\n",
      "              8 COMPARE_OP               4 (>)\n",
      "             10 POP_JUMP_IF_FALSE       16\n",
      "             12 LOAD_FAST                0 (x)\n",
      "             14 JUMP_FORWARD             6 (to 22)\n",
      "        >>   16 LOAD_FAST                0 (x)\n",
      "             18 LOAD_CONST               2 (1)\n",
      "             20 BINARY_ADD\n",
      "        >>   22 STORE_FAST               0 (x)\n",
      "\n",
      "  3          24 LOAD_FAST                0 (x)\n",
      "             26 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,364] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE third_fn1 /tmp/ipykernel_171109/3616372052.py line 1 \n",
      "  1           0 LOAD_GLOBAL              1 (__compiled_fn_21)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 POP_JUMP_IF_FALSE       18\n",
      "             10 LOAD_GLOBAL              2 (__resume_at_12_22)\n",
      "             12 LOAD_FAST                0 (x)\n",
      "             14 CALL_FUNCTION            1\n",
      "             16 RETURN_VALUE\n",
      "        >>   18 LOAD_GLOBAL              3 (__resume_at_16_23)\n",
      "             20 LOAD_FAST                0 (x)\n",
      "             22 CALL_FUNCTION            1\n",
      "             24 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,365] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0eef5c950; to 'Tensor' at 0x7fe0f3625db0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:11:57,381] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in third_fn1>\n",
      "[2023-03-16 17:11:57,382] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 18 []\n",
      "[2023-03-16 17:11:57,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:11:57,383] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST 1 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,384] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), ConstantVariable(int)]\n",
      "[2023-03-16 17:11:57,385] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-03-16 17:11:57,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:3\n",
      "[2023-03-16 17:11:57,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:11:57,386] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:11:57,387] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in third_fn1> (RETURN_VALUE)\n",
      "[2023-03-16 17:11:57,387] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:11:57,388] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 3 in <graph break in third_fn1>>])\n",
      "[2023-03-16 17:11:57,389] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:11:57,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 15\n",
      "[2023-03-16 17:11:57,401] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-16 17:11:57,403] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/hc/chcdzptcaykptajjyzr4dt5ladqdytk7a6bfrqcgo3l4hxtuwwwk.py\n",
      "[2023-03-16 17:11:57,404] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 15\n",
      "[2023-03-16 17:11:57,405] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:11:57,405] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_24 <eval_with_key>.95 opcode         name    target                   args       kwargs\n",
      "-------------  ------  -----------------------  ---------  --------\n",
      "placeholder    x       x                        ()         {}\n",
      "call_function  add     <built-in function add>  (x, 1)     {}\n",
      "output         output  output                   ((add,),)  {}\n",
      "\n",
      "[2023-03-16 17:11:57,406] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE <graph break in third_fn1> /tmp/ipykernel_171109/3616372052.py line 2 \n",
      "  2           0 JUMP_ABSOLUTE           18\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       18\n",
      "             14 LOAD_FAST                0 (x)\n",
      "             16 JUMP_FORWARD             6 (to 24)\n",
      "        >>   18 LOAD_FAST                0 (x)\n",
      "             20 LOAD_CONST               2 (1)\n",
      "             22 BINARY_ADD\n",
      "        >>   24 STORE_FAST               0 (x)\n",
      "\n",
      "  3          26 LOAD_FAST                0 (x)\n",
      "             28 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,406] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE <graph break in third_fn1> /tmp/ipykernel_171109/3616372052.py line 2 \n",
      "  2           0 LOAD_GLOBAL              1 (__compiled_fn_24)\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,407] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0eef5c950; to 'Tensor' at 0x7fe0f3625db0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:11:57,409] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in third_fn2>\n",
      "[2023-03-16 17:11:57,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2023-03-16 17:11:57,409] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 10 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-03-16 17:11:57,410] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:7\n",
      "[2023-03-16 17:11:57,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-03-16 17:11:57,411] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:11:57,411] torch._dynamo.convert_frame: [DEBUG] Skipping frame because no content in function call <graph break in third_fn2>                     /tmp/ipykernel_171109/3616372052.py 6\n",
      "[2023-03-16 17:11:57,413] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in main_fn1>\n",
      "[2023-03-16 17:11:57,414] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST ___stack0 []\n",
      "[2023-03-16 17:11:57,414] torch._dynamo.symbolic_convert: [DEBUG] TRACE JUMP_ABSOLUTE 10 [TensorVariable()]\n",
      "[2023-03-16 17:11:57,414] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-03-16 17:11:57,415] torch._dynamo.symbolic_convert: [DEBUG] TRACE starts_line /tmp/ipykernel_171109/3616372052.py:11\n",
      "[2023-03-16 17:11:57,415] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST y []\n",
      "[2023-03-16 17:11:57,415] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [TensorVariable()]\n",
      "[2023-03-16 17:11:57,415] torch._dynamo.symbolic_convert: [DEBUG] TRACE BINARY_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-03-16 17:11:57,417] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-03-16 17:11:57,417] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in main_fn1> (RETURN_VALUE)\n",
      "[2023-03-16 17:11:57,418] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-03-16 17:11:57,418] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /tmp/ipykernel_171109/3616372052.py, line 11 in <graph break in main_fn1>>])\n",
      "[2023-03-16 17:11:57,419] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-16 17:11:57,425] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 16\n",
      "[2023-03-16 17:11:57,429] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-16 17:11:57,431] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/te/cteq4kxxnv36aiy4rys25ixz76splq6qjwiyhwjmxvanntrryf2i.py\n",
      "[2023-03-16 17:11:57,432] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 16\n",
      "[2023-03-16 17:11:57,433] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-16 17:11:57,434] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_25 <eval_with_key>.101 opcode         name     target                   args          kwargs\n",
      "-------------  -------  -----------------------  ------------  --------\n",
      "placeholder    _stack0  _stack0                  ()            {}\n",
      "placeholder    y        y                        ()            {}\n",
      "call_function  add      <built-in function add>  (y, _stack0)  {}\n",
      "output         output   output                   ((add,),)     {}\n",
      "\n",
      "[2023-03-16 17:11:57,434] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE <graph break in main_fn1> /tmp/ipykernel_171109/3616372052.py line 10 \n",
      " 10           0 LOAD_FAST                0 (___stack0)\n",
      "              2 JUMP_ABSOLUTE           10\n",
      "              4 LOAD_GLOBAL              0 (third_fn2)\n",
      "              6 LOAD_FAST                2 (x)\n",
      "              8 CALL_FUNCTION            1\n",
      "        >>   10 STORE_FAST               2 (x)\n",
      "\n",
      " 11          12 LOAD_FAST                1 (y)\n",
      "             14 LOAD_FAST                2 (x)\n",
      "             16 BINARY_ADD\n",
      "             18 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,435] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE <graph break in main_fn1> /tmp/ipykernel_171109/3616372052.py line 10 \n",
      " 10           0 LOAD_GLOBAL              1 (__compiled_fn_25)\n",
      "              2 LOAD_FAST                0 (___stack0)\n",
      "              4 LOAD_FAST                1 (y)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-16 17:11:57,436] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'y' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0e7c2cea0; to 'Tensor' at 0x7fe0f35375e0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local '___stack0' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7fe0e7bb8c70; to 'Tensor' at 0x7fe0ef47dea0>\n",
      "                'guarded_class': <weakref at 0x7fe1b901bf90; to 'torch._C._TensorMeta' at 0x6ab5600 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-16 17:11:57,437] torch._dynamo.eval_frame: [DEBUG] skipping __del__ /home/chunwei/trienv/lib/python3.8/site-packages/torch/multiprocessing/reductions.py\n",
      "[2023-03-16 17:11:57,437] torch._dynamo.eval_frame: [DEBUG] skipping _free_weak_ref /home/chunwei/trienv/lib/python3.8/site-packages/torch/storage.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__resume_at_12_22:\n",
      "  2           0 JUMP_ABSOLUTE           14\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       18\n",
      "        >>   14 LOAD_FAST                0 (x)\n",
      "             16 JUMP_FORWARD             6 (to 24)\n",
      "        >>   18 LOAD_FAST                0 (x)\n",
      "             20 LOAD_CONST               2 (1)\n",
      "             22 BINARY_ADD\n",
      "        >>   24 STORE_FAST               0 (x)\n",
      "\n",
      "  3          26 LOAD_FAST                0 (x)\n",
      "             28 RETURN_VALUE\n",
      "__resume_at_16_23:\n",
      "  2           0 JUMP_ABSOLUTE           18\n",
      "              2 LOAD_FAST                0 (x)\n",
      "              4 LOAD_ATTR                0 (sum)\n",
      "              6 CALL_FUNCTION            0\n",
      "              8 LOAD_CONST               1 (0)\n",
      "             10 COMPARE_OP               4 (>)\n",
      "             12 POP_JUMP_IF_FALSE       18\n",
      "             14 LOAD_FAST                0 (x)\n",
      "             16 JUMP_FORWARD             6 (to 24)\n",
      "        >>   18 LOAD_FAST                0 (x)\n",
      "             20 LOAD_CONST               2 (1)\n",
      "             22 BINARY_ADD\n",
      "        >>   24 STORE_FAST               0 (x)\n",
      "\n",
      "  3          26 LOAD_FAST                0 (x)\n",
      "             28 RETURN_VALUE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7946,  0.4145,  2.0855,  ...,  1.1345,  0.8426,  3.2312],\n",
       "        [ 2.3433,  3.8785, -0.6530,  ..., -0.7912, -1.0573,  1.7959],\n",
       "        [ 0.4305, -0.6292,  1.0336,  ..., -0.2363,  2.5298, -0.5409],\n",
       "        ...,\n",
       "        [ 1.2256,  1.0435,  2.8306,  ...,  2.2719,  1.9207,  1.6777],\n",
       "        [-0.3494,  1.2264,  1.8916,  ..., -0.2846, -2.4267,  0.1767],\n",
       "        [ 1.4636, -1.4870,  0.5384,  ..., -0.3939,  2.6246,  4.3484]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_fn_2(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9be45825b6e11033c42eb29377956e200d55264a3cce733a812afa9001a7e64f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
