{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall torch -y\n",
        "!pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118 --force"
      ],
      "metadata": {
        "id": "QymGt9x98hQl"
      },
      "id": "QymGt9x98hQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "208f3970",
      "metadata": {
        "id": "208f3970"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch._dynamo import optimize\n",
        "from typing import *\n",
        "from torch import _dynamo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the valid backends"
      ],
      "metadata": {
        "id": "MfOUK6SV-zUB"
      },
      "id": "MfOUK6SV-zUB"
    },
    {
      "cell_type": "code",
      "source": [
        "_dynamo.list_backends()"
      ],
      "metadata": {
        "id": "sGlDbGXy-obW",
        "outputId": "166cd045-f20b-4000-c1fc-8be9c986da24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sGlDbGXy-obW",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aot_ts_nvfuser',\n",
              " 'cudagraphs',\n",
              " 'inductor',\n",
              " 'ipex',\n",
              " 'nvprims_nvfuser',\n",
              " 'onnxrt',\n",
              " 'tensorrt',\n",
              " 'tvm']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# optimizer()"
      ],
      "metadata": {
        "id": "kl3vIxtD-3_5"
      },
      "id": "kl3vIxtD-3_5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "A naive example"
      ],
      "metadata": {
        "id": "M96heyoMA-h0"
      },
      "id": "M96heyoMA-h0"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    x = F.relu(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "SyuoQza--7Os"
      },
      "id": "SyuoQza--7Os",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._inductor import config as inductor_config\n",
        "from torch._dynamo import config as dynamo_config\n",
        "\n",
        "inductor_config.debug = True\n",
        "dynamo_config.verbose = True"
      ],
      "metadata": {
        "id": "45WebTphE2dh"
      },
      "id": "45WebTphE2dh",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foo = Net()\n",
        "foo = torch.compile(foo)"
      ],
      "metadata": {
        "id": "TIW9R-cGBDJc"
      },
      "id": "TIW9R-cGBDJc",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "foo"
      ],
      "metadata": {
        "id": "VhuU13T3BL8j",
        "outputId": "ef43be12-4338-48cf-a75c-546a88fea356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VhuU13T3BL8j",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OptimizedModule(\n",
              "  (_orig_mod): Net(\n",
              "    (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When enable `inductor.debug`, it could dump the python code it codegened."
      ],
      "metadata": {
        "id": "kok22EXnHh1y"
      },
      "id": "kok22EXnHh1y"
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn((2, 128))\n",
        "\n",
        "foo(a)"
      ],
      "metadata": {
        "id": "pAvJRtdxD24H",
        "outputId": "1ee1e644-72a2-45e2-b692-8d4cb6097081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pAvJRtdxD24H",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2023-02-23 11:52:14,702] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2\n",
            "[2023-02-23 11:52:14,721] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "from ctypes import c_void_p, c_long\n",
            "import torch\n",
            "import math\n",
            "import random\n",
            "from torch import empty_strided, as_strided, device\n",
            "from torch._inductor.codecache import AsyncCompile\n",
            "from torch._inductor.select_algorithm import extern_kernels\n",
            "\n",
            "aten = torch.ops.aten\n",
            "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
            "async_compile = AsyncCompile()\n",
            "\n",
            "import triton\n",
            "import triton.language as tl\n",
            "from torch._inductor.triton_ops.autotune import grid\n",
            "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
            "\n",
            "\n",
            "kernel_cpp_0 = async_compile.cpp('''\n",
            "#include \"/tmp/torchinductor_root/zt/cztcl2vp5yqlnhofzpqfficjcxgyict6e3xhfdd7sdbkipp4p44x.h\"\n",
            "extern \"C\" void kernel(float* __restrict__ in_out_ptr0,\n",
            "                       bool* __restrict__ out_ptr0)\n",
            "{\n",
            "    {\n",
            "        #pragma GCC ivdep\n",
            "        for(long i0=0; i0<20; i0+=1)\n",
            "        {\n",
            "            auto tmp0 = in_out_ptr0[i0];\n",
            "            auto tmp1 = tmp0 * (tmp0>0);\n",
            "            auto tmp2 = static_cast<float>(0);\n",
            "            auto tmp3 = tmp1 <= tmp2;\n",
            "            in_out_ptr0[i0] = tmp1;\n",
            "            out_ptr0[i0] = tmp3;\n",
            "        }\n",
            "    }\n",
            "}\n",
            "''')\n",
            "\n",
            "\n",
            "async_compile.wait(globals())\n",
            "del async_compile\n",
            "\n",
            "def call(args):\n",
            "    primals_1, primals_2, primals_3 = args\n",
            "    args.clear()\n",
            "    buf0 = empty_strided((2, 10), (10, 1), device='cpu', dtype=torch.float32)\n",
            "    extern_kernels.addmm(primals_2, primals_3, as_strided(primals_1, (128, 10), (1, 128)), alpha=1, beta=1, out=buf0)\n",
            "    del primals_1\n",
            "    del primals_2\n",
            "    buf1 = buf0; del buf0  # reuse\n",
            "    buf2 = empty_strided((2, 10), (10, 1), device='cpu', dtype=torch.bool)\n",
            "    kernel_cpp_0(c_void_p(buf1.data_ptr()), c_void_p(buf2.data_ptr()))\n",
            "    return (buf1, primals_3, buf2, )\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    from torch._dynamo.testing import rand_strided\n",
            "    from torch._inductor.utils import print_performance\n",
            "    primals_1 = rand_strided((10, 128), (128, 1), device='cpu', dtype=torch.float32)\n",
            "    primals_2 = rand_strided((10, ), (1, ), device='cpu', dtype=torch.float32)\n",
            "    primals_3 = rand_strided((2, 128), (128, 1), device='cpu', dtype=torch.float32)\n",
            "    print_performance(lambda: call([primals_1, primals_2, primals_3]))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py:1251: UserWarning: Your compiler for AOTAutograd is returning a a function that doesn't take boxed arguments. Please wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. See https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.4226, 0.3017, 0.0000, 0.0000, 0.5286, 0.5539, 0.2217,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.8061, 0.0921, 0.0000, 0.0000, -0.0000, 0.3405, 0.4165,\n",
              "         -0.0000]], grad_fn=<CompiledFunctionBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "16d974c3",
      "metadata": {
        "id": "16d974c3"
      },
      "outputs": [],
      "source": [
        "def my_compiler( \n",
        "        gm: torch.fx.GraphModule,\n",
        "        example_inputs: List[torch.Tensor]):\n",
        "    print(\"my_compiler() called with FX graph:\")\n",
        "    gm.graph.print_tabular(); print()\n",
        "    #print(f\"code: {gm.graph.python_code()}\")\n",
        "    return gm.forward  # python callable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1171f13e",
      "metadata": {
        "id": "1171f13e"
      },
      "outputs": [],
      "source": [
        "def toy_example(a, b):\n",
        "    x = a / (torch.abs(a) + 1)\n",
        "    if b.sum() < 0:\n",
        "        b = b * -1\n",
        "    return x * b"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EzOsIbXxDwo0"
      },
      "id": "EzOsIbXxDwo0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b1d4c39",
      "metadata": {
        "id": "8b1d4c39"
      },
      "outputs": [],
      "source": [
        "torch._dynamo.reset()\n",
        "toy_example = optimize(my_compiler)(toy_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "702c025a",
      "metadata": {
        "id": "702c025a",
        "outputId": "d566255f-f1b7-4c4a-862c-0f1b3b4fd4d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Iteration 0\n",
            "my_compiler() called with FX graph:\n",
            "opcode         name     target                                                  args              kwargs\n",
            "-------------  -------  ------------------------------------------------------  ----------------  --------\n",
            "placeholder    a        a                                                       ()                {}\n",
            "placeholder    b        b                                                       ()                {}\n",
            "call_function  abs_1    <built-in method abs of type object at 0x7f21751e6b80>  (a,)              {}\n",
            "call_function  add      <built-in function add>                                 (abs_1, 1)        {}\n",
            "call_function  truediv  <built-in function truediv>                             (a, add)          {}\n",
            "call_method    sum_1    sum                                                     (b,)              {}\n",
            "call_function  lt       <built-in function lt>                                  (sum_1, 0)        {}\n",
            "output         output   output                                                  ((truediv, lt),)  {}\n",
            "\n",
            "my_compiler() called with FX graph:\n",
            "opcode         name    target                   args       kwargs\n",
            "-------------  ------  -----------------------  ---------  --------\n",
            "placeholder    b       b                        ()         {}\n",
            "placeholder    x       x                        ()         {}\n",
            "call_function  mul     <built-in function mul>  (x, b)     {}\n",
            "output         output  output                   ((mul,),)  {}\n",
            "\n",
            ">>> Iteration 1\n",
            "my_compiler() called with FX graph:\n",
            "opcode         name    target                   args         kwargs\n",
            "-------------  ------  -----------------------  -----------  --------\n",
            "placeholder    b       b                        ()           {}\n",
            "placeholder    x       x                        ()           {}\n",
            "call_function  mul     <built-in function mul>  (b, -1)      {}\n",
            "call_function  mul_1   <built-in function mul>  (x, mul)     {}\n",
            "output         output  output                   ((mul_1,),)  {}\n",
            "\n",
            ">>> Iteration 2\n",
            ">>> Iteration 3\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor(data=[1. for i in range(6)]).reshape((2,3))\n",
        "a_neg = torch.tensor(data=[-1. for i in range(6)]).reshape((2,3))\n",
        "b = torch.randn((2, 3))\n",
        "for i in range(4):\n",
        "    print(f\">>> Iteration {i}\")\n",
        "    toy_example(a, b * (-1) ** i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "711089b6",
      "metadata": {
        "id": "711089b6"
      },
      "outputs": [],
      "source": [
        "func = lambda x, y : -y if x.sum() < 0 else y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf8f1a3",
      "metadata": {
        "id": "fbf8f1a3"
      },
      "outputs": [],
      "source": [
        "torch._dynamo.reset()\n",
        "func = optimize(my_compiler)(func)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20c41f34",
      "metadata": {
        "id": "20c41f34"
      },
      "source": [
        "## The compilation cache is reused"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "914b0515",
      "metadata": {
        "id": "914b0515",
        "outputId": "18e971f2-8cde-4d52-9aad-36a2d2bd812b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0:\n",
            "my_compiler() called with FX graph:\n",
            "opcode         name    target                  args        kwargs\n",
            "-------------  ------  ----------------------  ----------  --------\n",
            "placeholder    x       x                       ()          {}\n",
            "call_method    sum_1   sum                     (x,)        {}\n",
            "call_function  lt      <built-in function lt>  (sum_1, 0)  {}\n",
            "output         output  output                  ((lt,),)    {}\n",
            "\n",
            "my_compiler() called with FX graph:\n",
            "opcode         name    target                   args       kwargs\n",
            "-------------  ------  -----------------------  ---------  --------\n",
            "placeholder    y       y                        ()         {}\n",
            "call_function  neg     <built-in function neg>  (y,)       {}\n",
            "output         output  output                   ((neg,),)  {}\n",
            "\n",
            "Iteration 1:\n",
            "Iteration 2:\n",
            "Iteration 3:\n",
            "Iteration 4:\n",
            "Iteration 5:\n"
          ]
        }
      ],
      "source": [
        "for i in range(6):\n",
        "    print(f\"Iteration {i}:\")\n",
        "    func(a, b)\n",
        "    func(a_neg, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1a562b",
      "metadata": {
        "id": "8d1a562b"
      },
      "source": [
        "## Non-torch function call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "478f5710",
      "metadata": {
        "id": "478f5710"
      },
      "outputs": [],
      "source": [
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5691731",
      "metadata": {
        "id": "f5691731"
      },
      "outputs": [],
      "source": [
        "def draw_example(a, b):\n",
        "    import numpy as np\n",
        "    aa = np.randn((2,3))\n",
        "    sum = a + b\n",
        "    return sum.numpy() + aa\n",
        "    return aa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a45ea114",
      "metadata": {
        "id": "a45ea114"
      },
      "outputs": [],
      "source": [
        "torch._dynamo.reset()\n",
        "torch._dynamo.config.verbose=True\n",
        "func = optimize(my_compiler)(draw_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e73bc9",
      "metadata": {
        "id": "45e73bc9",
        "outputId": "1fecdb66-bc92-44ac-f1da-fe9373c56a74"
      },
      "outputs": [
        {
          "ename": "InternalTorchDynamoError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:324\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m     out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     orig_code_map[out_code] \u001b[38;5;241m=\u001b[39m code\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/bytecode_transformation.py:445\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m    443\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m--> 445\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:311\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    299\u001b[0m tracer \u001b[38;5;241m=\u001b[39m InstructionTranslator(\n\u001b[1;32m    300\u001b[0m     instructions,\n\u001b[1;32m    301\u001b[0m     code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated_closure_cell_contents,\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m output \u001b[38;5;241m=\u001b[39m tracer\u001b[38;5;241m.\u001b[39moutput\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1738\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1737\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo start tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1738\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:588\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m ):\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:552\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m     unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 552\u001b[0m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/symbolic_convert.py:1042\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.LOAD_ATTR\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m   1041\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m-> 1042\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mBuiltinVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConstantVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush(result)\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/builtin.py:566\u001b[0m, in \u001b[0;36mBuiltinVariable.call_function\u001b[0;34m(self, tx, args, kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/variables/builtin.py:971\u001b[0m, in \u001b[0;36mBuiltinVariable.call_getattr\u001b[0;34m(self, tx, obj, name_var, default)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (PythonModuleVariable, DummyModule)):\n\u001b[0;32m--> 971\u001b[0m     member \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mreplay_record_enabled:\n",
            "\u001b[0;31mKeyError\u001b[0m: randn\n\nfrom user code:\n   File \"/tmp/ipykernel_2032177/1399088902.py\", line 3, in draw_example\n    aa = np.randn((2,3))\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInternalTorchDynamoError\u001b[0m                  Traceback (most recent call last)",
            "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:337\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_size)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(frame, cache_size, hooks)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:404\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    402\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43minner_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:104\u001b[0m, in \u001b[0;36mwrap_convert_context.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mgraph_module\u001b[38;5;241m.\u001b[39m_forward_from_src \u001b[38;5;241m=\u001b[39m fx_forward_from_src_skip_result\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_set_grad_enabled(prior_grad_mode)\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:262\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m initial_grad_state\n\u001b[1;32m    260\u001b[0m initial_grad_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     compilation_metrics[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
            "File \u001b[0;32m~/trienv/lib/python3.8/site-packages/torch/_dynamo/convert_frame.py:394\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    393\u001b[0m     exception_handler(e, code, frame)\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InternalTorchDynamoError() \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[0;31mInternalTorchDynamoError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "func(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8e5476a",
      "metadata": {
        "id": "e8e5476a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}