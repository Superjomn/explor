{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode OptimizedModule(\n",
      "  (_orig_mod): Net(\n",
      "    (conv1): ARMAConv(1433, 16, num_stacks=3, num_layers=2)\n",
      "    (conv2): ARMAConv(16, 7, num_stacks=3, num_layers=2)\n",
      "  )\n",
      ")\n",
      "data tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from arma import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import _dynamo\n",
    "from torch import _inductor\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dynamo.config.log_level = logging.INFO\n",
    "_dynamo.config.output_code = True\n",
    "_inductor.config.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-09 10:31:38,074] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n",
      "[2023-03-09 10:31:38,132] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:40,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 0\n",
      "[2023-03-09 10:31:40,049] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-03-09 10:31:40,079] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:40,135] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/jm/cjm2qvvi6wkcsdgcuhgbsimijokfanwzhajcgrl34yow5rsnzwea.py\n",
      "[2023-03-09 10:31:40,136] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 0\n",
      "[2023-03-09 10:31:40,137] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:40,140] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_0 <eval_with_key>.5 opcode         name            target                                       args                  kwargs\n",
      "-------------  --------------  -------------------------------------------  --------------------  ------------------\n",
      "placeholder    x               x                                            ()                    {}\n",
      "call_function  lowmem_dropout  <function lowmem_dropout at 0x7f359c059ca0>  (x,)                  {'training': True}\n",
      "output         output          output                                       ((lowmem_dropout,),)  {}\n",
      "\n",
      "[2023-03-09 10:31:40,141] torch._dynamo.symbolic_convert: [INFO] __resume_at_30_1 function\n",
      "[2023-03-09 10:31:40,143] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE forward /home/chunwei/project/explor/torch/arma.py line 50 \n",
      " 51           0 LOAD_GLOBAL              0 (F)\n",
      "              2 LOAD_ATTR                1 (dropout)\n",
      "              4 LOAD_FAST                1 (x)\n",
      "              6 LOAD_FAST                0 (self)\n",
      "              8 LOAD_ATTR                2 (training)\n",
      "             10 LOAD_CONST               1 (('training',))\n",
      "             12 CALL_FUNCTION_KW         2\n",
      "             14 STORE_FAST               1 (x)\n",
      "\n",
      " 52          16 LOAD_GLOBAL              0 (F)\n",
      "             18 LOAD_METHOD              3 (relu)\n",
      "             20 LOAD_FAST                0 (self)\n",
      "             22 LOAD_METHOD              4 (conv1)\n",
      "             24 LOAD_FAST                1 (x)\n",
      "             26 LOAD_FAST                2 (edge_index)\n",
      "             28 CALL_METHOD              2\n",
      "             30 CALL_METHOD              1\n",
      "             32 STORE_FAST               1 (x)\n",
      "\n",
      " 53          34 LOAD_GLOBAL              0 (F)\n",
      "             36 LOAD_ATTR                1 (dropout)\n",
      "             38 LOAD_FAST                1 (x)\n",
      "             40 LOAD_FAST                0 (self)\n",
      "             42 LOAD_ATTR                2 (training)\n",
      "             44 LOAD_CONST               1 (('training',))\n",
      "             46 CALL_FUNCTION_KW         2\n",
      "             48 STORE_FAST               1 (x)\n",
      "\n",
      " 54          50 LOAD_FAST                0 (self)\n",
      "             52 LOAD_METHOD              5 (conv2)\n",
      "             54 LOAD_FAST                1 (x)\n",
      "             56 LOAD_FAST                2 (edge_index)\n",
      "             58 CALL_METHOD              2\n",
      "             60 STORE_FAST               1 (x)\n",
      "\n",
      " 55          62 LOAD_GLOBAL              0 (F)\n",
      "             64 LOAD_ATTR                6 (log_softmax)\n",
      "             66 LOAD_FAST                1 (x)\n",
      "             68 LOAD_CONST               2 (1)\n",
      "             70 LOAD_CONST               3 (('dim',))\n",
      "             72 CALL_FUNCTION_KW         2\n",
      "             74 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:40,143] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE forward /home/chunwei/project/explor/torch/arma.py line 50 \n",
      " 50           0 LOAD_GLOBAL             13 (__compiled_fn_0)\n",
      "              2 LOAD_FAST                1 (x)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               3 (___graph_out_0)\n",
      "              8 LOAD_GLOBAL              0 (F)\n",
      "             10 LOAD_ATTR                3 (relu)\n",
      "             12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                4 (conv1)\n",
      "             16 LOAD_FAST                3 (___graph_out_0)\n",
      "             18 LOAD_CONST               4 (0)\n",
      "             20 BINARY_SUBSCR\n",
      "             22 LOAD_FAST                2 (edge_index)\n",
      "\n",
      " 52          24 CALL_FUNCTION            2\n",
      "             26 LOAD_GLOBAL             14 (__resume_at_30_1)\n",
      "             28 ROT_THREE\n",
      "             30 LOAD_FAST                0 (self)\n",
      "             32 LOAD_FAST                2 (edge_index)\n",
      "             34 CALL_FUNCTION            4\n",
      "             36 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:40,243] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36acbb88b0; to 'Tensor' at 0x7f3637ffd720>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 139870845923040)'],\n",
      "                'obj_weakref': <weakref at 0x7f36aca5bf40; to 'Net' at 0x7f363815eee0>\n",
      "                'guarded_class': <weakref at 0x7f35b43ecc20; to 'type' at 0x7f1e410 (Net)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'F' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.conv1' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.training' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:40,247] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_fx_inner begin:\n",
      "class <lambda>(torch.nn.Module):\n",
      "    def forward(self, arg0_1: f32[2708, 1433]):\n",
      "        # No stacktrace found for following nodes\n",
      "        philox_seed_like: i32[] = torch.ops.prims.philox_seed_like.default(arg0_1)\n",
      "        philox_rand_like: f32[2708, 1433] = torch.ops.prims.philox_rand_like.default(arg0_1, philox_seed_like, 0);  philox_seed_like = None\n",
      "        gt: b8[2708, 1433] = torch.ops.aten.gt.Scalar(philox_rand_like, 0.5);  philox_rand_like = None\n",
      "        convert_element_type: f32[2708, 1433] = torch.ops.prims.convert_element_type.default(gt, torch.float32);  gt = None\n",
      "        mul: f32[2708, 1433] = torch.ops.aten.mul.Tensor(convert_element_type, arg0_1);  convert_element_type = arg0_1 = None\n",
      "        mul_1: f32[2708, 1433] = torch.ops.aten.mul.Tensor(mul, 2.0);  mul = None\n",
      "        return (mul_1,)\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out RandSeedBuffer(name='seed_cuda_0', layout=FixedLayout('cuda', torch.int64, size=[], stride=[]))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 1433 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[2708, 1433],\n",
      "    origins={philox_rand_like, philox_seed_like, arg0_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.bool,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 1433 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    return tmp4\n",
      "    ,\n",
      "    ranges=[2708, 1433],\n",
      "    origins={gt, philox_rand_like, philox_seed_like, arg0_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 1433 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[2708, 1433],\n",
      "    origins={gt, convert_element_type, philox_rand_like, philox_seed_like, arg0_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 1433 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(arg0_1, i1 + 1433 * i0)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    return tmp7\n",
      "    ,\n",
      "    ranges=[2708, 1433],\n",
      "    origins={gt, mul, convert_element_type, philox_rand_like, philox_seed_like, arg0_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 1433 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(arg0_1, i1 + 1433 * i0)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = constant(2.0, torch.float32)\n",
      "    tmp9 = tmp7 * tmp8\n",
      "    return tmp9\n",
      "    ,\n",
      "    ranges=[2708, 1433],\n",
      "    origins={gt, mul_1, mul, convert_element_type, philox_rand_like, philox_seed_like, arg0_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "seed_cuda_0 = None  # 12bf87036c8e625335a9db42dcf50de0c1ec952294785adced537424d5733e17\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[4194304], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(seed0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 3880564\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0_load = tl.load(seed0 + (0))\n",
      "    tmp0 = tl.broadcast_to(tmp0_load, [XBLOCK])\n",
      "    tmp6 = tl.load(in_ptr1 + (x0), xmask)\n",
      "    tmp1 = x0\n",
      "    tmp2 = tl.rand(tmp0, tmp1)\n",
      "    tmp3 = 0.5\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = tmp4.to(tl.float32)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = 2.0\n",
      "    tmp9 = tmp7 * tmp8\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp9, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    arg0_1, = args\n",
      "    args.clear()\n",
      "    torch.randint(2**31, size=(), dtype=torch.int64, out=seed_cuda_0)\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((2708, 1433), (1433, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(seed_cuda_0, arg0_1, buf0, 3880564, grid=grid(3880564), stream=stream0)\n",
      "        del arg0_1\n",
      "        return (buf0, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    seed_cuda_0 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "    arg0_1 = rand_strided((2708, 1433), (1433, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([arg0_1]))\n",
      "\n",
      "inductor code end\n",
      "__resume_at_30_1:\n",
      " 52           0 LOAD_FAST                0 (___stack0)\n",
      "              2 LOAD_FAST                1 (___stack1)\n",
      "              4 JUMP_ABSOLUTE           36\n",
      "              6 LOAD_GLOBAL              0 (F)\n",
      "              8 LOAD_ATTR                1 (dropout)\n",
      "             10 LOAD_FAST                4 (x)\n",
      "             12 LOAD_FAST                2 (self)\n",
      "             14 LOAD_ATTR                2 (training)\n",
      "             16 LOAD_CONST               1 (('training',))\n",
      "             18 CALL_FUNCTION_KW         2\n",
      "             20 STORE_FAST               4 (x)\n",
      "             22 LOAD_GLOBAL              0 (F)\n",
      "             24 LOAD_ATTR                3 (relu)\n",
      "             26 LOAD_FAST                2 (self)\n",
      "             28 LOAD_ATTR                4 (conv1)\n",
      "             30 LOAD_FAST                4 (x)\n",
      "             32 LOAD_FAST                3 (edge_index)\n",
      "             34 CALL_FUNCTION            2\n",
      "        >>   36 CALL_FUNCTION            1\n",
      "             38 STORE_FAST               4 (x)\n",
      "\n",
      " 53          40 LOAD_GLOBAL              0 (F)\n",
      "             42 LOAD_ATTR                1 (dropout)\n",
      "             44 LOAD_FAST                4 (x)\n",
      "             46 LOAD_FAST                2 (self)\n",
      "             48 LOAD_ATTR                2 (training)\n",
      "             50 LOAD_CONST               1 (('training',))\n",
      "             52 CALL_FUNCTION_KW         2\n",
      "             54 STORE_FAST               4 (x)\n",
      "\n",
      " 54          56 LOAD_FAST                2 (self)\n",
      "             58 LOAD_ATTR                5 (conv2)\n",
      "             60 LOAD_FAST                4 (x)\n",
      "             62 LOAD_FAST                3 (edge_index)\n",
      "             64 CALL_FUNCTION            2\n",
      "             66 STORE_FAST               4 (x)\n",
      "\n",
      " 55          68 LOAD_GLOBAL              0 (F)\n",
      "             70 LOAD_ATTR                6 (log_softmax)\n",
      "             72 LOAD_FAST                4 (x)\n",
      "             74 LOAD_CONST               2 (1)\n",
      "             76 LOAD_CONST               3 (('dim',))\n",
      "             78 CALL_FUNCTION_KW         2\n",
      "             80 RETURN_VALUE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-09 10:31:40,299] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing gcn_norm\n",
      "[2023-03-09 10:31:40,313] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing gcn_norm (RETURN_VALUE)\n",
      "[2023-03-09 10:31:40,314] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:40,338] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 1\n",
      "[2023-03-09 10:31:40,352] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:40,354] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf1')]\n",
      "[2023-03-09 10:31:40,356] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf2')]\n",
      "[2023-03-09 10:31:40,397] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/pt/cptx3ghvq2323qxfk7p54xm6mcekxzq2geoychiqih74xmp2ji34.py\n",
      "[2023-03-09 10:31:40,397] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 1\n",
      "[2023-03-09 10:31:40,398] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:40,400] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_2 <eval_with_key>.11 opcode         name          target                                                    args                      kwargs\n",
      "-------------  ------------  --------------------------------------------------------  ------------------------  ----------------------------------------------------------------\n",
      "placeholder    edge_index    edge_index                                                ()                        {}\n",
      "call_function  ones          <built-in method ones of type object at 0x7f371c7edba0>   ((10556,),)               {'dtype': torch.float32, 'device': device(type='cuda', index=0)}\n",
      "call_function  getitem       <built-in function getitem>                               (edge_index, 0)           {}\n",
      "call_function  getitem_1     <built-in function getitem>                               (edge_index, 1)           {}\n",
      "call_method    expand        expand                                                    (getitem_1, (10556,))     {}\n",
      "call_function  zeros         <built-in method zeros of type object at 0x7f371c7edba0>  ([2708],)                 {'dtype': torch.float32, 'device': device(type='cuda', index=0)}\n",
      "call_method    scatter_add_  scatter_add_                                              (zeros, 0, expand, ones)  {}\n",
      "call_method    pow_          pow_                                                      (scatter_add_, -0.5)      {}\n",
      "call_function  eq            <built-in function eq>                                    (pow_, inf)               {}\n",
      "call_method    masked_fill_  masked_fill_                                              (pow_, eq, 0)             {}\n",
      "call_function  getitem_2     <built-in function getitem>                               (pow_, getitem)           {}\n",
      "call_function  mul           <built-in function mul>                                   (getitem_2, ones)         {}\n",
      "call_function  getitem_3     <built-in function getitem>                               (pow_, getitem_1)         {}\n",
      "call_function  mul_1         <built-in function mul>                                   (mul, getitem_3)          {}\n",
      "output         output        output                                                    ((mul_1,),)               {}\n",
      "\n",
      "[2023-03-09 10:31:40,401] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE gcn_norm /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py line 33 \n",
      " 36           0 LOAD_FAST                3 (improved)\n",
      "              2 POP_JUMP_IF_FALSE        8\n",
      "              4 LOAD_CONST               1 (2.0)\n",
      "              6 JUMP_FORWARD             2 (to 10)\n",
      "        >>    8 LOAD_CONST               2 (1.0)\n",
      "        >>   10 STORE_FAST               7 (fill_value)\n",
      "\n",
      " 38          12 LOAD_GLOBAL              0 (isinstance)\n",
      "             14 LOAD_FAST                0 (edge_index)\n",
      "             16 LOAD_GLOBAL              1 (SparseTensor)\n",
      "             18 CALL_FUNCTION            2\n",
      "             20 POP_JUMP_IF_FALSE      156\n",
      "\n",
      " 39          22 LOAD_FAST                5 (flow)\n",
      "             24 LOAD_CONST               3 (('source_to_target',))\n",
      "             26 COMPARE_OP               6 (in)\n",
      "             28 POP_JUMP_IF_TRUE        34\n",
      "             30 LOAD_GLOBAL              2 (AssertionError)\n",
      "             32 RAISE_VARARGS            1\n",
      "\n",
      " 40     >>   34 LOAD_FAST                0 (edge_index)\n",
      "             36 STORE_FAST               8 (adj_t)\n",
      "\n",
      " 41          38 LOAD_FAST                8 (adj_t)\n",
      "             40 LOAD_METHOD              3 (has_value)\n",
      "             42 CALL_METHOD              0\n",
      "             44 POP_JUMP_IF_TRUE        60\n",
      "\n",
      " 42          46 LOAD_FAST                8 (adj_t)\n",
      "             48 LOAD_ATTR                4 (fill_value)\n",
      "             50 LOAD_CONST               2 (1.0)\n",
      "             52 LOAD_FAST                6 (dtype)\n",
      "             54 LOAD_CONST               4 (('dtype',))\n",
      "             56 CALL_FUNCTION_KW         2\n",
      "             58 STORE_FAST               8 (adj_t)\n",
      "\n",
      " 43     >>   60 LOAD_FAST                4 (add_self_loops)\n",
      "             62 POP_JUMP_IF_FALSE       74\n",
      "\n",
      " 44          64 LOAD_GLOBAL              5 (fill_diag)\n",
      "             66 LOAD_FAST                8 (adj_t)\n",
      "             68 LOAD_FAST                7 (fill_value)\n",
      "             70 CALL_FUNCTION            2\n",
      "             72 STORE_FAST               8 (adj_t)\n",
      "\n",
      " 45     >>   74 LOAD_GLOBAL              6 (sparsesum)\n",
      "             76 LOAD_FAST                8 (adj_t)\n",
      "             78 LOAD_CONST               5 (1)\n",
      "             80 LOAD_CONST               6 (('dim',))\n",
      "             82 CALL_FUNCTION_KW         2\n",
      "             84 STORE_FAST               9 (deg)\n",
      "\n",
      " 46          86 LOAD_FAST                9 (deg)\n",
      "             88 LOAD_METHOD              7 (pow_)\n",
      "             90 LOAD_CONST               7 (-0.5)\n",
      "             92 CALL_METHOD              1\n",
      "             94 STORE_FAST              10 (deg_inv_sqrt)\n",
      "\n",
      " 47          96 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "             98 LOAD_METHOD              8 (masked_fill_)\n",
      "            100 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "            102 LOAD_GLOBAL              9 (float)\n",
      "            104 LOAD_CONST               8 ('inf')\n",
      "            106 CALL_FUNCTION            1\n",
      "            108 COMPARE_OP               2 (==)\n",
      "            110 LOAD_CONST               9 (0.0)\n",
      "            112 CALL_METHOD              2\n",
      "            114 POP_TOP\n",
      "\n",
      " 48         116 LOAD_GLOBAL             10 (mul)\n",
      "            118 LOAD_FAST                8 (adj_t)\n",
      "            120 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "            122 LOAD_METHOD             11 (view)\n",
      "            124 LOAD_CONST              10 (-1)\n",
      "            126 LOAD_CONST               5 (1)\n",
      "            128 CALL_METHOD              2\n",
      "            130 CALL_FUNCTION            2\n",
      "            132 STORE_FAST               8 (adj_t)\n",
      "\n",
      " 49         134 LOAD_GLOBAL             10 (mul)\n",
      "            136 LOAD_FAST                8 (adj_t)\n",
      "            138 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "            140 LOAD_METHOD             11 (view)\n",
      "            142 LOAD_CONST               5 (1)\n",
      "            144 LOAD_CONST              10 (-1)\n",
      "            146 CALL_METHOD              2\n",
      "            148 CALL_FUNCTION            2\n",
      "            150 STORE_FAST               8 (adj_t)\n",
      "\n",
      " 50         152 LOAD_FAST                8 (adj_t)\n",
      "            154 RETURN_VALUE\n",
      "\n",
      " 53     >>  156 LOAD_FAST                5 (flow)\n",
      "            158 LOAD_CONST              11 (('source_to_target', 'target_to_source'))\n",
      "            160 COMPARE_OP               6 (in)\n",
      "            162 POP_JUMP_IF_TRUE       168\n",
      "            164 LOAD_GLOBAL              2 (AssertionError)\n",
      "            166 RAISE_VARARGS            1\n",
      "\n",
      " 54     >>  168 LOAD_GLOBAL             12 (maybe_num_nodes)\n",
      "            170 LOAD_FAST                0 (edge_index)\n",
      "            172 LOAD_FAST                2 (num_nodes)\n",
      "            174 CALL_FUNCTION            2\n",
      "            176 STORE_FAST               2 (num_nodes)\n",
      "\n",
      " 56         178 LOAD_FAST                1 (edge_weight)\n",
      "            180 LOAD_CONST               0 (None)\n",
      "            182 COMPARE_OP               8 (is)\n",
      "            184 POP_JUMP_IF_FALSE      212\n",
      "\n",
      " 57         186 LOAD_GLOBAL             13 (torch)\n",
      "            188 LOAD_ATTR               14 (ones)\n",
      "            190 LOAD_FAST                0 (edge_index)\n",
      "            192 LOAD_METHOD             15 (size)\n",
      "            194 LOAD_CONST               5 (1)\n",
      "            196 CALL_METHOD              1\n",
      "            198 BUILD_TUPLE              1\n",
      "            200 LOAD_FAST                6 (dtype)\n",
      "\n",
      " 58         202 LOAD_FAST                0 (edge_index)\n",
      "            204 LOAD_ATTR               16 (device)\n",
      "\n",
      " 57         206 LOAD_CONST              12 (('dtype', 'device'))\n",
      "            208 CALL_FUNCTION_KW         3\n",
      "            210 STORE_FAST               1 (edge_weight)\n",
      "\n",
      " 60     >>  212 LOAD_FAST                4 (add_self_loops)\n",
      "            214 POP_JUMP_IF_FALSE      250\n",
      "\n",
      " 61         216 LOAD_GLOBAL             17 (add_remaining_self_loops)\n",
      "\n",
      " 62         218 LOAD_FAST                0 (edge_index)\n",
      "            220 LOAD_FAST                1 (edge_weight)\n",
      "            222 LOAD_FAST                7 (fill_value)\n",
      "            224 LOAD_FAST                2 (num_nodes)\n",
      "\n",
      " 61         226 CALL_FUNCTION            4\n",
      "            228 UNPACK_SEQUENCE          2\n",
      "            230 STORE_FAST               0 (edge_index)\n",
      "            232 STORE_FAST              11 (tmp_edge_weight)\n",
      "\n",
      " 63         234 LOAD_FAST               11 (tmp_edge_weight)\n",
      "            236 LOAD_CONST               0 (None)\n",
      "            238 COMPARE_OP               9 (is not)\n",
      "            240 POP_JUMP_IF_TRUE       246\n",
      "            242 LOAD_GLOBAL              2 (AssertionError)\n",
      "            244 RAISE_VARARGS            1\n",
      "\n",
      " 64     >>  246 LOAD_FAST               11 (tmp_edge_weight)\n",
      "            248 STORE_FAST               1 (edge_weight)\n",
      "\n",
      " 66     >>  250 LOAD_FAST                0 (edge_index)\n",
      "            252 LOAD_CONST              13 (0)\n",
      "            254 BINARY_SUBSCR\n",
      "            256 LOAD_FAST                0 (edge_index)\n",
      "            258 LOAD_CONST               5 (1)\n",
      "            260 BINARY_SUBSCR\n",
      "            262 ROT_TWO\n",
      "            264 STORE_FAST              12 (row)\n",
      "            266 STORE_FAST              13 (col)\n",
      "\n",
      " 67         268 LOAD_FAST                5 (flow)\n",
      "            270 LOAD_CONST              14 ('source_to_target')\n",
      "            272 COMPARE_OP               2 (==)\n",
      "            274 EXTENDED_ARG             1\n",
      "            276 POP_JUMP_IF_FALSE      282\n",
      "            278 LOAD_FAST               13 (col)\n",
      "            280 JUMP_FORWARD             2 (to 284)\n",
      "        >>  282 LOAD_FAST               12 (row)\n",
      "        >>  284 STORE_FAST              14 (idx)\n",
      "\n",
      " 68         286 LOAD_GLOBAL             18 (scatter_add)\n",
      "            288 LOAD_FAST                1 (edge_weight)\n",
      "            290 LOAD_FAST               14 (idx)\n",
      "            292 LOAD_CONST              13 (0)\n",
      "            294 LOAD_FAST                2 (num_nodes)\n",
      "            296 LOAD_CONST              15 (('dim', 'dim_size'))\n",
      "            298 CALL_FUNCTION_KW         4\n",
      "            300 STORE_FAST               9 (deg)\n",
      "\n",
      " 69         302 LOAD_FAST                9 (deg)\n",
      "            304 LOAD_METHOD              7 (pow_)\n",
      "            306 LOAD_CONST               7 (-0.5)\n",
      "            308 CALL_METHOD              1\n",
      "            310 STORE_FAST              10 (deg_inv_sqrt)\n",
      "\n",
      " 70         312 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "            314 LOAD_METHOD              8 (masked_fill_)\n",
      "            316 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "            318 LOAD_GLOBAL              9 (float)\n",
      "            320 LOAD_CONST               8 ('inf')\n",
      "            322 CALL_FUNCTION            1\n",
      "            324 COMPARE_OP               2 (==)\n",
      "            326 LOAD_CONST              13 (0)\n",
      "            328 CALL_METHOD              2\n",
      "            330 POP_TOP\n",
      "\n",
      " 71         332 LOAD_FAST                0 (edge_index)\n",
      "            334 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "            336 LOAD_FAST               12 (row)\n",
      "            338 BINARY_SUBSCR\n",
      "            340 LOAD_FAST                1 (edge_weight)\n",
      "            342 BINARY_MULTIPLY\n",
      "            344 LOAD_FAST               10 (deg_inv_sqrt)\n",
      "            346 LOAD_FAST               13 (col)\n",
      "            348 BINARY_SUBSCR\n",
      "            350 BINARY_MULTIPLY\n",
      "            352 BUILD_TUPLE              2\n",
      "            354 RETURN_VALUE\n",
      "            356 LOAD_CONST               0 (None)\n",
      "            358 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:40,401] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE gcn_norm /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py line 33 \n",
      " 33           0 LOAD_GLOBAL             20 (__compiled_fn_2)\n",
      "              2 LOAD_FAST                0 (edge_index)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST              15 (___graph_out_0)\n",
      "              8 LOAD_FAST                0 (edge_index)\n",
      "             10 LOAD_FAST               15 (___graph_out_0)\n",
      "             12 LOAD_CONST              13 (0)\n",
      "             14 BINARY_SUBSCR\n",
      "             16 BUILD_TUPLE              2\n",
      "             18 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:40,403] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'flow' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(flow, 9488480)', \"flow == 'source_to_target'\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e9810; to 'type' at 0x90c860 (str)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'dtype' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['EQUALS_MATCH'],\n",
      "                'code': [\"str(dtype) == 'torch.float32'\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37605f59a0; to 'type' at 0x7f371c7ea160 (dtype)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'improved' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(improved, 9478112)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769d5360; to 'type' at 0x90a980 (bool)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'num_nodes' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(num_nodes, 9487360)', 'num_nodes == 2708'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769d5090; to 'type' at 0x90c400 (int)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TYPE_MATCH\n",
      "            {\n",
      "                'guard_types': ['TYPE_MATCH'],\n",
      "                'code': ['___check_type_id(edge_index, 98247040)'],\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_weight' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(edge_weight, 9488912)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'add_self_loops' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(add_self_loops, 9478112)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769d5360; to 'type' at 0x90a980 (bool)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'list' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'float' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'range' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'torch' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'isinstance' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'scatter_add' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'SparseTensor' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'maybe_num_nodes' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_scatter_dot_scatter.torch' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_scatter_dot_scatter.broadcast' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_scatter_dot_scatter.scatter_sum' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_fx_inner begin:\n",
      "class <lambda>(torch.nn.Module):\n",
      "    def forward(self, arg0_1: i64[2, 10556]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:57, code: edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
      "        full: f32[10556] = torch.ops.aten.full.default([10556], 1, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:66, code: row, col = edge_index[0], edge_index[1]\n",
      "        select: i64[10556] = torch.ops.aten.select.int(arg0_1, 0, 0)\n",
      "        select_1: i64[10556] = torch.ops.aten.select.int(arg0_1, 0, 1);  arg0_1 = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_scatter-2.1.0-py3.8-linux-x86_64.egg/torch_scatter/utils.py:12, code: src = src.expand(other.size())\n",
      "        expand: i64[10556] = torch.ops.aten.expand.default(select_1, [10556])\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_scatter-2.1.0-py3.8-linux-x86_64.egg/torch_scatter/scatter.py:20, code: out = torch.zeros(size, dtype=src.dtype, device=src.device)\n",
      "        full_1: f32[2708] = torch.ops.aten.full.default([2708], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_scatter-2.1.0-py3.8-linux-x86_64.egg/torch_scatter/scatter.py:21, code: return out.scatter_add_(dim, index, src)\n",
      "        scatter_add: f32[2708] = torch.ops.aten.scatter_add.default(full_1, 0, expand, full);  full_1 = expand = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:69, code: deg_inv_sqrt = deg.pow_(-0.5)\n",
      "        pow_1: f32[2708] = torch.ops.aten.pow.Tensor_Scalar(scatter_add, -0.5);  scatter_add = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:70, code: deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0)\n",
      "        eq: b8[2708] = torch.ops.aten.eq.Scalar(pow_1, inf)\n",
      "        scalar_tensor: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))\n",
      "        where: f32[2708] = torch.ops.aten.where.self(eq, scalar_tensor, pow_1);  eq = scalar_tensor = pow_1 = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/gcn_conv.py:71, code: return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
      "        index: f32[10556] = torch.ops.aten.index.Tensor(where, [select]);  select = None\n",
      "        mul: f32[10556] = torch.ops.aten.mul.Tensor(index, full);  index = full = None\n",
      "        index_1: f32[10556] = torch.ops.aten.index.Tensor(where, [select_1]);  where = select_1 = None\n",
      "        mul_1: f32[10556] = torch.ops.aten.mul.Tensor(mul, index_1);  mul = index_1 = None\n",
      "        return (mul_1,)\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(1, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[10556],\n",
      "    origins={full}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='arg0_1', layout=FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[10556], stride=[1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='arg0_1', layout=FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[10556], stride=[1], offset=10556),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='arg0_1', layout=FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[10556], stride=[1], offset=10556),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[2708],\n",
      "    origins={full_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  ComputedBuffer(name='buf0', layout=FlexibleLayout('cuda', torch.float32, size=[2708], stride=[1]), data=Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[2708],\n",
      "    origins={full, full_1, arg0_1, scatter_add, select_1}\n",
      "  ))\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf0, i0)\n",
      "    tmp1 = constant(-0.5, torch.float32)\n",
      "    tmp2 = tmp0 ** tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[2708],\n",
      "    origins={full, full_1, pow_1, arg0_1, scatter_add, select_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.bool,\n",
      "    tmp0 = load(buf0, i0)\n",
      "    tmp1 = constant(-0.5, torch.float32)\n",
      "    tmp2 = tmp0 ** tmp1\n",
      "    tmp3 = constant(inf, torch.float32)\n",
      "    tmp4 = tmp2 == tmp3\n",
      "    return tmp4\n",
      "    ,\n",
      "    ranges=[2708],\n",
      "    origins={full, full_1, eq, pow_1, arg0_1, scatter_add, select_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0.0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[],\n",
      "    origins={scalar_tensor}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(buf0, i0)\n",
      "    tmp1 = constant(-0.5, torch.float32)\n",
      "    tmp2 = tmp0 ** tmp1\n",
      "    tmp3 = constant(inf, torch.float32)\n",
      "    tmp4 = tmp2 == tmp3\n",
      "    tmp5 = constant(0.0, torch.float32)\n",
      "    tmp6 = load(buf0, i0)\n",
      "    tmp7 = constant(-0.5, torch.float32)\n",
      "    tmp8 = tmp6 ** tmp7\n",
      "    tmp9 = where(tmp4, tmp5, tmp8)\n",
      "    return tmp9\n",
      "    ,\n",
      "    ranges=[2708],\n",
      "    origins={where, full, eq, pow_1, full_1, scalar_tensor, arg0_1, scatter_add, select_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg0_1, i0)\n",
      "    tmp1 = load(buf0, (tmp0))\n",
      "    tmp2 = constant(-0.5, torch.float32)\n",
      "    tmp3 = tmp1 ** tmp2\n",
      "    tmp4 = constant(inf, torch.float32)\n",
      "    tmp5 = tmp3 == tmp4\n",
      "    tmp6 = constant(0.0, torch.float32)\n",
      "    tmp7 = load(buf0, (tmp0))\n",
      "    tmp8 = constant(-0.5, torch.float32)\n",
      "    tmp9 = tmp7 ** tmp8\n",
      "    tmp10 = where(tmp5, tmp6, tmp9)\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[10556],\n",
      "    origins={where, full, eq, pow_1, index, full_1, scalar_tensor, arg0_1, scatter_add, select_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg0_1, i0)\n",
      "    tmp1 = load(buf0, (tmp0))\n",
      "    tmp2 = constant(-0.5, torch.float32)\n",
      "    tmp3 = tmp1 ** tmp2\n",
      "    tmp4 = constant(inf, torch.float32)\n",
      "    tmp5 = tmp3 == tmp4\n",
      "    tmp6 = constant(0.0, torch.float32)\n",
      "    tmp7 = load(buf0, (tmp0))\n",
      "    tmp8 = constant(-0.5, torch.float32)\n",
      "    tmp9 = tmp7 ** tmp8\n",
      "    tmp10 = where(tmp5, tmp6, tmp9)\n",
      "    tmp11 = constant(1, torch.float32)\n",
      "    tmp12 = tmp10 * tmp11\n",
      "    return tmp12\n",
      "    ,\n",
      "    ranges=[10556],\n",
      "    origins={where, full, mul, eq, pow_1, index, full_1, scalar_tensor, arg0_1, scatter_add, select_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg0_1, 10556 + i0)\n",
      "    tmp1 = load(buf0, (tmp0))\n",
      "    tmp2 = constant(-0.5, torch.float32)\n",
      "    tmp3 = tmp1 ** tmp2\n",
      "    tmp4 = constant(inf, torch.float32)\n",
      "    tmp5 = tmp3 == tmp4\n",
      "    tmp6 = constant(0.0, torch.float32)\n",
      "    tmp7 = load(buf0, (tmp0))\n",
      "    tmp8 = constant(-0.5, torch.float32)\n",
      "    tmp9 = tmp7 ** tmp8\n",
      "    tmp10 = where(tmp5, tmp6, tmp9)\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[10556],\n",
      "    origins={where, full, eq, index_1, pow_1, full_1, scalar_tensor, arg0_1, scatter_add, select_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(arg0_1, i0)\n",
      "    tmp1 = load(buf0, (tmp0))\n",
      "    tmp2 = constant(-0.5, torch.float32)\n",
      "    tmp3 = tmp1 ** tmp2\n",
      "    tmp4 = constant(inf, torch.float32)\n",
      "    tmp5 = tmp3 == tmp4\n",
      "    tmp6 = constant(0.0, torch.float32)\n",
      "    tmp7 = load(buf0, (tmp0))\n",
      "    tmp8 = constant(-0.5, torch.float32)\n",
      "    tmp9 = tmp7 ** tmp8\n",
      "    tmp10 = where(tmp5, tmp6, tmp9)\n",
      "    tmp11 = constant(1, torch.float32)\n",
      "    tmp12 = tmp10 * tmp11\n",
      "    tmp13 = load(arg0_1, 10556 + i0)\n",
      "    tmp14 = load(buf0, (tmp13))\n",
      "    tmp15 = constant(-0.5, torch.float32)\n",
      "    tmp16 = tmp14 ** tmp15\n",
      "    tmp17 = constant(inf, torch.float32)\n",
      "    tmp18 = tmp16 == tmp17\n",
      "    tmp19 = constant(0.0, torch.float32)\n",
      "    tmp20 = load(buf0, (tmp13))\n",
      "    tmp21 = constant(-0.5, torch.float32)\n",
      "    tmp22 = tmp20 ** tmp21\n",
      "    tmp23 = where(tmp18, tmp19, tmp22)\n",
      "    tmp24 = tmp12 * tmp23\n",
      "    return tmp24\n",
      "    ,\n",
      "    ranges=[10556],\n",
      "    origins={where, full, mul, eq, index_1, mul_1, pow_1, index, full_1, scalar_tensor, arg0_1, scatter_add, select_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[4096], filename=__file__, meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 2708\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = 0.0\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp0, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__1 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': ['out_ptr0'], 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 10556\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (10556 + x0), xmask)\n",
      "    tmp1 = 1.0\n",
      "    tl.atomic_add(out_ptr0 + (tmp0), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__2 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 10556\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x0), xmask)\n",
      "    tmp10 = tl.load(in_ptr0 + (10556 + x0), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (tmp0), xmask)\n",
      "    tmp2 = -0.5\n",
      "    tmp3 = tl.libdevice.pow(tmp1, tmp2)\n",
      "    tmp4 = float(\"inf\")\n",
      "    tmp5 = tmp3 == tmp4\n",
      "    tmp6 = 0.0\n",
      "    tmp7 = tl.where(tmp5, tmp6, tmp3)\n",
      "    tmp8 = 1.0\n",
      "    tmp9 = tmp7 * tmp8\n",
      "    tmp11 = tl.load(in_ptr1 + (tmp10), xmask)\n",
      "    tmp12 = tl.libdevice.pow(tmp11, tmp2)\n",
      "    tmp13 = tmp12 == tmp4\n",
      "    tmp14 = tl.where(tmp13, tmp6, tmp12)\n",
      "    tmp15 = tmp9 * tmp14\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp15, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    arg0_1, = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((2708, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(buf0, 2708, grid=grid(2708), stream=stream0)\n",
      "        triton__1.run(arg0_1, buf0, 10556, grid=grid(10556), stream=stream0)\n",
      "        buf2 = empty_strided((10556, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "        triton__2.run(arg0_1, buf0, buf2, 10556, grid=grid(10556), stream=stream0)\n",
      "        del arg0_1\n",
      "        return (buf2, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    arg0_1 = rand_strided((2, 10556), (10556, 1), device='cuda:0', dtype=torch.int64)\n",
      "    print_performance(lambda: call([arg0_1]))\n",
      "\n",
      "inductor code end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-09 10:31:40,990] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing propagate\n",
      "[2023-03-09 10:31:41,016] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing explain\n",
      "[2023-03-09 10:31:41,018] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __check_input__\n",
      "[2023-03-09 10:31:41,023] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing is_sparse\n",
      "[2023-03-09 10:31:41,025] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing is_torch_sparse_tensor\n",
      "[2023-03-09 10:31:41,028] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __collect__\n",
      "[2023-03-09 10:31:41,040] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing __collect__ (RETURN_VALUE)\n",
      "[2023-03-09 10:31:41,042] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,102] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 2\n",
      "[2023-03-09 10:31:41,112] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,151] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/3s/c3stcbcncxcixpwu4gvbvsxvribjjx4duv5kqk4jqhhlafxwqc5f.py\n",
      "[2023-03-09 10:31:41,152] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 2\n",
      "[2023-03-09 10:31:41,153] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,154] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_3 <eval_with_key>.17 opcode         name          target                       args                                     kwargs\n",
      "-------------  ------------  ---------------------------  ---------------------------------------  --------\n",
      "placeholder    edge_index    edge_index                   ()                                       {}\n",
      "placeholder    kwargs_x_     kwargs_x_                    ()                                       {}\n",
      "call_function  getitem       <built-in function getitem>  (edge_index, 0)                          {}\n",
      "call_method    index_select  index_select                 (kwargs_x_, -2, getitem)                 {}\n",
      "call_function  getitem_1     <built-in function getitem>  (edge_index, 1)                          {}\n",
      "call_function  getitem_2     <built-in function getitem>  (edge_index, 0)                          {}\n",
      "output         output        output                       ((index_select, getitem_1, getitem_2),)  {}\n",
      "\n",
      "[2023-03-09 10:31:41,156] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE __collect__ /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 282 \n",
      "283           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_ATTR                0 (flow)\n",
      "              4 LOAD_CONST               1 ('source_to_target')\n",
      "              6 COMPARE_OP               2 (==)\n",
      "              8 POP_JUMP_IF_FALSE       14\n",
      "             10 LOAD_CONST               2 ((1, 0))\n",
      "             12 JUMP_FORWARD             2 (to 16)\n",
      "        >>   14 LOAD_CONST               3 ((0, 1))\n",
      "        >>   16 UNPACK_SEQUENCE          2\n",
      "             18 STORE_FAST               5 (i)\n",
      "             20 STORE_FAST               6 (j)\n",
      "\n",
      "285          22 BUILD_MAP                0\n",
      "             24 STORE_FAST               7 (out)\n",
      "\n",
      "286          26 LOAD_FAST                1 (args)\n",
      "             28 GET_ITER\n",
      "        >>   30 FOR_ITER               214 (to 246)\n",
      "             32 STORE_FAST               8 (arg)\n",
      "\n",
      "287          34 LOAD_FAST                8 (arg)\n",
      "             36 LOAD_CONST               4 (-2)\n",
      "             38 LOAD_CONST               0 (None)\n",
      "             40 BUILD_SLICE              2\n",
      "             42 BINARY_SUBSCR\n",
      "             44 LOAD_CONST               5 (('_i', '_j'))\n",
      "             46 COMPARE_OP               7 (not in)\n",
      "             48 POP_JUMP_IF_FALSE       70\n",
      "\n",
      "288          50 LOAD_FAST                4 (kwargs)\n",
      "             52 LOAD_METHOD              1 (get)\n",
      "             54 LOAD_FAST                8 (arg)\n",
      "             56 LOAD_GLOBAL              2 (Parameter)\n",
      "             58 LOAD_ATTR                3 (empty)\n",
      "             60 CALL_METHOD              2\n",
      "             62 LOAD_FAST                7 (out)\n",
      "             64 LOAD_FAST                8 (arg)\n",
      "             66 STORE_SUBSCR\n",
      "             68 JUMP_ABSOLUTE           30\n",
      "\n",
      "290     >>   70 LOAD_FAST                8 (arg)\n",
      "             72 LOAD_CONST               4 (-2)\n",
      "             74 LOAD_CONST               0 (None)\n",
      "             76 BUILD_SLICE              2\n",
      "             78 BINARY_SUBSCR\n",
      "             80 LOAD_CONST               6 ('_j')\n",
      "             82 COMPARE_OP               2 (==)\n",
      "             84 POP_JUMP_IF_FALSE       90\n",
      "             86 LOAD_FAST                6 (j)\n",
      "             88 JUMP_FORWARD             2 (to 92)\n",
      "        >>   90 LOAD_FAST                5 (i)\n",
      "        >>   92 STORE_FAST               9 (dim)\n",
      "\n",
      "291          94 LOAD_FAST                4 (kwargs)\n",
      "             96 LOAD_METHOD              1 (get)\n",
      "             98 LOAD_FAST                8 (arg)\n",
      "            100 LOAD_CONST               0 (None)\n",
      "            102 LOAD_CONST               4 (-2)\n",
      "            104 BUILD_SLICE              2\n",
      "            106 BINARY_SUBSCR\n",
      "            108 LOAD_GLOBAL              2 (Parameter)\n",
      "            110 LOAD_ATTR                3 (empty)\n",
      "            112 CALL_METHOD              2\n",
      "            114 STORE_FAST              10 (data)\n",
      "\n",
      "293         116 LOAD_GLOBAL              4 (isinstance)\n",
      "            118 LOAD_FAST               10 (data)\n",
      "            120 LOAD_GLOBAL              5 (tuple)\n",
      "            122 LOAD_GLOBAL              6 (list)\n",
      "            124 BUILD_TUPLE              2\n",
      "            126 CALL_FUNCTION            2\n",
      "            128 POP_JUMP_IF_FALSE      198\n",
      "\n",
      "294         130 LOAD_GLOBAL              7 (len)\n",
      "            132 LOAD_FAST               10 (data)\n",
      "            134 CALL_FUNCTION            1\n",
      "            136 LOAD_CONST               7 (2)\n",
      "            138 COMPARE_OP               2 (==)\n",
      "            140 POP_JUMP_IF_TRUE       146\n",
      "            142 LOAD_GLOBAL              8 (AssertionError)\n",
      "            144 RAISE_VARARGS            1\n",
      "\n",
      "295     >>  146 LOAD_GLOBAL              4 (isinstance)\n",
      "            148 LOAD_FAST               10 (data)\n",
      "            150 LOAD_CONST               8 (1)\n",
      "            152 LOAD_FAST                9 (dim)\n",
      "            154 BINARY_SUBTRACT\n",
      "            156 BINARY_SUBSCR\n",
      "            158 LOAD_GLOBAL              9 (Tensor)\n",
      "            160 CALL_FUNCTION            2\n",
      "            162 POP_JUMP_IF_FALSE      190\n",
      "\n",
      "296         164 LOAD_FAST                0 (self)\n",
      "            166 LOAD_METHOD             10 (__set_size__)\n",
      "            168 LOAD_FAST                3 (size)\n",
      "            170 LOAD_CONST               8 (1)\n",
      "            172 LOAD_FAST                9 (dim)\n",
      "            174 BINARY_SUBTRACT\n",
      "            176 LOAD_FAST               10 (data)\n",
      "            178 LOAD_CONST               8 (1)\n",
      "            180 LOAD_FAST                9 (dim)\n",
      "            182 BINARY_SUBTRACT\n",
      "            184 BINARY_SUBSCR\n",
      "            186 CALL_METHOD              3\n",
      "            188 POP_TOP\n",
      "\n",
      "297     >>  190 LOAD_FAST               10 (data)\n",
      "            192 LOAD_FAST                9 (dim)\n",
      "            194 BINARY_SUBSCR\n",
      "            196 STORE_FAST              10 (data)\n",
      "\n",
      "299     >>  198 LOAD_GLOBAL              4 (isinstance)\n",
      "            200 LOAD_FAST               10 (data)\n",
      "            202 LOAD_GLOBAL              9 (Tensor)\n",
      "            204 CALL_FUNCTION            2\n",
      "            206 POP_JUMP_IF_FALSE      236\n",
      "\n",
      "300         208 LOAD_FAST                0 (self)\n",
      "            210 LOAD_METHOD             10 (__set_size__)\n",
      "            212 LOAD_FAST                3 (size)\n",
      "            214 LOAD_FAST                9 (dim)\n",
      "            216 LOAD_FAST               10 (data)\n",
      "            218 CALL_METHOD              3\n",
      "            220 POP_TOP\n",
      "\n",
      "301         222 LOAD_FAST                0 (self)\n",
      "            224 LOAD_METHOD             11 (__lift__)\n",
      "            226 LOAD_FAST               10 (data)\n",
      "            228 LOAD_FAST                2 (edge_index)\n",
      "            230 LOAD_FAST                9 (dim)\n",
      "            232 CALL_METHOD              3\n",
      "            234 STORE_FAST              10 (data)\n",
      "\n",
      "303     >>  236 LOAD_FAST               10 (data)\n",
      "            238 LOAD_FAST                7 (out)\n",
      "            240 LOAD_FAST                8 (arg)\n",
      "            242 STORE_SUBSCR\n",
      "            244 JUMP_ABSOLUTE           30\n",
      "\n",
      "305     >>  246 LOAD_GLOBAL             12 (is_torch_sparse_tensor)\n",
      "            248 LOAD_FAST                2 (edge_index)\n",
      "            250 CALL_FUNCTION            1\n",
      "            252 EXTENDED_ARG             1\n",
      "            254 POP_JUMP_IF_FALSE      434\n",
      "\n",
      "306         256 LOAD_FAST                2 (edge_index)\n",
      "            258 LOAD_ATTR               13 (requires_grad)\n",
      "            260 EXTENDED_ARG             1\n",
      "            262 POP_JUMP_IF_FALSE      290\n",
      "\n",
      "307         264 LOAD_FAST                2 (edge_index)\n",
      "            266 LOAD_METHOD             14 (coalesce)\n",
      "            268 CALL_METHOD              0\n",
      "            270 STORE_FAST               2 (edge_index)\n",
      "\n",
      "308         272 LOAD_FAST                2 (edge_index)\n",
      "            274 LOAD_METHOD             15 (indices)\n",
      "            276 CALL_METHOD              0\n",
      "            278 STORE_FAST              11 (indices)\n",
      "\n",
      "309         280 LOAD_FAST                2 (edge_index)\n",
      "            282 LOAD_METHOD             16 (values)\n",
      "            284 CALL_METHOD              0\n",
      "            286 STORE_FAST              12 (values)\n",
      "            288 JUMP_FORWARD            16 (to 306)\n",
      "\n",
      "311     >>  290 LOAD_FAST                2 (edge_index)\n",
      "            292 LOAD_METHOD             17 (_indices)\n",
      "            294 CALL_METHOD              0\n",
      "            296 STORE_FAST              11 (indices)\n",
      "\n",
      "312         298 LOAD_FAST                2 (edge_index)\n",
      "            300 LOAD_METHOD             18 (_values)\n",
      "            302 CALL_METHOD              0\n",
      "            304 STORE_FAST              12 (values)\n",
      "\n",
      "313     >>  306 LOAD_FAST                2 (edge_index)\n",
      "            308 LOAD_FAST                7 (out)\n",
      "            310 LOAD_CONST               9 ('adj_t')\n",
      "            312 STORE_SUBSCR\n",
      "\n",
      "314         314 LOAD_CONST               0 (None)\n",
      "            316 LOAD_FAST                7 (out)\n",
      "            318 LOAD_CONST              10 ('edge_index')\n",
      "            320 STORE_SUBSCR\n",
      "\n",
      "315         322 LOAD_FAST               11 (indices)\n",
      "            324 LOAD_CONST              11 (0)\n",
      "            326 BINARY_SUBSCR\n",
      "            328 LOAD_FAST                7 (out)\n",
      "            330 LOAD_CONST              12 ('edge_index_i')\n",
      "            332 STORE_SUBSCR\n",
      "\n",
      "316         334 LOAD_FAST               11 (indices)\n",
      "            336 LOAD_CONST               8 (1)\n",
      "            338 BINARY_SUBSCR\n",
      "            340 LOAD_FAST                7 (out)\n",
      "            342 LOAD_CONST              13 ('edge_index_j')\n",
      "            344 STORE_SUBSCR\n",
      "\n",
      "317         346 LOAD_CONST               0 (None)\n",
      "            348 LOAD_FAST                7 (out)\n",
      "            350 LOAD_CONST              14 ('ptr')\n",
      "            352 STORE_SUBSCR\n",
      "\n",
      "318         354 LOAD_FAST                7 (out)\n",
      "            356 LOAD_METHOD              1 (get)\n",
      "            358 LOAD_CONST              15 ('edge_weight')\n",
      "            360 LOAD_CONST               0 (None)\n",
      "            362 CALL_METHOD              2\n",
      "            364 LOAD_CONST               0 (None)\n",
      "            366 COMPARE_OP               8 (is)\n",
      "            368 EXTENDED_ARG             1\n",
      "            370 POP_JUMP_IF_FALSE      380\n",
      "\n",
      "319         372 LOAD_FAST               12 (values)\n",
      "            374 LOAD_FAST                7 (out)\n",
      "            376 LOAD_CONST              15 ('edge_weight')\n",
      "            378 STORE_SUBSCR\n",
      "\n",
      "320     >>  380 LOAD_FAST                7 (out)\n",
      "            382 LOAD_METHOD              1 (get)\n",
      "            384 LOAD_CONST              16 ('edge_attr')\n",
      "            386 LOAD_CONST               0 (None)\n",
      "            388 CALL_METHOD              2\n",
      "            390 LOAD_CONST               0 (None)\n",
      "            392 COMPARE_OP               8 (is)\n",
      "            394 EXTENDED_ARG             1\n",
      "            396 POP_JUMP_IF_FALSE      406\n",
      "\n",
      "321         398 LOAD_FAST               12 (values)\n",
      "            400 LOAD_FAST                7 (out)\n",
      "            402 LOAD_CONST              16 ('edge_attr')\n",
      "            404 STORE_SUBSCR\n",
      "\n",
      "322     >>  406 LOAD_FAST                7 (out)\n",
      "            408 LOAD_METHOD              1 (get)\n",
      "            410 LOAD_CONST              17 ('edge_type')\n",
      "            412 LOAD_CONST               0 (None)\n",
      "            414 CALL_METHOD              2\n",
      "            416 LOAD_CONST               0 (None)\n",
      "            418 COMPARE_OP               8 (is)\n",
      "            420 EXTENDED_ARG             2\n",
      "            422 POP_JUMP_IF_FALSE      662\n",
      "\n",
      "323         424 LOAD_FAST               12 (values)\n",
      "            426 LOAD_FAST                7 (out)\n",
      "            428 LOAD_CONST              17 ('edge_type')\n",
      "            430 STORE_SUBSCR\n",
      "            432 JUMP_FORWARD           228 (to 662)\n",
      "\n",
      "325     >>  434 LOAD_GLOBAL              4 (isinstance)\n",
      "            436 LOAD_FAST                2 (edge_index)\n",
      "            438 LOAD_GLOBAL              9 (Tensor)\n",
      "            440 CALL_FUNCTION            2\n",
      "            442 EXTENDED_ARG             1\n",
      "            444 POP_JUMP_IF_FALSE      496\n",
      "\n",
      "326         446 LOAD_CONST               0 (None)\n",
      "            448 LOAD_FAST                7 (out)\n",
      "            450 LOAD_CONST               9 ('adj_t')\n",
      "            452 STORE_SUBSCR\n",
      "\n",
      "327         454 LOAD_FAST                2 (edge_index)\n",
      "            456 LOAD_FAST                7 (out)\n",
      "            458 LOAD_CONST              10 ('edge_index')\n",
      "            460 STORE_SUBSCR\n",
      "\n",
      "328         462 LOAD_FAST                2 (edge_index)\n",
      "            464 LOAD_FAST                5 (i)\n",
      "            466 BINARY_SUBSCR\n",
      "            468 LOAD_FAST                7 (out)\n",
      "            470 LOAD_CONST              12 ('edge_index_i')\n",
      "            472 STORE_SUBSCR\n",
      "\n",
      "329         474 LOAD_FAST                2 (edge_index)\n",
      "            476 LOAD_FAST                6 (j)\n",
      "            478 BINARY_SUBSCR\n",
      "            480 LOAD_FAST                7 (out)\n",
      "            482 LOAD_CONST              13 ('edge_index_j')\n",
      "            484 STORE_SUBSCR\n",
      "\n",
      "330         486 LOAD_CONST               0 (None)\n",
      "            488 LOAD_FAST                7 (out)\n",
      "            490 LOAD_CONST              14 ('ptr')\n",
      "            492 STORE_SUBSCR\n",
      "            494 JUMP_FORWARD           166 (to 662)\n",
      "\n",
      "332     >>  496 LOAD_GLOBAL              4 (isinstance)\n",
      "            498 LOAD_FAST                2 (edge_index)\n",
      "            500 LOAD_GLOBAL             19 (SparseTensor)\n",
      "            502 CALL_FUNCTION            2\n",
      "            504 EXTENDED_ARG             2\n",
      "            506 POP_JUMP_IF_FALSE      662\n",
      "\n",
      "333         508 LOAD_FAST                2 (edge_index)\n",
      "            510 LOAD_FAST                7 (out)\n",
      "            512 LOAD_CONST               9 ('adj_t')\n",
      "            514 STORE_SUBSCR\n",
      "\n",
      "334         516 LOAD_CONST               0 (None)\n",
      "            518 LOAD_FAST                7 (out)\n",
      "            520 LOAD_CONST              10 ('edge_index')\n",
      "            522 STORE_SUBSCR\n",
      "\n",
      "335         524 LOAD_FAST                2 (edge_index)\n",
      "            526 LOAD_ATTR               20 (storage)\n",
      "            528 LOAD_METHOD             21 (row)\n",
      "            530 CALL_METHOD              0\n",
      "            532 LOAD_FAST                7 (out)\n",
      "            534 LOAD_CONST              12 ('edge_index_i')\n",
      "            536 STORE_SUBSCR\n",
      "\n",
      "336         538 LOAD_FAST                2 (edge_index)\n",
      "            540 LOAD_ATTR               20 (storage)\n",
      "            542 LOAD_METHOD             22 (col)\n",
      "            544 CALL_METHOD              0\n",
      "            546 LOAD_FAST                7 (out)\n",
      "            548 LOAD_CONST              13 ('edge_index_j')\n",
      "            550 STORE_SUBSCR\n",
      "\n",
      "337         552 LOAD_FAST                2 (edge_index)\n",
      "            554 LOAD_ATTR               20 (storage)\n",
      "            556 LOAD_METHOD             23 (rowptr)\n",
      "            558 CALL_METHOD              0\n",
      "            560 LOAD_FAST                7 (out)\n",
      "            562 LOAD_CONST              14 ('ptr')\n",
      "            564 STORE_SUBSCR\n",
      "\n",
      "338         566 LOAD_FAST                7 (out)\n",
      "            568 LOAD_METHOD              1 (get)\n",
      "            570 LOAD_CONST              15 ('edge_weight')\n",
      "            572 LOAD_CONST               0 (None)\n",
      "            574 CALL_METHOD              2\n",
      "            576 LOAD_CONST               0 (None)\n",
      "            578 COMPARE_OP               8 (is)\n",
      "            580 EXTENDED_ARG             2\n",
      "            582 POP_JUMP_IF_FALSE      598\n",
      "\n",
      "339         584 LOAD_FAST                2 (edge_index)\n",
      "            586 LOAD_ATTR               20 (storage)\n",
      "            588 LOAD_METHOD             24 (value)\n",
      "            590 CALL_METHOD              0\n",
      "            592 LOAD_FAST                7 (out)\n",
      "            594 LOAD_CONST              15 ('edge_weight')\n",
      "            596 STORE_SUBSCR\n",
      "\n",
      "340     >>  598 LOAD_FAST                7 (out)\n",
      "            600 LOAD_METHOD              1 (get)\n",
      "            602 LOAD_CONST              16 ('edge_attr')\n",
      "            604 LOAD_CONST               0 (None)\n",
      "            606 CALL_METHOD              2\n",
      "            608 LOAD_CONST               0 (None)\n",
      "            610 COMPARE_OP               8 (is)\n",
      "            612 EXTENDED_ARG             2\n",
      "            614 POP_JUMP_IF_FALSE      630\n",
      "\n",
      "341         616 LOAD_FAST                2 (edge_index)\n",
      "            618 LOAD_ATTR               20 (storage)\n",
      "            620 LOAD_METHOD             24 (value)\n",
      "            622 CALL_METHOD              0\n",
      "            624 LOAD_FAST                7 (out)\n",
      "            626 LOAD_CONST              16 ('edge_attr')\n",
      "            628 STORE_SUBSCR\n",
      "\n",
      "342     >>  630 LOAD_FAST                7 (out)\n",
      "            632 LOAD_METHOD              1 (get)\n",
      "            634 LOAD_CONST              17 ('edge_type')\n",
      "            636 LOAD_CONST               0 (None)\n",
      "            638 CALL_METHOD              2\n",
      "            640 LOAD_CONST               0 (None)\n",
      "            642 COMPARE_OP               8 (is)\n",
      "            644 EXTENDED_ARG             2\n",
      "            646 POP_JUMP_IF_FALSE      662\n",
      "\n",
      "343         648 LOAD_FAST                2 (edge_index)\n",
      "            650 LOAD_ATTR               20 (storage)\n",
      "            652 LOAD_METHOD             24 (value)\n",
      "            654 CALL_METHOD              0\n",
      "            656 LOAD_FAST                7 (out)\n",
      "            658 LOAD_CONST              17 ('edge_type')\n",
      "            660 STORE_SUBSCR\n",
      "\n",
      "345     >>  662 LOAD_FAST                7 (out)\n",
      "            664 LOAD_CONST              12 ('edge_index_i')\n",
      "            666 BINARY_SUBSCR\n",
      "            668 LOAD_FAST                7 (out)\n",
      "            670 LOAD_CONST              18 ('index')\n",
      "            672 STORE_SUBSCR\n",
      "\n",
      "346         674 LOAD_FAST                3 (size)\n",
      "            676 LOAD_FAST                7 (out)\n",
      "            678 LOAD_CONST              19 ('size')\n",
      "            680 STORE_SUBSCR\n",
      "\n",
      "347         682 LOAD_FAST                3 (size)\n",
      "            684 LOAD_FAST                5 (i)\n",
      "            686 BINARY_SUBSCR\n",
      "            688 LOAD_CONST               0 (None)\n",
      "            690 COMPARE_OP               9 (is not)\n",
      "            692 EXTENDED_ARG             2\n",
      "            694 POP_JUMP_IF_FALSE      704\n",
      "            696 LOAD_FAST                3 (size)\n",
      "            698 LOAD_FAST                5 (i)\n",
      "            700 BINARY_SUBSCR\n",
      "            702 JUMP_FORWARD             6 (to 710)\n",
      "        >>  704 LOAD_FAST                3 (size)\n",
      "            706 LOAD_FAST                6 (j)\n",
      "            708 BINARY_SUBSCR\n",
      "        >>  710 LOAD_FAST                7 (out)\n",
      "            712 LOAD_CONST              20 ('size_i')\n",
      "            714 STORE_SUBSCR\n",
      "\n",
      "348         716 LOAD_FAST                3 (size)\n",
      "            718 LOAD_FAST                6 (j)\n",
      "            720 BINARY_SUBSCR\n",
      "            722 LOAD_CONST               0 (None)\n",
      "            724 COMPARE_OP               9 (is not)\n",
      "            726 EXTENDED_ARG             2\n",
      "            728 POP_JUMP_IF_FALSE      738\n",
      "            730 LOAD_FAST                3 (size)\n",
      "            732 LOAD_FAST                6 (j)\n",
      "            734 BINARY_SUBSCR\n",
      "            736 JUMP_FORWARD             6 (to 744)\n",
      "        >>  738 LOAD_FAST                3 (size)\n",
      "            740 LOAD_FAST                5 (i)\n",
      "            742 BINARY_SUBSCR\n",
      "        >>  744 LOAD_FAST                7 (out)\n",
      "            746 LOAD_CONST              21 ('size_j')\n",
      "            748 STORE_SUBSCR\n",
      "\n",
      "349         750 LOAD_FAST                7 (out)\n",
      "            752 LOAD_CONST              20 ('size_i')\n",
      "            754 BINARY_SUBSCR\n",
      "            756 LOAD_FAST                7 (out)\n",
      "            758 LOAD_CONST              22 ('dim_size')\n",
      "            760 STORE_SUBSCR\n",
      "\n",
      "351         762 LOAD_FAST                7 (out)\n",
      "            764 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,156] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE __collect__ /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 282 \n",
      "282           0 LOAD_GLOBAL             26 (__compiled_fn_3)\n",
      "              2 LOAD_FAST                2 (edge_index)\n",
      "              4 LOAD_FAST                4 (kwargs)\n",
      "              6 LOAD_CONST              25 ('x')\n",
      "              8 BINARY_SUBSCR\n",
      "             10 CALL_FUNCTION            2\n",
      "             12 STORE_FAST              13 (___graph_out_0)\n",
      "             14 LOAD_FAST                3 (size)\n",
      "             16 STORE_FAST              14 (___tmp_0)\n",
      "             18 LOAD_CONST              15 ('edge_weight')\n",
      "             20 LOAD_FAST                4 (kwargs)\n",
      "             22 LOAD_CONST              15 ('edge_weight')\n",
      "             24 BINARY_SUBSCR\n",
      "             26 LOAD_CONST              23 ('x_j')\n",
      "             28 LOAD_FAST               13 (___graph_out_0)\n",
      "             30 LOAD_CONST              11 (0)\n",
      "             32 BINARY_SUBSCR\n",
      "             34 LOAD_CONST               9 ('adj_t')\n",
      "             36 LOAD_CONST               0 (None)\n",
      "             38 LOAD_CONST              10 ('edge_index')\n",
      "             40 LOAD_FAST                2 (edge_index)\n",
      "             42 LOAD_CONST              12 ('edge_index_i')\n",
      "             44 LOAD_FAST               13 (___graph_out_0)\n",
      "             46 LOAD_CONST               8 (1)\n",
      "             48 BINARY_SUBSCR\n",
      "             50 LOAD_CONST              13 ('edge_index_j')\n",
      "             52 LOAD_FAST               13 (___graph_out_0)\n",
      "             54 LOAD_CONST               7 (2)\n",
      "             56 BINARY_SUBSCR\n",
      "             58 LOAD_CONST              14 ('ptr')\n",
      "             60 LOAD_CONST               0 (None)\n",
      "             62 LOAD_CONST              18 ('index')\n",
      "             64 LOAD_FAST               13 (___graph_out_0)\n",
      "             66 LOAD_CONST               8 (1)\n",
      "             68 BINARY_SUBSCR\n",
      "             70 LOAD_CONST              19 ('size')\n",
      "             72 LOAD_FAST               14 (___tmp_0)\n",
      "             74 LOAD_CONST              20 ('size_i')\n",
      "             76 LOAD_CONST              24 (2708)\n",
      "             78 LOAD_CONST              21 ('size_j')\n",
      "             80 LOAD_CONST              24 (2708)\n",
      "             82 LOAD_CONST              22 ('dim_size')\n",
      "             84 LOAD_CONST              24 (2708)\n",
      "             86 BUILD_MAP               12\n",
      "             88 LOAD_CONST              24 (2708)\n",
      "             90 LOAD_FAST                3 (size)\n",
      "             92 LOAD_CONST               8 (1)\n",
      "             94 BINARY_SUBSCR\n",
      "             96 BUILD_LIST               2\n",
      "             98 LOAD_FAST                3 (size)\n",
      "            100 LOAD_CONST               0 (None)\n",
      "            102 LOAD_CONST               0 (None)\n",
      "            104 BUILD_SLICE              2\n",
      "            106 STORE_SUBSCR\n",
      "            108 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,158] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'args' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(args, 9451840)', \"args == {'edge_weight', 'x_j'}\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e8220; to 'type' at 0x903940 (set)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'args' LIST_LENGTH\n",
      "            {\n",
      "                'guard_types': ['LIST_LENGTH'],\n",
      "                'code': ['___check_type_id(args, 9451840)', 'len(args) == 2'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e8220; to 'type' at 0x903940 (set)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 139870845922656)'],\n",
      "                'obj_weakref': <weakref at 0x7f36ac9fb720; to 'ARMAConv' at 0x7f363815ed60>\n",
      "                'guarded_class': <weakref at 0x7f36366bb090; to 'type' at 0x7c28600 (ARMAConv)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'size' EQUALS_MATCH\n",
      "            {\n",
      "                'guard_types': ['LIST_LENGTH', 'EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(size, 9465376)', 'len(size) == 2', '___check_type_id(size[0], 9474080)', '___check_type_id(size[1], 9474080)', 'size == [None, None]'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769ddae0; to 'type' at 0x906e20 (list)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'kwargs' DICT_KEYS\n",
      "            {\n",
      "                'guard_types': ['DICT_KEYS'],\n",
      "                'code': ['___check_type_id(kwargs, 9490176)', \"set(kwargs.keys()) == {'edge_weight', 'x'}\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e20e0; to 'type' at 0x90cf00 (dict)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'size[0]' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(size[0], 9488912)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'size[1]' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(size[1], 9488912)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TYPE_MATCH\n",
      "            {\n",
      "                'guard_types': ['TYPE_MATCH'],\n",
      "                'code': ['___check_type_id(edge_index, 98247040)'],\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['x']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36ac9fb040; to 'Tensor' at 0x7f36accc4f40>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_weight']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f6d0; to 'Tensor' at 0x7f36ac9e8e00>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'list' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'tuple' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'Tensor' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'Parameter' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'isinstance' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'is_torch_sparse_tensor' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_geometric_dot_utils_dot_sparse.Tensor' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.flow' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.node_dim' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,163] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing distribute\n",
      "[2023-03-09 10:31:41,169] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE distribute /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/utils/inspector.py line 52 \n",
      " 53           0 BUILD_MAP                0\n",
      "              2 STORE_FAST               3 (out)\n",
      "\n",
      " 54           4 LOAD_FAST                0 (self)\n",
      "              6 LOAD_ATTR                0 (params)\n",
      "              8 LOAD_FAST                1 (func_name)\n",
      "             10 BINARY_SUBSCR\n",
      "             12 LOAD_METHOD              1 (items)\n",
      "             14 CALL_METHOD              0\n",
      "             16 GET_ITER\n",
      "        >>   18 FOR_ITER                80 (to 100)\n",
      "             20 UNPACK_SEQUENCE          2\n",
      "             22 STORE_FAST               4 (key)\n",
      "             24 STORE_FAST               5 (param)\n",
      "\n",
      " 55          26 LOAD_FAST                2 (kwargs)\n",
      "             28 LOAD_METHOD              2 (get)\n",
      "             30 LOAD_FAST                4 (key)\n",
      "             32 LOAD_GLOBAL              3 (inspect)\n",
      "             34 LOAD_ATTR                4 (Parameter)\n",
      "             36 LOAD_ATTR                5 (empty)\n",
      "             38 CALL_METHOD              2\n",
      "             40 STORE_FAST               6 (data)\n",
      "\n",
      " 56          42 LOAD_FAST                6 (data)\n",
      "             44 LOAD_GLOBAL              3 (inspect)\n",
      "             46 LOAD_ATTR                4 (Parameter)\n",
      "             48 LOAD_ATTR                5 (empty)\n",
      "             50 COMPARE_OP               8 (is)\n",
      "             52 POP_JUMP_IF_FALSE       90\n",
      "\n",
      " 57          54 LOAD_FAST                5 (param)\n",
      "             56 LOAD_ATTR                6 (default)\n",
      "             58 LOAD_GLOBAL              3 (inspect)\n",
      "             60 LOAD_ATTR                4 (Parameter)\n",
      "             62 LOAD_ATTR                5 (empty)\n",
      "             64 COMPARE_OP               8 (is)\n",
      "             66 POP_JUMP_IF_FALSE       84\n",
      "\n",
      " 58          68 LOAD_GLOBAL              7 (TypeError)\n",
      "             70 LOAD_CONST               1 ('Required parameter ')\n",
      "             72 LOAD_FAST                4 (key)\n",
      "             74 FORMAT_VALUE             0\n",
      "             76 LOAD_CONST               2 (' is empty.')\n",
      "             78 BUILD_STRING             3\n",
      "             80 CALL_FUNCTION            1\n",
      "             82 RAISE_VARARGS            1\n",
      "\n",
      " 59     >>   84 LOAD_FAST                5 (param)\n",
      "             86 LOAD_ATTR                6 (default)\n",
      "             88 STORE_FAST               6 (data)\n",
      "\n",
      " 60     >>   90 LOAD_FAST                6 (data)\n",
      "             92 LOAD_FAST                3 (out)\n",
      "             94 LOAD_FAST                4 (key)\n",
      "             96 STORE_SUBSCR\n",
      "             98 JUMP_ABSOLUTE           18\n",
      "\n",
      " 61     >>  100 LOAD_FAST                3 (out)\n",
      "            102 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,170] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE distribute /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/utils/inspector.py line 52 \n",
      " 52           0 BUILD_MAP                0\n",
      "              2 STORE_FAST               3 (out)\n",
      "\n",
      " 54           4 LOAD_FAST                0 (self)\n",
      "              6 LOAD_ATTR                0 (params)\n",
      "              8 LOAD_FAST                1 (func_name)\n",
      "             10 BINARY_SUBSCR\n",
      "             12 LOAD_ATTR                1 (items)\n",
      "             14 CALL_FUNCTION            0\n",
      "             16 GET_ITER\n",
      "        >>   18 FOR_ITER                80 (to 100)\n",
      "             20 UNPACK_SEQUENCE          2\n",
      "             22 STORE_FAST               4 (key)\n",
      "             24 STORE_FAST               5 (param)\n",
      "\n",
      " 55          26 LOAD_FAST                2 (kwargs)\n",
      "             28 LOAD_ATTR                2 (get)\n",
      "             30 LOAD_FAST                4 (key)\n",
      "             32 LOAD_GLOBAL              3 (inspect)\n",
      "             34 LOAD_ATTR                4 (Parameter)\n",
      "             36 LOAD_ATTR                5 (empty)\n",
      "             38 CALL_FUNCTION            2\n",
      "             40 STORE_FAST               6 (data)\n",
      "\n",
      " 56          42 LOAD_FAST                6 (data)\n",
      "             44 LOAD_GLOBAL              3 (inspect)\n",
      "             46 LOAD_ATTR                4 (Parameter)\n",
      "             48 LOAD_ATTR                5 (empty)\n",
      "             50 COMPARE_OP               8 (is)\n",
      "             52 POP_JUMP_IF_FALSE       90\n",
      "\n",
      " 57          54 LOAD_FAST                5 (param)\n",
      "             56 LOAD_ATTR                6 (default)\n",
      "             58 LOAD_GLOBAL              3 (inspect)\n",
      "             60 LOAD_ATTR                4 (Parameter)\n",
      "             62 LOAD_ATTR                5 (empty)\n",
      "             64 COMPARE_OP               8 (is)\n",
      "             66 POP_JUMP_IF_FALSE       84\n",
      "\n",
      " 58          68 LOAD_GLOBAL              7 (TypeError)\n",
      "             70 LOAD_CONST               1 ('Required parameter ')\n",
      "             72 LOAD_FAST                4 (key)\n",
      "             74 FORMAT_VALUE             0\n",
      "             76 LOAD_CONST               2 (' is empty.')\n",
      "             78 BUILD_STRING             3\n",
      "             80 CALL_FUNCTION            1\n",
      "             82 RAISE_VARARGS            1\n",
      "\n",
      " 59     >>   84 LOAD_FAST                5 (param)\n",
      "             86 LOAD_ATTR                6 (default)\n",
      "             88 STORE_FAST               6 (data)\n",
      "\n",
      " 60     >>   90 LOAD_FAST                6 (data)\n",
      "             92 LOAD_FAST                3 (out)\n",
      "             94 LOAD_FAST                4 (key)\n",
      "             96 STORE_SUBSCR\n",
      "             98 JUMP_ABSOLUTE           18\n",
      "\n",
      " 61     >>  100 LOAD_FAST                3 (out)\n",
      "            102 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,171] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'kwargs' DICT_KEYS\n",
      "            {\n",
      "                'guard_types': ['DICT_KEYS'],\n",
      "                'code': ['___check_type_id(kwargs, 9490176)', \"set(kwargs.keys()) == {'edge_index_i', 'size_j', 'edge_index_j', 'index', 'edge_index', 'size', 'x_j', 'dim_size', 'edge_weight', 'size_i', 'adj_t', 'ptr'}\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e20e0; to 'type' at 0x90cf00 (dict)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['x_j']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84fd630; to 'Tensor' at 0x7f36accc01d0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['index']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84fd4a0; to 'Tensor' at 0x7f36acba5ae0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_index']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_weight']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f6d0; to 'Tensor' at 0x7f36ac9e8e00>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_index_i']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84fd4a0; to 'Tensor' at 0x7f36acba5ae0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_index_j']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84fd900; to 'Tensor' at 0x7f36a84fdf40>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,172] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing message\n",
      "[2023-03-09 10:31:41,174] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing message (RETURN_VALUE)\n",
      "[2023-03-09 10:31:41,175] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,187] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 3\n",
      "[2023-03-09 10:31:41,192] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,221] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/vd/cvdgducjehexuk3jjeyi22hgyfazpvnqgfqjkzidlfrqnvrs3ekc.py\n",
      "[2023-03-09 10:31:41,221] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 3\n",
      "[2023-03-09 10:31:41,222] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,223] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_4 <eval_with_key>.28 opcode         name         target                   args                  kwargs\n",
      "-------------  -----------  -----------------------  --------------------  --------\n",
      "placeholder    x_j          x_j                      ()                    {}\n",
      "placeholder    edge_weight  edge_weight              ()                    {}\n",
      "call_method    view         view                     (edge_weight, -1, 1)  {}\n",
      "call_function  mul          <built-in function mul>  (view, x_j)           {}\n",
      "output         output       output                   ((mul,),)             {}\n",
      "\n",
      "[2023-03-09 10:31:41,224] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE message /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py line 143 \n",
      "144           0 LOAD_FAST                2 (edge_weight)\n",
      "              2 LOAD_METHOD              0 (view)\n",
      "              4 LOAD_CONST               1 (-1)\n",
      "              6 LOAD_CONST               2 (1)\n",
      "              8 CALL_METHOD              2\n",
      "             10 LOAD_FAST                1 (x_j)\n",
      "             12 BINARY_MULTIPLY\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,225] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE message /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py line 143 \n",
      "143           0 LOAD_GLOBAL              1 (__compiled_fn_4)\n",
      "              2 LOAD_FAST                1 (x_j)\n",
      "              4 LOAD_FAST                2 (edge_weight)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,225] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x_j' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84fd630; to 'Tensor' at 0x7f36accc01d0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_weight' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f6d0; to 'Tensor' at 0x7f36ac9e8e00>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,228] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing aggregate\n",
      "[2023-03-09 10:31:41,238] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing aggregate (RETURN_VALUE)\n",
      "[2023-03-09 10:31:41,239] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,255] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 4\n",
      "[2023-03-09 10:31:41,263] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,265] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf1')]\n",
      "[2023-03-09 10:31:41,303] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/5g/c5g25g3chwh3ez3arzmmjvc3g4d4ajzvzv3x2yyrshc4g3zlqab4.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: i64[2, 10556], primals_2: f32[3, 2708, 16]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:238, code: index = edge_index[dim]\n",
      "        select: i64[10556] = torch.ops.aten.select.int(primals_1, 0, 0)\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:239, code: return src.index_select(self.node_dim, index)\n",
      "        slice_1: f32[3, 2708, 16] = torch.ops.aten.slice.Tensor(primals_2, 0, 0, 9223372036854775807);  primals_2 = None\n",
      "        index: f32[3, 10556, 16] = torch.ops.aten.index.Tensor(slice_1, [None, select]);  slice_1 = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:328, code: out['edge_index_i'] = edge_index[i]\n",
      "        select_1: i64[10556] = torch.ops.aten.select.int(primals_1, 0, 1);  primals_1 = None\n",
      "        return [index, select_1, select, select]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[10556], stride=[1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[3, 2708, 16], stride=[43328, 16, 1]))\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, i1)\n",
      "    tmp1 = load(primals_2, i2 + 16 * (tmp0) + 43328 * i0)\n",
      "    return tmp1\n",
      "    ,\n",
      "    ranges=[3, 10556, 16],\n",
      "    origins={index, primals_2, slice_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[10556], stride=[1], offset=10556),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[524288], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 506688\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 16) % 10556\n",
      "    x0 = xindex % 16\n",
      "    x2 = (xindex // 168896)\n",
      "    x3 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x0 + (16*tmp0) + (43328*x2)), xmask)\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, primals_2 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 16), (168896, 16, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(primals_1, primals_2, buf0, 506688, grid=grid(506688), stream=stream0)\n",
      "        del primals_2\n",
      "        return (buf0, as_strided(primals_1, (10556, ), (1, ), 10556), as_strided(primals_1, (10556, ), (1, )), as_strided(primals_1, (10556, ), (1, )), )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_1 = rand_strided((2, 10556), (10556, 1), device='cuda:0', dtype=torch.int64)\n",
      "    primals_2 = rand_strided((3, 2708, 16), (43328, 16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_1, primals_2]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: f32[3, 10556, 16], primals_2: f32[10556]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py:144, code: return edge_weight.view(-1, 1) * x_j\n",
      "        view: f32[10556, 1] = torch.ops.aten.view.default(primals_2, [-1, 1])\n",
      "        mul: f32[3, 10556, 16] = torch.ops.aten.mul.Tensor(view, primals_1);  view = primals_1 = None\n",
      "        return [mul, primals_2]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.float32, size=[10556, 1], stride=[1, 1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_2, i1)\n",
      "    tmp1 = load(primals_1, i2 + 16 * i1 + 168896 * i0)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[3, 10556, 16],\n",
      "    origins={primals_2, mul, view, primals_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[524288], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 506688\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 16) % 10556\n",
      "    x3 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x3), xmask)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp2, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, primals_2 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 16), (168896, 16, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(primals_2, primals_1, buf0, 506688, grid=grid(506688), stream=stream0)\n",
      "        del primals_1\n",
      "        return (buf0, primals_2, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_1 = rand_strided((3, 10556, 16), (168896, 16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    primals_2 = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_1, primals_2]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: f32[3, 10556, 16], primals_2: i64[10556]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:20, code: return src.view(size).expand_as(ref)\n",
      "        view: i64[1, 10556, 1] = torch.ops.aten.view.default(primals_2, [1, -1, 1]);  primals_2 = None\n",
      "        expand: i64[3, 10556, 16] = torch.ops.aten.expand.default(view, [3, 10556, 16]);  view = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:54, code: return src.new_zeros(size).scatter_add_(dim, index, src)\n",
      "        full: f32[3, 2708, 16] = torch.ops.aten.full.default([3, 2708, 16], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)\n",
      "        scatter_add: f32[3, 2708, 16] = torch.ops.aten.scatter_add.default(full, 1, expand, primals_1);  full = primals_1 = None\n",
      "        return [scatter_add, expand]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.int64, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[1, 10556, 1], stride=[10556, 1, 1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.int64, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[3, 10556, 16], stride=[0, 1, 0]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 16],\n",
      "    origins={full}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  ComputedBuffer(name='buf0', layout=FlexibleLayout('cuda', torch.float32, size=[3, 2708, 16], stride=[43328, 16, 1]), data=Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 16],\n",
      "    origins={full, view, primals_2, primals_1, scatter_add, expand}\n",
      "  ))\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[131072], filename=__file__, meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 129984\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = 0.0\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp0, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__1 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[524288], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': ['out_ptr0'], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 506688\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 16) % 10556\n",
      "    x3 = xindex\n",
      "    x0 = xindex % 16\n",
      "    x2 = (xindex // 168896)\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x3), xmask)\n",
      "    tl.atomic_add(out_ptr0 + (x0 + (16*tmp0) + (43328*x2) + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, primals_2 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 2708, 16), (43328, 16, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(buf0, 129984, grid=grid(129984), stream=stream0)\n",
      "        triton__1.run(primals_2, primals_1, buf0, 506688, grid=grid(506688), stream=stream0)\n",
      "        del primals_1\n",
      "        return (buf0, as_strided(primals_2, (3, 10556, 16), (0, 1, 0)), )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_1 = rand_strided((3, 10556, 16), (168896, 16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    primals_2 = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.int64)\n",
      "    print_performance(lambda: call([primals_1, primals_2]))\n",
      "\n",
      "inductor code end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-09 10:31:41,304] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 4\n",
      "[2023-03-09 10:31:41,305] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,307] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_5 <eval_with_key>.39 opcode       name          target        args                               kwargs\n",
      "-----------  ------------  ------------  ---------------------------------  --------\n",
      "placeholder  inputs        inputs        ()                                 {}\n",
      "placeholder  index         index         ()                                 {}\n",
      "call_method  view          view          (index, [1, -1, 1])                {}\n",
      "call_method  expand_as     expand_as     (view, inputs)                     {}\n",
      "call_method  new_zeros     new_zeros     (inputs, [3, 2708, 16])            {}\n",
      "call_method  scatter_add_  scatter_add_  (new_zeros, 1, expand_as, inputs)  {}\n",
      "output       output        output        ((scatter_add_,),)                 {}\n",
      "\n",
      "[2023-03-09 10:31:41,307] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE aggregate /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 565 \n",
      "578           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_ATTR                0 (aggr_module)\n",
      "              4 LOAD_FAST                1 (inputs)\n",
      "              6 LOAD_FAST                2 (index)\n",
      "              8 LOAD_FAST                3 (ptr)\n",
      "             10 LOAD_FAST                4 (dim_size)\n",
      "\n",
      "579          12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                1 (node_dim)\n",
      "\n",
      "578          16 LOAD_CONST               1 (('ptr', 'dim_size', 'dim'))\n",
      "             18 CALL_FUNCTION_KW         5\n",
      "             20 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,308] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE aggregate /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 565 \n",
      "565           0 LOAD_GLOBAL              4 (__compiled_fn_5)\n",
      "              2 LOAD_FAST                1 (inputs)\n",
      "              4 LOAD_FAST                2 (index)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,310] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'ptr' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(ptr, 9488912)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 139870845922656)'],\n",
      "                'obj_weakref': <weakref at 0x7f36ac9fb720; to 'ARMAConv' at 0x7f363815ed60>\n",
      "                'guarded_class': <weakref at 0x7f36366bb090; to 'type' at 0x7c28600 (ARMAConv)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'index' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84fd4a0; to 'Tensor' at 0x7f36acba5ae0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'inputs' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84ae630; to 'Tensor' at 0x7f36a84fd2c0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'dim_size' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(dim_size, 9487360)', 'dim_size == 2708'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769d5090; to 'type' at 0x90c400 (int)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'list' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_geometric_dot_utils_dot_scatter.broadcast' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_geometric_dot_nn_dot_aggr_dot_base.scatter' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.node_dim' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.aggr_module' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,313] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing update\n",
      "[2023-03-09 10:31:41,317] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>\n",
      "[2023-03-09 10:31:41,372] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,403] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 5\n",
      "[2023-03-09 10:31:41,405] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-03-09 10:31:41,414] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0'), SchedulerNode(name='buf1')]\n",
      "[2023-03-09 10:31:41,455] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/3c/c3coc7qup7zx4adpp7bnggw2qy5gwf3flnrcvihvuutlfun3erj6.py\n",
      "[2023-03-09 10:31:41,455] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 5\n",
      "[2023-03-09 10:31:41,456] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,457] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_6 <eval_with_key>.50 opcode         name            target                                       args                  kwargs\n",
      "-------------  --------------  -------------------------------------------  --------------------  ------------------\n",
      "placeholder    _stack1         _stack1                                      ()                    {}\n",
      "call_function  relu            <function relu at 0x7f363776e5e0>            (_stack1,)            {}\n",
      "call_function  lowmem_dropout  <function lowmem_dropout at 0x7f359c059ca0>  (relu,)               {'training': True}\n",
      "output         output          output                                       ((lowmem_dropout,),)  {}\n",
      "\n",
      "[2023-03-09 10:31:41,459] torch._dynamo.symbolic_convert: [INFO] __resume_at_66_7 function\n",
      "[2023-03-09 10:31:41,460] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE <graph break in forward> /home/chunwei/project/explor/torch/arma.py line 52 \n",
      " 52           0 LOAD_FAST                0 (___stack0)\n",
      "              2 LOAD_FAST                1 (___stack1)\n",
      "              4 JUMP_ABSOLUTE           36\n",
      "              6 LOAD_GLOBAL              0 (F)\n",
      "              8 LOAD_ATTR                1 (dropout)\n",
      "             10 LOAD_FAST                4 (x)\n",
      "             12 LOAD_FAST                2 (self)\n",
      "             14 LOAD_ATTR                2 (training)\n",
      "             16 LOAD_CONST               1 (('training',))\n",
      "             18 CALL_FUNCTION_KW         2\n",
      "             20 STORE_FAST               4 (x)\n",
      "             22 LOAD_GLOBAL              0 (F)\n",
      "             24 LOAD_ATTR                3 (relu)\n",
      "             26 LOAD_FAST                2 (self)\n",
      "             28 LOAD_ATTR                4 (conv1)\n",
      "             30 LOAD_FAST                4 (x)\n",
      "             32 LOAD_FAST                3 (edge_index)\n",
      "             34 CALL_FUNCTION            2\n",
      "        >>   36 CALL_FUNCTION            1\n",
      "             38 STORE_FAST               4 (x)\n",
      "\n",
      " 53          40 LOAD_GLOBAL              0 (F)\n",
      "             42 LOAD_ATTR                1 (dropout)\n",
      "             44 LOAD_FAST                4 (x)\n",
      "             46 LOAD_FAST                2 (self)\n",
      "             48 LOAD_ATTR                2 (training)\n",
      "             50 LOAD_CONST               1 (('training',))\n",
      "             52 CALL_FUNCTION_KW         2\n",
      "             54 STORE_FAST               4 (x)\n",
      "\n",
      " 54          56 LOAD_FAST                2 (self)\n",
      "             58 LOAD_ATTR                5 (conv2)\n",
      "             60 LOAD_FAST                4 (x)\n",
      "             62 LOAD_FAST                3 (edge_index)\n",
      "             64 CALL_FUNCTION            2\n",
      "             66 STORE_FAST               4 (x)\n",
      "\n",
      " 55          68 LOAD_GLOBAL              0 (F)\n",
      "             70 LOAD_ATTR                6 (log_softmax)\n",
      "             72 LOAD_FAST                4 (x)\n",
      "             74 LOAD_CONST               2 (1)\n",
      "             76 LOAD_CONST               3 (('dim',))\n",
      "             78 CALL_FUNCTION_KW         2\n",
      "             80 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,461] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE <graph break in forward> /home/chunwei/project/explor/torch/arma.py line 52 \n",
      " 52           0 LOAD_GLOBAL             13 (__compiled_fn_6)\n",
      "              2 LOAD_FAST                1 (___stack1)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 STORE_FAST               5 (___graph_out_0)\n",
      "              8 LOAD_FAST                2 (self)\n",
      "             10 LOAD_ATTR                5 (conv2)\n",
      "             12 LOAD_FAST                5 (___graph_out_0)\n",
      "             14 LOAD_CONST               4 (0)\n",
      "             16 BINARY_SUBSCR\n",
      "             18 LOAD_FAST                3 (edge_index)\n",
      "\n",
      " 54          20 CALL_FUNCTION            2\n",
      "             22 LOAD_GLOBAL             14 (__resume_at_66_7)\n",
      "             24 ROT_TWO\n",
      "             26 CALL_FUNCTION            1\n",
      "             28 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,462] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 139870845923040)'],\n",
      "                'obj_weakref': <weakref at 0x7f36aca5bf40; to 'Net' at 0x7f363815eee0>\n",
      "                'guarded_class': <weakref at 0x7f35b43ecc20; to 'type' at 0x7f1e410 (Net)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local '___stack0' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(___stack0, 139870835500512)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769f3c70; to 'type' at 0x8fc9c0 (function)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local '___stack1' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36acc1d4a0; to 'Tensor' at 0x7f36ac9d9900>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'F' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.conv2' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.training' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,466] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing __collect__\n",
      "[2023-03-09 10:31:41,482] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing __collect__ (RETURN_VALUE)\n",
      "[2023-03-09 10:31:41,484] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,502] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6\n",
      "[2023-03-09 10:31:41,511] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,547] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/zq/czquq4op63r3tobc7lbnuh2sudvnfzyhkgjdoyxagxxyjwkjs2a3.py\n",
      "[2023-03-09 10:31:41,548] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6\n",
      "[2023-03-09 10:31:41,549] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,550] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_8 <eval_with_key>.61 opcode         name          target                       args                                     kwargs\n",
      "-------------  ------------  ---------------------------  ---------------------------------------  --------\n",
      "placeholder    edge_index    edge_index                   ()                                       {}\n",
      "placeholder    kwargs_x_     kwargs_x_                    ()                                       {}\n",
      "call_function  getitem       <built-in function getitem>  (edge_index, 0)                          {}\n",
      "call_method    index_select  index_select                 (kwargs_x_, -2, getitem)                 {}\n",
      "call_function  getitem_1     <built-in function getitem>  (edge_index, 1)                          {}\n",
      "call_function  getitem_2     <built-in function getitem>  (edge_index, 0)                          {}\n",
      "output         output        output                       ((index_select, getitem_1, getitem_2),)  {}\n",
      "\n",
      "[2023-03-09 10:31:41,552] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE __collect__ /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 282 \n",
      "283           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_ATTR                0 (flow)\n",
      "              4 LOAD_CONST               1 ('source_to_target')\n",
      "              6 COMPARE_OP               2 (==)\n",
      "              8 POP_JUMP_IF_FALSE       14\n",
      "             10 LOAD_CONST               2 ((1, 0))\n",
      "             12 JUMP_FORWARD             2 (to 16)\n",
      "        >>   14 LOAD_CONST               3 ((0, 1))\n",
      "        >>   16 UNPACK_SEQUENCE          2\n",
      "             18 STORE_FAST               5 (i)\n",
      "             20 STORE_FAST               6 (j)\n",
      "\n",
      "285          22 BUILD_MAP                0\n",
      "             24 STORE_FAST               7 (out)\n",
      "\n",
      "286          26 LOAD_FAST                1 (args)\n",
      "             28 GET_ITER\n",
      "        >>   30 FOR_ITER               214 (to 246)\n",
      "             32 STORE_FAST               8 (arg)\n",
      "\n",
      "287          34 LOAD_FAST                8 (arg)\n",
      "             36 LOAD_CONST               4 (-2)\n",
      "             38 LOAD_CONST               0 (None)\n",
      "             40 BUILD_SLICE              2\n",
      "             42 BINARY_SUBSCR\n",
      "             44 LOAD_CONST               5 (('_i', '_j'))\n",
      "             46 COMPARE_OP               7 (not in)\n",
      "             48 POP_JUMP_IF_FALSE       70\n",
      "\n",
      "288          50 LOAD_FAST                4 (kwargs)\n",
      "             52 LOAD_METHOD              1 (get)\n",
      "             54 LOAD_FAST                8 (arg)\n",
      "             56 LOAD_GLOBAL              2 (Parameter)\n",
      "             58 LOAD_ATTR                3 (empty)\n",
      "             60 CALL_METHOD              2\n",
      "             62 LOAD_FAST                7 (out)\n",
      "             64 LOAD_FAST                8 (arg)\n",
      "             66 STORE_SUBSCR\n",
      "             68 JUMP_ABSOLUTE           30\n",
      "\n",
      "290     >>   70 LOAD_FAST                8 (arg)\n",
      "             72 LOAD_CONST               4 (-2)\n",
      "             74 LOAD_CONST               0 (None)\n",
      "             76 BUILD_SLICE              2\n",
      "             78 BINARY_SUBSCR\n",
      "             80 LOAD_CONST               6 ('_j')\n",
      "             82 COMPARE_OP               2 (==)\n",
      "             84 POP_JUMP_IF_FALSE       90\n",
      "             86 LOAD_FAST                6 (j)\n",
      "             88 JUMP_FORWARD             2 (to 92)\n",
      "        >>   90 LOAD_FAST                5 (i)\n",
      "        >>   92 STORE_FAST               9 (dim)\n",
      "\n",
      "291          94 LOAD_FAST                4 (kwargs)\n",
      "             96 LOAD_METHOD              1 (get)\n",
      "             98 LOAD_FAST                8 (arg)\n",
      "            100 LOAD_CONST               0 (None)\n",
      "            102 LOAD_CONST               4 (-2)\n",
      "            104 BUILD_SLICE              2\n",
      "            106 BINARY_SUBSCR\n",
      "            108 LOAD_GLOBAL              2 (Parameter)\n",
      "            110 LOAD_ATTR                3 (empty)\n",
      "            112 CALL_METHOD              2\n",
      "            114 STORE_FAST              10 (data)\n",
      "\n",
      "293         116 LOAD_GLOBAL              4 (isinstance)\n",
      "            118 LOAD_FAST               10 (data)\n",
      "            120 LOAD_GLOBAL              5 (tuple)\n",
      "            122 LOAD_GLOBAL              6 (list)\n",
      "            124 BUILD_TUPLE              2\n",
      "            126 CALL_FUNCTION            2\n",
      "            128 POP_JUMP_IF_FALSE      198\n",
      "\n",
      "294         130 LOAD_GLOBAL              7 (len)\n",
      "            132 LOAD_FAST               10 (data)\n",
      "            134 CALL_FUNCTION            1\n",
      "            136 LOAD_CONST               7 (2)\n",
      "            138 COMPARE_OP               2 (==)\n",
      "            140 POP_JUMP_IF_TRUE       146\n",
      "            142 LOAD_GLOBAL              8 (AssertionError)\n",
      "            144 RAISE_VARARGS            1\n",
      "\n",
      "295     >>  146 LOAD_GLOBAL              4 (isinstance)\n",
      "            148 LOAD_FAST               10 (data)\n",
      "            150 LOAD_CONST               8 (1)\n",
      "            152 LOAD_FAST                9 (dim)\n",
      "            154 BINARY_SUBTRACT\n",
      "            156 BINARY_SUBSCR\n",
      "            158 LOAD_GLOBAL              9 (Tensor)\n",
      "            160 CALL_FUNCTION            2\n",
      "            162 POP_JUMP_IF_FALSE      190\n",
      "\n",
      "296         164 LOAD_FAST                0 (self)\n",
      "            166 LOAD_METHOD             10 (__set_size__)\n",
      "            168 LOAD_FAST                3 (size)\n",
      "            170 LOAD_CONST               8 (1)\n",
      "            172 LOAD_FAST                9 (dim)\n",
      "            174 BINARY_SUBTRACT\n",
      "            176 LOAD_FAST               10 (data)\n",
      "            178 LOAD_CONST               8 (1)\n",
      "            180 LOAD_FAST                9 (dim)\n",
      "            182 BINARY_SUBTRACT\n",
      "            184 BINARY_SUBSCR\n",
      "            186 CALL_METHOD              3\n",
      "            188 POP_TOP\n",
      "\n",
      "297     >>  190 LOAD_FAST               10 (data)\n",
      "            192 LOAD_FAST                9 (dim)\n",
      "            194 BINARY_SUBSCR\n",
      "            196 STORE_FAST              10 (data)\n",
      "\n",
      "299     >>  198 LOAD_GLOBAL              4 (isinstance)\n",
      "            200 LOAD_FAST               10 (data)\n",
      "            202 LOAD_GLOBAL              9 (Tensor)\n",
      "            204 CALL_FUNCTION            2\n",
      "            206 POP_JUMP_IF_FALSE      236\n",
      "\n",
      "300         208 LOAD_FAST                0 (self)\n",
      "            210 LOAD_METHOD             10 (__set_size__)\n",
      "            212 LOAD_FAST                3 (size)\n",
      "            214 LOAD_FAST                9 (dim)\n",
      "            216 LOAD_FAST               10 (data)\n",
      "            218 CALL_METHOD              3\n",
      "            220 POP_TOP\n",
      "\n",
      "301         222 LOAD_FAST                0 (self)\n",
      "            224 LOAD_METHOD             11 (__lift__)\n",
      "            226 LOAD_FAST               10 (data)\n",
      "            228 LOAD_FAST                2 (edge_index)\n",
      "            230 LOAD_FAST                9 (dim)\n",
      "            232 CALL_METHOD              3\n",
      "            234 STORE_FAST              10 (data)\n",
      "\n",
      "303     >>  236 LOAD_FAST               10 (data)\n",
      "            238 LOAD_FAST                7 (out)\n",
      "            240 LOAD_FAST                8 (arg)\n",
      "            242 STORE_SUBSCR\n",
      "            244 JUMP_ABSOLUTE           30\n",
      "\n",
      "305     >>  246 LOAD_GLOBAL             12 (is_torch_sparse_tensor)\n",
      "            248 LOAD_FAST                2 (edge_index)\n",
      "            250 CALL_FUNCTION            1\n",
      "            252 EXTENDED_ARG             1\n",
      "            254 POP_JUMP_IF_FALSE      434\n",
      "\n",
      "306         256 LOAD_FAST                2 (edge_index)\n",
      "            258 LOAD_ATTR               13 (requires_grad)\n",
      "            260 EXTENDED_ARG             1\n",
      "            262 POP_JUMP_IF_FALSE      290\n",
      "\n",
      "307         264 LOAD_FAST                2 (edge_index)\n",
      "            266 LOAD_METHOD             14 (coalesce)\n",
      "            268 CALL_METHOD              0\n",
      "            270 STORE_FAST               2 (edge_index)\n",
      "\n",
      "308         272 LOAD_FAST                2 (edge_index)\n",
      "            274 LOAD_METHOD             15 (indices)\n",
      "            276 CALL_METHOD              0\n",
      "            278 STORE_FAST              11 (indices)\n",
      "\n",
      "309         280 LOAD_FAST                2 (edge_index)\n",
      "            282 LOAD_METHOD             16 (values)\n",
      "            284 CALL_METHOD              0\n",
      "            286 STORE_FAST              12 (values)\n",
      "            288 JUMP_FORWARD            16 (to 306)\n",
      "\n",
      "311     >>  290 LOAD_FAST                2 (edge_index)\n",
      "            292 LOAD_METHOD             17 (_indices)\n",
      "            294 CALL_METHOD              0\n",
      "            296 STORE_FAST              11 (indices)\n",
      "\n",
      "312         298 LOAD_FAST                2 (edge_index)\n",
      "            300 LOAD_METHOD             18 (_values)\n",
      "            302 CALL_METHOD              0\n",
      "            304 STORE_FAST              12 (values)\n",
      "\n",
      "313     >>  306 LOAD_FAST                2 (edge_index)\n",
      "            308 LOAD_FAST                7 (out)\n",
      "            310 LOAD_CONST               9 ('adj_t')\n",
      "            312 STORE_SUBSCR\n",
      "\n",
      "314         314 LOAD_CONST               0 (None)\n",
      "            316 LOAD_FAST                7 (out)\n",
      "            318 LOAD_CONST              10 ('edge_index')\n",
      "            320 STORE_SUBSCR\n",
      "\n",
      "315         322 LOAD_FAST               11 (indices)\n",
      "            324 LOAD_CONST              11 (0)\n",
      "            326 BINARY_SUBSCR\n",
      "            328 LOAD_FAST                7 (out)\n",
      "            330 LOAD_CONST              12 ('edge_index_i')\n",
      "            332 STORE_SUBSCR\n",
      "\n",
      "316         334 LOAD_FAST               11 (indices)\n",
      "            336 LOAD_CONST               8 (1)\n",
      "            338 BINARY_SUBSCR\n",
      "            340 LOAD_FAST                7 (out)\n",
      "            342 LOAD_CONST              13 ('edge_index_j')\n",
      "            344 STORE_SUBSCR\n",
      "\n",
      "317         346 LOAD_CONST               0 (None)\n",
      "            348 LOAD_FAST                7 (out)\n",
      "            350 LOAD_CONST              14 ('ptr')\n",
      "            352 STORE_SUBSCR\n",
      "\n",
      "318         354 LOAD_FAST                7 (out)\n",
      "            356 LOAD_METHOD              1 (get)\n",
      "            358 LOAD_CONST              15 ('edge_weight')\n",
      "            360 LOAD_CONST               0 (None)\n",
      "            362 CALL_METHOD              2\n",
      "            364 LOAD_CONST               0 (None)\n",
      "            366 COMPARE_OP               8 (is)\n",
      "            368 EXTENDED_ARG             1\n",
      "            370 POP_JUMP_IF_FALSE      380\n",
      "\n",
      "319         372 LOAD_FAST               12 (values)\n",
      "            374 LOAD_FAST                7 (out)\n",
      "            376 LOAD_CONST              15 ('edge_weight')\n",
      "            378 STORE_SUBSCR\n",
      "\n",
      "320     >>  380 LOAD_FAST                7 (out)\n",
      "            382 LOAD_METHOD              1 (get)\n",
      "            384 LOAD_CONST              16 ('edge_attr')\n",
      "            386 LOAD_CONST               0 (None)\n",
      "            388 CALL_METHOD              2\n",
      "            390 LOAD_CONST               0 (None)\n",
      "            392 COMPARE_OP               8 (is)\n",
      "            394 EXTENDED_ARG             1\n",
      "            396 POP_JUMP_IF_FALSE      406\n",
      "\n",
      "321         398 LOAD_FAST               12 (values)\n",
      "            400 LOAD_FAST                7 (out)\n",
      "            402 LOAD_CONST              16 ('edge_attr')\n",
      "            404 STORE_SUBSCR\n",
      "\n",
      "322     >>  406 LOAD_FAST                7 (out)\n",
      "            408 LOAD_METHOD              1 (get)\n",
      "            410 LOAD_CONST              17 ('edge_type')\n",
      "            412 LOAD_CONST               0 (None)\n",
      "            414 CALL_METHOD              2\n",
      "            416 LOAD_CONST               0 (None)\n",
      "            418 COMPARE_OP               8 (is)\n",
      "            420 EXTENDED_ARG             2\n",
      "            422 POP_JUMP_IF_FALSE      662\n",
      "\n",
      "323         424 LOAD_FAST               12 (values)\n",
      "            426 LOAD_FAST                7 (out)\n",
      "            428 LOAD_CONST              17 ('edge_type')\n",
      "            430 STORE_SUBSCR\n",
      "            432 JUMP_FORWARD           228 (to 662)\n",
      "\n",
      "325     >>  434 LOAD_GLOBAL              4 (isinstance)\n",
      "            436 LOAD_FAST                2 (edge_index)\n",
      "            438 LOAD_GLOBAL              9 (Tensor)\n",
      "            440 CALL_FUNCTION            2\n",
      "            442 EXTENDED_ARG             1\n",
      "            444 POP_JUMP_IF_FALSE      496\n",
      "\n",
      "326         446 LOAD_CONST               0 (None)\n",
      "            448 LOAD_FAST                7 (out)\n",
      "            450 LOAD_CONST               9 ('adj_t')\n",
      "            452 STORE_SUBSCR\n",
      "\n",
      "327         454 LOAD_FAST                2 (edge_index)\n",
      "            456 LOAD_FAST                7 (out)\n",
      "            458 LOAD_CONST              10 ('edge_index')\n",
      "            460 STORE_SUBSCR\n",
      "\n",
      "328         462 LOAD_FAST                2 (edge_index)\n",
      "            464 LOAD_FAST                5 (i)\n",
      "            466 BINARY_SUBSCR\n",
      "            468 LOAD_FAST                7 (out)\n",
      "            470 LOAD_CONST              12 ('edge_index_i')\n",
      "            472 STORE_SUBSCR\n",
      "\n",
      "329         474 LOAD_FAST                2 (edge_index)\n",
      "            476 LOAD_FAST                6 (j)\n",
      "            478 BINARY_SUBSCR\n",
      "            480 LOAD_FAST                7 (out)\n",
      "            482 LOAD_CONST              13 ('edge_index_j')\n",
      "            484 STORE_SUBSCR\n",
      "\n",
      "330         486 LOAD_CONST               0 (None)\n",
      "            488 LOAD_FAST                7 (out)\n",
      "            490 LOAD_CONST              14 ('ptr')\n",
      "            492 STORE_SUBSCR\n",
      "            494 JUMP_FORWARD           166 (to 662)\n",
      "\n",
      "332     >>  496 LOAD_GLOBAL              4 (isinstance)\n",
      "            498 LOAD_FAST                2 (edge_index)\n",
      "            500 LOAD_GLOBAL             19 (SparseTensor)\n",
      "            502 CALL_FUNCTION            2\n",
      "            504 EXTENDED_ARG             2\n",
      "            506 POP_JUMP_IF_FALSE      662\n",
      "\n",
      "333         508 LOAD_FAST                2 (edge_index)\n",
      "            510 LOAD_FAST                7 (out)\n",
      "            512 LOAD_CONST               9 ('adj_t')\n",
      "            514 STORE_SUBSCR\n",
      "\n",
      "334         516 LOAD_CONST               0 (None)\n",
      "            518 LOAD_FAST                7 (out)\n",
      "            520 LOAD_CONST              10 ('edge_index')\n",
      "            522 STORE_SUBSCR\n",
      "\n",
      "335         524 LOAD_FAST                2 (edge_index)\n",
      "            526 LOAD_ATTR               20 (storage)\n",
      "            528 LOAD_METHOD             21 (row)\n",
      "            530 CALL_METHOD              0\n",
      "            532 LOAD_FAST                7 (out)\n",
      "            534 LOAD_CONST              12 ('edge_index_i')\n",
      "            536 STORE_SUBSCR\n",
      "\n",
      "336         538 LOAD_FAST                2 (edge_index)\n",
      "            540 LOAD_ATTR               20 (storage)\n",
      "            542 LOAD_METHOD             22 (col)\n",
      "            544 CALL_METHOD              0\n",
      "            546 LOAD_FAST                7 (out)\n",
      "            548 LOAD_CONST              13 ('edge_index_j')\n",
      "            550 STORE_SUBSCR\n",
      "\n",
      "337         552 LOAD_FAST                2 (edge_index)\n",
      "            554 LOAD_ATTR               20 (storage)\n",
      "            556 LOAD_METHOD             23 (rowptr)\n",
      "            558 CALL_METHOD              0\n",
      "            560 LOAD_FAST                7 (out)\n",
      "            562 LOAD_CONST              14 ('ptr')\n",
      "            564 STORE_SUBSCR\n",
      "\n",
      "338         566 LOAD_FAST                7 (out)\n",
      "            568 LOAD_METHOD              1 (get)\n",
      "            570 LOAD_CONST              15 ('edge_weight')\n",
      "            572 LOAD_CONST               0 (None)\n",
      "            574 CALL_METHOD              2\n",
      "            576 LOAD_CONST               0 (None)\n",
      "            578 COMPARE_OP               8 (is)\n",
      "            580 EXTENDED_ARG             2\n",
      "            582 POP_JUMP_IF_FALSE      598\n",
      "\n",
      "339         584 LOAD_FAST                2 (edge_index)\n",
      "            586 LOAD_ATTR               20 (storage)\n",
      "            588 LOAD_METHOD             24 (value)\n",
      "            590 CALL_METHOD              0\n",
      "            592 LOAD_FAST                7 (out)\n",
      "            594 LOAD_CONST              15 ('edge_weight')\n",
      "            596 STORE_SUBSCR\n",
      "\n",
      "340     >>  598 LOAD_FAST                7 (out)\n",
      "            600 LOAD_METHOD              1 (get)\n",
      "            602 LOAD_CONST              16 ('edge_attr')\n",
      "            604 LOAD_CONST               0 (None)\n",
      "            606 CALL_METHOD              2\n",
      "            608 LOAD_CONST               0 (None)\n",
      "            610 COMPARE_OP               8 (is)\n",
      "            612 EXTENDED_ARG             2\n",
      "            614 POP_JUMP_IF_FALSE      630\n",
      "\n",
      "341         616 LOAD_FAST                2 (edge_index)\n",
      "            618 LOAD_ATTR               20 (storage)\n",
      "            620 LOAD_METHOD             24 (value)\n",
      "            622 CALL_METHOD              0\n",
      "            624 LOAD_FAST                7 (out)\n",
      "            626 LOAD_CONST              16 ('edge_attr')\n",
      "            628 STORE_SUBSCR\n",
      "\n",
      "342     >>  630 LOAD_FAST                7 (out)\n",
      "            632 LOAD_METHOD              1 (get)\n",
      "            634 LOAD_CONST              17 ('edge_type')\n",
      "            636 LOAD_CONST               0 (None)\n",
      "            638 CALL_METHOD              2\n",
      "            640 LOAD_CONST               0 (None)\n",
      "            642 COMPARE_OP               8 (is)\n",
      "            644 EXTENDED_ARG             2\n",
      "            646 POP_JUMP_IF_FALSE      662\n",
      "\n",
      "343         648 LOAD_FAST                2 (edge_index)\n",
      "            650 LOAD_ATTR               20 (storage)\n",
      "            652 LOAD_METHOD             24 (value)\n",
      "            654 CALL_METHOD              0\n",
      "            656 LOAD_FAST                7 (out)\n",
      "            658 LOAD_CONST              17 ('edge_type')\n",
      "            660 STORE_SUBSCR\n",
      "\n",
      "345     >>  662 LOAD_FAST                7 (out)\n",
      "            664 LOAD_CONST              12 ('edge_index_i')\n",
      "            666 BINARY_SUBSCR\n",
      "            668 LOAD_FAST                7 (out)\n",
      "            670 LOAD_CONST              18 ('index')\n",
      "            672 STORE_SUBSCR\n",
      "\n",
      "346         674 LOAD_FAST                3 (size)\n",
      "            676 LOAD_FAST                7 (out)\n",
      "            678 LOAD_CONST              19 ('size')\n",
      "            680 STORE_SUBSCR\n",
      "\n",
      "347         682 LOAD_FAST                3 (size)\n",
      "            684 LOAD_FAST                5 (i)\n",
      "            686 BINARY_SUBSCR\n",
      "            688 LOAD_CONST               0 (None)\n",
      "            690 COMPARE_OP               9 (is not)\n",
      "            692 EXTENDED_ARG             2\n",
      "            694 POP_JUMP_IF_FALSE      704\n",
      "            696 LOAD_FAST                3 (size)\n",
      "            698 LOAD_FAST                5 (i)\n",
      "            700 BINARY_SUBSCR\n",
      "            702 JUMP_FORWARD             6 (to 710)\n",
      "        >>  704 LOAD_FAST                3 (size)\n",
      "            706 LOAD_FAST                6 (j)\n",
      "            708 BINARY_SUBSCR\n",
      "        >>  710 LOAD_FAST                7 (out)\n",
      "            712 LOAD_CONST              20 ('size_i')\n",
      "            714 STORE_SUBSCR\n",
      "\n",
      "348         716 LOAD_FAST                3 (size)\n",
      "            718 LOAD_FAST                6 (j)\n",
      "            720 BINARY_SUBSCR\n",
      "            722 LOAD_CONST               0 (None)\n",
      "            724 COMPARE_OP               9 (is not)\n",
      "            726 EXTENDED_ARG             2\n",
      "            728 POP_JUMP_IF_FALSE      738\n",
      "            730 LOAD_FAST                3 (size)\n",
      "            732 LOAD_FAST                6 (j)\n",
      "            734 BINARY_SUBSCR\n",
      "            736 JUMP_FORWARD             6 (to 744)\n",
      "        >>  738 LOAD_FAST                3 (size)\n",
      "            740 LOAD_FAST                5 (i)\n",
      "            742 BINARY_SUBSCR\n",
      "        >>  744 LOAD_FAST                7 (out)\n",
      "            746 LOAD_CONST              21 ('size_j')\n",
      "            748 STORE_SUBSCR\n",
      "\n",
      "349         750 LOAD_FAST                7 (out)\n",
      "            752 LOAD_CONST              20 ('size_i')\n",
      "            754 BINARY_SUBSCR\n",
      "            756 LOAD_FAST                7 (out)\n",
      "            758 LOAD_CONST              22 ('dim_size')\n",
      "            760 STORE_SUBSCR\n",
      "\n",
      "351         762 LOAD_FAST                7 (out)\n",
      "            764 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,553] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE __collect__ /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 282 \n",
      "282           0 LOAD_GLOBAL             26 (__compiled_fn_8)\n",
      "              2 LOAD_FAST                2 (edge_index)\n",
      "              4 LOAD_FAST                4 (kwargs)\n",
      "              6 LOAD_CONST              25 ('x')\n",
      "              8 BINARY_SUBSCR\n",
      "             10 CALL_FUNCTION            2\n",
      "             12 STORE_FAST              13 (___graph_out_0)\n",
      "             14 LOAD_FAST                3 (size)\n",
      "             16 STORE_FAST              14 (___tmp_0)\n",
      "             18 LOAD_CONST              15 ('edge_weight')\n",
      "             20 LOAD_FAST                4 (kwargs)\n",
      "             22 LOAD_CONST              15 ('edge_weight')\n",
      "             24 BINARY_SUBSCR\n",
      "             26 LOAD_CONST              23 ('x_j')\n",
      "             28 LOAD_FAST               13 (___graph_out_0)\n",
      "             30 LOAD_CONST              11 (0)\n",
      "             32 BINARY_SUBSCR\n",
      "             34 LOAD_CONST               9 ('adj_t')\n",
      "             36 LOAD_CONST               0 (None)\n",
      "             38 LOAD_CONST              10 ('edge_index')\n",
      "             40 LOAD_FAST                2 (edge_index)\n",
      "             42 LOAD_CONST              12 ('edge_index_i')\n",
      "             44 LOAD_FAST               13 (___graph_out_0)\n",
      "             46 LOAD_CONST               8 (1)\n",
      "             48 BINARY_SUBSCR\n",
      "             50 LOAD_CONST              13 ('edge_index_j')\n",
      "             52 LOAD_FAST               13 (___graph_out_0)\n",
      "             54 LOAD_CONST               7 (2)\n",
      "             56 BINARY_SUBSCR\n",
      "             58 LOAD_CONST              14 ('ptr')\n",
      "             60 LOAD_CONST               0 (None)\n",
      "             62 LOAD_CONST              18 ('index')\n",
      "             64 LOAD_FAST               13 (___graph_out_0)\n",
      "             66 LOAD_CONST               8 (1)\n",
      "             68 BINARY_SUBSCR\n",
      "             70 LOAD_CONST              19 ('size')\n",
      "             72 LOAD_FAST               14 (___tmp_0)\n",
      "             74 LOAD_CONST              20 ('size_i')\n",
      "             76 LOAD_CONST              24 (2708)\n",
      "             78 LOAD_CONST              21 ('size_j')\n",
      "             80 LOAD_CONST              24 (2708)\n",
      "             82 LOAD_CONST              22 ('dim_size')\n",
      "             84 LOAD_CONST              24 (2708)\n",
      "             86 BUILD_MAP               12\n",
      "             88 LOAD_CONST              24 (2708)\n",
      "             90 LOAD_FAST                3 (size)\n",
      "             92 LOAD_CONST               8 (1)\n",
      "             94 BINARY_SUBSCR\n",
      "             96 BUILD_LIST               2\n",
      "             98 LOAD_FAST                3 (size)\n",
      "            100 LOAD_CONST               0 (None)\n",
      "            102 LOAD_CONST               0 (None)\n",
      "            104 BUILD_SLICE              2\n",
      "            106 STORE_SUBSCR\n",
      "            108 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,555] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'args' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(args, 9451840)', \"args == {'edge_weight', 'x_j'}\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e8220; to 'type' at 0x903940 (set)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'args' LIST_LENGTH\n",
      "            {\n",
      "                'guard_types': ['LIST_LENGTH'],\n",
      "                'code': ['___check_type_id(args, 9451840)', 'len(args) == 2'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e8220; to 'type' at 0x903940 (set)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 139870845919872)'],\n",
      "                'obj_weakref': <weakref at 0x7f36a8447680; to 'ARMAConv' at 0x7f363815e280>\n",
      "                'guarded_class': <weakref at 0x7f36366bb090; to 'type' at 0x7c28600 (ARMAConv)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'size' EQUALS_MATCH\n",
      "            {\n",
      "                'guard_types': ['LIST_LENGTH', 'EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(size, 9465376)', 'len(size) == 2', '___check_type_id(size[0], 9474080)', '___check_type_id(size[1], 9474080)', 'size == [None, None]'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769ddae0; to 'type' at 0x906e20 (list)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'kwargs' DICT_KEYS\n",
      "            {\n",
      "                'guard_types': ['DICT_KEYS'],\n",
      "                'code': ['___check_type_id(kwargs, 9490176)', \"set(kwargs.keys()) == {'edge_weight', 'x'}\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e20e0; to 'type' at 0x90cf00 (dict)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'size[0]' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(size[0], 9488912)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'size[1]' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(size[1], 9488912)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TYPE_MATCH\n",
      "            {\n",
      "                'guard_types': ['TYPE_MATCH'],\n",
      "                'code': ['___check_type_id(edge_index, 98247040)'],\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_index' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['x']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a8447770; to 'Tensor' at 0x7f36ac9fe310>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_weight']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84476d0; to 'Tensor' at 0x7f36ac9d4310>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'list' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'tuple' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'Tensor' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'Parameter' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'isinstance' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'is_torch_sparse_tensor' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_geometric_dot_utils_dot_sparse.Tensor' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.flow' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.node_dim' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,560] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing distribute\n",
      "[2023-03-09 10:31:41,565] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE distribute /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/utils/inspector.py line 52 \n",
      " 53           0 BUILD_MAP                0\n",
      "              2 STORE_FAST               3 (out)\n",
      "\n",
      " 54           4 LOAD_FAST                0 (self)\n",
      "              6 LOAD_ATTR                0 (params)\n",
      "              8 LOAD_FAST                1 (func_name)\n",
      "             10 BINARY_SUBSCR\n",
      "             12 LOAD_METHOD              1 (items)\n",
      "             14 CALL_METHOD              0\n",
      "             16 GET_ITER\n",
      "        >>   18 FOR_ITER                80 (to 100)\n",
      "             20 UNPACK_SEQUENCE          2\n",
      "             22 STORE_FAST               4 (key)\n",
      "             24 STORE_FAST               5 (param)\n",
      "\n",
      " 55          26 LOAD_FAST                2 (kwargs)\n",
      "             28 LOAD_METHOD              2 (get)\n",
      "             30 LOAD_FAST                4 (key)\n",
      "             32 LOAD_GLOBAL              3 (inspect)\n",
      "             34 LOAD_ATTR                4 (Parameter)\n",
      "             36 LOAD_ATTR                5 (empty)\n",
      "             38 CALL_METHOD              2\n",
      "             40 STORE_FAST               6 (data)\n",
      "\n",
      " 56          42 LOAD_FAST                6 (data)\n",
      "             44 LOAD_GLOBAL              3 (inspect)\n",
      "             46 LOAD_ATTR                4 (Parameter)\n",
      "             48 LOAD_ATTR                5 (empty)\n",
      "             50 COMPARE_OP               8 (is)\n",
      "             52 POP_JUMP_IF_FALSE       90\n",
      "\n",
      " 57          54 LOAD_FAST                5 (param)\n",
      "             56 LOAD_ATTR                6 (default)\n",
      "             58 LOAD_GLOBAL              3 (inspect)\n",
      "             60 LOAD_ATTR                4 (Parameter)\n",
      "             62 LOAD_ATTR                5 (empty)\n",
      "             64 COMPARE_OP               8 (is)\n",
      "             66 POP_JUMP_IF_FALSE       84\n",
      "\n",
      " 58          68 LOAD_GLOBAL              7 (TypeError)\n",
      "             70 LOAD_CONST               1 ('Required parameter ')\n",
      "             72 LOAD_FAST                4 (key)\n",
      "             74 FORMAT_VALUE             0\n",
      "             76 LOAD_CONST               2 (' is empty.')\n",
      "             78 BUILD_STRING             3\n",
      "             80 CALL_FUNCTION            1\n",
      "             82 RAISE_VARARGS            1\n",
      "\n",
      " 59     >>   84 LOAD_FAST                5 (param)\n",
      "             86 LOAD_ATTR                6 (default)\n",
      "             88 STORE_FAST               6 (data)\n",
      "\n",
      " 60     >>   90 LOAD_FAST                6 (data)\n",
      "             92 LOAD_FAST                3 (out)\n",
      "             94 LOAD_FAST                4 (key)\n",
      "             96 STORE_SUBSCR\n",
      "             98 JUMP_ABSOLUTE           18\n",
      "\n",
      " 61     >>  100 LOAD_FAST                3 (out)\n",
      "            102 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,566] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE distribute /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/utils/inspector.py line 52 \n",
      " 52           0 BUILD_MAP                0\n",
      "              2 STORE_FAST               3 (out)\n",
      "\n",
      " 54           4 LOAD_FAST                0 (self)\n",
      "              6 LOAD_ATTR                0 (params)\n",
      "              8 LOAD_FAST                1 (func_name)\n",
      "             10 BINARY_SUBSCR\n",
      "             12 LOAD_ATTR                1 (items)\n",
      "             14 CALL_FUNCTION            0\n",
      "             16 GET_ITER\n",
      "        >>   18 FOR_ITER                80 (to 100)\n",
      "             20 UNPACK_SEQUENCE          2\n",
      "             22 STORE_FAST               4 (key)\n",
      "             24 STORE_FAST               5 (param)\n",
      "\n",
      " 55          26 LOAD_FAST                2 (kwargs)\n",
      "             28 LOAD_ATTR                2 (get)\n",
      "             30 LOAD_FAST                4 (key)\n",
      "             32 LOAD_GLOBAL              3 (inspect)\n",
      "             34 LOAD_ATTR                4 (Parameter)\n",
      "             36 LOAD_ATTR                5 (empty)\n",
      "             38 CALL_FUNCTION            2\n",
      "             40 STORE_FAST               6 (data)\n",
      "\n",
      " 56          42 LOAD_FAST                6 (data)\n",
      "             44 LOAD_GLOBAL              3 (inspect)\n",
      "             46 LOAD_ATTR                4 (Parameter)\n",
      "             48 LOAD_ATTR                5 (empty)\n",
      "             50 COMPARE_OP               8 (is)\n",
      "             52 POP_JUMP_IF_FALSE       90\n",
      "\n",
      " 57          54 LOAD_FAST                5 (param)\n",
      "             56 LOAD_ATTR                6 (default)\n",
      "             58 LOAD_GLOBAL              3 (inspect)\n",
      "             60 LOAD_ATTR                4 (Parameter)\n",
      "             62 LOAD_ATTR                5 (empty)\n",
      "             64 COMPARE_OP               8 (is)\n",
      "             66 POP_JUMP_IF_FALSE       84\n",
      "\n",
      " 58          68 LOAD_GLOBAL              7 (TypeError)\n",
      "             70 LOAD_CONST               1 ('Required parameter ')\n",
      "             72 LOAD_FAST                4 (key)\n",
      "             74 FORMAT_VALUE             0\n",
      "             76 LOAD_CONST               2 (' is empty.')\n",
      "             78 BUILD_STRING             3\n",
      "             80 CALL_FUNCTION            1\n",
      "             82 RAISE_VARARGS            1\n",
      "\n",
      " 59     >>   84 LOAD_FAST                5 (param)\n",
      "             86 LOAD_ATTR                6 (default)\n",
      "             88 STORE_FAST               6 (data)\n",
      "\n",
      " 60     >>   90 LOAD_FAST                6 (data)\n",
      "             92 LOAD_FAST                3 (out)\n",
      "             94 LOAD_FAST                4 (key)\n",
      "             96 STORE_SUBSCR\n",
      "             98 JUMP_ABSOLUTE           18\n",
      "\n",
      " 61     >>  100 LOAD_FAST                3 (out)\n",
      "            102 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,567] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'kwargs' DICT_KEYS\n",
      "            {\n",
      "                'guard_types': ['DICT_KEYS'],\n",
      "                'code': ['___check_type_id(kwargs, 9490176)', \"set(kwargs.keys()) == {'edge_index_i', 'size_j', 'edge_index_j', 'index', 'edge_index', 'size', 'x_j', 'dim_size', 'edge_weight', 'size_i', 'adj_t', 'ptr'}\"],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769e20e0; to 'type' at 0x90cf00 (dict)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['x_j']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a83d4680; to 'Tensor' at 0x7f36ac9d46d0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['index']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36ac959090; to 'Tensor' at 0x7f36a84fd2c0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_index']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36aca5f040; to 'Tensor' at 0x7f35b43ec590>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_weight']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84476d0; to 'Tensor' at 0x7f36ac9d4310>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_index_i']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36ac959090; to 'Tensor' at 0x7f36a84fd2c0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local \"kwargs['edge_index_j']\" TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a841a4f0; to 'Tensor' at 0x7f36a8447860>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,568] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing message\n",
      "[2023-03-09 10:31:41,570] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing message (RETURN_VALUE)\n",
      "[2023-03-09 10:31:41,572] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,584] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 7\n",
      "[2023-03-09 10:31:41,588] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: f32[2708, 16]):\n",
      "        # File: /home/chunwei/project/explor/torch/arma.py:52, code: x = F.relu(self.conv1(x, edge_index))\n",
      "        relu: f32[2708, 16] = torch.ops.aten.relu.default(primals_1);  primals_1 = None\n",
      "        \n",
      "        # No stacktrace found for following nodes\n",
      "        philox_seed_like: i32[] = torch.ops.prims.philox_seed_like.default(relu)\n",
      "        philox_rand_like: f32[2708, 16] = torch.ops.prims.philox_rand_like.default(relu, philox_seed_like, 0)\n",
      "        gt: b8[2708, 16] = torch.ops.aten.gt.Scalar(philox_rand_like, 0.5);  philox_rand_like = None\n",
      "        convert_element_type: f32[2708, 16] = torch.ops.prims.convert_element_type.default(gt, torch.float32);  gt = None\n",
      "        mul: f32[2708, 16] = torch.ops.aten.mul.Tensor(convert_element_type, relu);  convert_element_type = None\n",
      "        mul_1: f32[2708, 16] = torch.ops.aten.mul.Tensor(mul, 2.0);  mul = None\n",
      "        \n",
      "        # File: /home/chunwei/project/explor/torch/arma.py:52, code: x = F.relu(self.conv1(x, edge_index))\n",
      "        le: b8[2708, 16] = torch.ops.aten.le.Scalar(relu, 0);  relu = None\n",
      "        return [mul_1, philox_seed_like, le]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, i1 + 16 * i0)\n",
      "    tmp1 = relu(tmp0)\n",
      "    return tmp1\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={primals_1, relu}\n",
      "  )\n",
      "))\n",
      "** out RandSeedBuffer(name='seed_cuda_0', layout=FixedLayout('cuda', torch.int64, size=[], stride=[]))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_rand_like, primals_1, relu, philox_seed_like}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.bool,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    return tmp4\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_rand_like, relu, philox_seed_like, gt, primals_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_rand_like, gt, relu, philox_seed_like, convert_element_type, primals_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(primals_1, i1 + 16 * i0)\n",
      "    tmp7 = relu(tmp6)\n",
      "    tmp8 = tmp5 * tmp7\n",
      "    return tmp8\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_rand_like, relu, philox_seed_like, convert_element_type, gt, primals_1, mul}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(seed_cuda_0, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(primals_1, i1 + 16 * i0)\n",
      "    tmp7 = relu(tmp6)\n",
      "    tmp8 = tmp5 * tmp7\n",
      "    tmp9 = constant(2.0, torch.float32)\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    return tmp10\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_rand_like, mul, relu, gt, primals_1, philox_seed_like, convert_element_type, mul_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.bool,\n",
      "    tmp0 = load(primals_1, i1 + 16 * i0)\n",
      "    tmp1 = relu(tmp0)\n",
      "    tmp2 = constant(0, torch.float32)\n",
      "    tmp3 = tmp1 <= tmp2\n",
      "    return tmp3\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={le, primals_1, relu}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "seed_cuda_0 = None  # 12bf87036c8e625335a9db42dcf50de0c1ec952294785adced537424d5733e17\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[65536], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: '*i1', 4: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(seed0, in_ptr1, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 43328\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0_load = tl.load(seed0 + (0))\n",
      "    tmp0 = tl.broadcast_to(tmp0_load, [XBLOCK])\n",
      "    tmp6 = tl.load(in_ptr1 + (x0), xmask)\n",
      "    tmp1 = x0\n",
      "    tmp2 = tl.rand(tmp0, tmp1)\n",
      "    tmp3 = 0.5\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = tmp4.to(tl.float32)\n",
      "    tmp7 = tl.where(0 != 0, 0, tl.where(0 > tmp6, 0, tmp6))\n",
      "    tmp8 = tmp5 * tmp7\n",
      "    tmp9 = 2.0\n",
      "    tmp10 = tmp8 * tmp9\n",
      "    tmp11 = 0.0\n",
      "    tmp12 = tmp7 <= tmp11\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp10, xmask)\n",
      "    tl.store(out_ptr1 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp12, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, = args\n",
      "    args.clear()\n",
      "    torch.randint(2**31, size=(), dtype=torch.int64, out=seed_cuda_0)\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((2708, 16), (16, 1), device='cuda', dtype=torch.float32)\n",
      "        buf1 = empty_strided((2708, 16), (16, 1), device='cuda', dtype=torch.bool)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(seed_cuda_0, primals_1, buf0, buf1, 43328, grid=grid(43328), stream=stream0)\n",
      "        del primals_1\n",
      "        return (buf0, seed_cuda_0.clone(), buf1, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    seed_cuda_0 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "    primals_1 = rand_strided((2708, 16), (16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_1]))\n",
      "\n",
      "inductor code end\n",
      "__resume_at_66_7:\n",
      " 54           0 LOAD_FAST                0 (___stack0)\n",
      "              2 JUMP_ABSOLUTE           64\n",
      "              4 LOAD_GLOBAL              0 (F)\n",
      "              6 LOAD_ATTR                1 (dropout)\n",
      "              8 LOAD_FAST                2 (x)\n",
      "             10 LOAD_FAST                1 (self)\n",
      "             12 LOAD_ATTR                2 (training)\n",
      "             14 LOAD_CONST               1 (('training',))\n",
      "             16 CALL_FUNCTION_KW         2\n",
      "             18 STORE_FAST               2 (x)\n",
      "             20 LOAD_GLOBAL              0 (F)\n",
      "             22 LOAD_ATTR                3 (relu)\n",
      "             24 LOAD_FAST                1 (self)\n",
      "             26 LOAD_ATTR                4 (conv1)\n",
      "             28 LOAD_FAST                2 (x)\n",
      "             30 LOAD_FAST                3 (edge_index)\n",
      "             32 CALL_FUNCTION            2\n",
      "             34 CALL_FUNCTION            1\n",
      "             36 STORE_FAST               2 (x)\n",
      "             38 LOAD_GLOBAL              0 (F)\n",
      "             40 LOAD_ATTR                1 (dropout)\n",
      "             42 LOAD_FAST                2 (x)\n",
      "             44 LOAD_FAST                1 (self)\n",
      "             46 LOAD_ATTR                2 (training)\n",
      "             48 LOAD_CONST               1 (('training',))\n",
      "             50 CALL_FUNCTION_KW         2\n",
      "             52 STORE_FAST               2 (x)\n",
      "             54 LOAD_FAST                1 (self)\n",
      "             56 LOAD_ATTR                5 (conv2)\n",
      "             58 LOAD_FAST                2 (x)\n",
      "             60 LOAD_FAST                3 (edge_index)\n",
      "             62 CALL_FUNCTION            2\n",
      "        >>   64 STORE_FAST               2 (x)\n",
      "\n",
      " 55          66 LOAD_GLOBAL              0 (F)\n",
      "             68 LOAD_ATTR                6 (log_softmax)\n",
      "             70 LOAD_FAST                2 (x)\n",
      "             72 LOAD_CONST               2 (1)\n",
      "             74 LOAD_CONST               3 (('dim',))\n",
      "             76 CALL_FUNCTION_KW         2\n",
      "             78 RETURN_VALUE\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: i64[2, 10556], primals_2: f32[3, 2708, 7]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:238, code: index = edge_index[dim]\n",
      "        select: i64[10556] = torch.ops.aten.select.int(primals_1, 0, 0)\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:239, code: return src.index_select(self.node_dim, index)\n",
      "        slice_1: f32[3, 2708, 7] = torch.ops.aten.slice.Tensor(primals_2, 0, 0, 9223372036854775807);  primals_2 = None\n",
      "        index: f32[3, 10556, 7] = torch.ops.aten.index.Tensor(slice_1, [None, select]);  slice_1 = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:328, code: out['edge_index_i'] = edge_index[i]\n",
      "        select_1: i64[10556] = torch.ops.aten.select.int(primals_1, 0, 1);  primals_1 = None\n",
      "        return [index, select_1, select, select]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[10556], stride=[1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[3, 2708, 7], stride=[18956, 7, 1]))\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, i1)\n",
      "    tmp1 = load(primals_2, i2 + 7 * (tmp0) + 18956 * i0)\n",
      "    return tmp1\n",
      "    ,\n",
      "    ranges=[3, 10556, 7],\n",
      "    origins={primals_2, index, slice_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.int64, size=[2, 10556], stride=[10556, 1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[10556], stride=[1], offset=10556),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[262144], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 221676\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 7) % 10556\n",
      "    x0 = xindex % 7\n",
      "    x2 = (xindex // 73892)\n",
      "    x3 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x0 + (7*tmp0) + (18956*x2)), xmask)\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, primals_2 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 7), (73892, 7, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(primals_1, primals_2, buf0, 221676, grid=grid(221676), stream=stream0)\n",
      "        del primals_2\n",
      "        return (buf0, as_strided(primals_1, (10556, ), (1, ), 10556), as_strided(primals_1, (10556, ), (1, )), as_strided(primals_1, (10556, ), (1, )), )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_1 = rand_strided((2, 10556), (10556, 1), device='cuda:0', dtype=torch.int64)\n",
      "    primals_2 = rand_strided((3, 2708, 7), (18956, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_1, primals_2]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: f32[3, 10556, 7], primals_2: f32[10556]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py:144, code: return edge_weight.view(-1, 1) * x_j\n",
      "        view: f32[10556, 1] = torch.ops.aten.view.default(primals_2, [-1, 1])\n",
      "        mul: f32[3, 10556, 7] = torch.ops.aten.mul.Tensor(view, primals_1);  view = primals_1 = None\n",
      "        return [mul, primals_2]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.float32, size=[10556, 1], stride=[1, 1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_2, i1)\n",
      "    tmp1 = load(primals_1, i2 + 7 * i1 + 73892 * i0)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[3, 10556, 7],\n",
      "    origins={view, primals_2, primals_1, mul}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[262144], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 221676\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 7) % 10556\n",
      "    x3 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x3), xmask)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp2, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, primals_2 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 7), (73892, 7, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(primals_2, primals_1, buf0, 221676, grid=grid(221676), stream=stream0)\n",
      "        del primals_1\n",
      "        return (buf0, primals_2, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_1 = rand_strided((3, 10556, 7), (73892, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    primals_2 = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_1, primals_2]))\n",
      "\n",
      "inductor code end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-09 10:31:41,622] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/qq/cqq4wnseyxckmqucsctbrc4n3r3eu65px3smqqwi6pimzjmm5sa6.py\n",
      "[2023-03-09 10:31:41,622] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 7\n",
      "[2023-03-09 10:31:41,623] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,624] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_9 <eval_with_key>.72 opcode         name         target                   args                  kwargs\n",
      "-------------  -----------  -----------------------  --------------------  --------\n",
      "placeholder    x_j          x_j                      ()                    {}\n",
      "placeholder    edge_weight  edge_weight              ()                    {}\n",
      "call_method    view         view                     (edge_weight, -1, 1)  {}\n",
      "call_function  mul          <built-in function mul>  (view, x_j)           {}\n",
      "output         output       output                   ((mul,),)             {}\n",
      "\n",
      "[2023-03-09 10:31:41,625] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE message /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py line 143 \n",
      "144           0 LOAD_FAST                2 (edge_weight)\n",
      "              2 LOAD_METHOD              0 (view)\n",
      "              4 LOAD_CONST               1 (-1)\n",
      "              6 LOAD_CONST               2 (1)\n",
      "              8 CALL_METHOD              2\n",
      "             10 LOAD_FAST                1 (x_j)\n",
      "             12 BINARY_MULTIPLY\n",
      "             14 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,625] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE message /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py line 143 \n",
      "143           0 LOAD_GLOBAL              1 (__compiled_fn_9)\n",
      "              2 LOAD_FAST                1 (x_j)\n",
      "              4 LOAD_FAST                2 (edge_weight)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,626] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'x_j' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a83d4680; to 'Tensor' at 0x7f36ac9d46d0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'edge_weight' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a84476d0; to 'Tensor' at 0x7f36ac9d4310>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,629] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing aggregate\n",
      "[2023-03-09 10:31:41,638] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing aggregate (RETURN_VALUE)\n",
      "[2023-03-09 10:31:41,639] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,655] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 8\n",
      "[2023-03-09 10:31:41,662] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,664] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf1')]\n",
      "[2023-03-09 10:31:41,703] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/x4/cx45ai3fmmdj3xo4di36u56verj2nad763j2e4l6emiwrunlv5xs.py\n",
      "[2023-03-09 10:31:41,704] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 8\n",
      "[2023-03-09 10:31:41,705] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,705] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_10 <eval_with_key>.83 opcode       name          target        args                               kwargs\n",
      "-----------  ------------  ------------  ---------------------------------  --------\n",
      "placeholder  inputs        inputs        ()                                 {}\n",
      "placeholder  index         index         ()                                 {}\n",
      "call_method  view          view          (index, [1, -1, 1])                {}\n",
      "call_method  expand_as     expand_as     (view, inputs)                     {}\n",
      "call_method  new_zeros     new_zeros     (inputs, [3, 2708, 7])             {}\n",
      "call_method  scatter_add_  scatter_add_  (new_zeros, 1, expand_as, inputs)  {}\n",
      "output       output        output        ((scatter_add_,),)                 {}\n",
      "\n",
      "[2023-03-09 10:31:41,706] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE aggregate /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 565 \n",
      "578           0 LOAD_FAST                0 (self)\n",
      "              2 LOAD_ATTR                0 (aggr_module)\n",
      "              4 LOAD_FAST                1 (inputs)\n",
      "              6 LOAD_FAST                2 (index)\n",
      "              8 LOAD_FAST                3 (ptr)\n",
      "             10 LOAD_FAST                4 (dim_size)\n",
      "\n",
      "579          12 LOAD_FAST                0 (self)\n",
      "             14 LOAD_ATTR                1 (node_dim)\n",
      "\n",
      "578          16 LOAD_CONST               1 (('ptr', 'dim_size', 'dim'))\n",
      "             18 CALL_FUNCTION_KW         5\n",
      "             20 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,707] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE aggregate /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py line 565 \n",
      "565           0 LOAD_GLOBAL              4 (__compiled_fn_10)\n",
      "              2 LOAD_FAST                1 (inputs)\n",
      "              4 LOAD_FAST                2 (index)\n",
      "              6 CALL_FUNCTION            2\n",
      "              8 UNPACK_SEQUENCE          1\n",
      "             10 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,708] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local 'ptr' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(ptr, 9488912)'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'self' NN_MODULE\n",
      "            {\n",
      "                'guard_types': ['ID_MATCH'],\n",
      "                'code': ['___check_obj_id(self, 139870845919872)'],\n",
      "                'obj_weakref': <weakref at 0x7f36a8447680; to 'ARMAConv' at 0x7f363815e280>\n",
      "                'guarded_class': <weakref at 0x7f36366bb090; to 'type' at 0x7c28600 (ARMAConv)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'index' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36ac959090; to 'Tensor' at 0x7f36a84fd2c0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'inputs' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36a8488040; to 'Tensor' at 0x7f36ac959ae0>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local 'dim_size' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': ['EQUALS_MATCH'],\n",
      "                'code': ['___check_type_id(dim_size, 9487360)', 'dim_size == 2708'],\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': <weakref at 0x7f37769d5090; to 'type' at 0x90c400 (int)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'list' BUILTIN_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_geometric_dot_utils_dot_scatter.broadcast' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global '__import_torch_geometric_dot_nn_dot_aggr_dot_base.scatter' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.node_dim' CONSTANT_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      " - \n",
      "            local_nn_module 'self.aggr_module' NN_MODULE\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,710] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing act_fn\n",
      "[2023-03-09 10:31:41,712] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing <graph break in forward>\n",
      "[2023-03-09 10:31:41,716] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing <graph break in forward> (RETURN_VALUE)\n",
      "[2023-03-09 10:31:41,717] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,739] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 9\n",
      "[2023-03-09 10:31:41,761] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0'), SchedulerNode(name='buf1')]\n",
      "[2023-03-09 10:31:41,766] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf2')]\n",
      "[2023-03-09 10:31:41,813] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/kr/ckrxbmdlzdcmszvv6ygl7xoo7pnk34u2k47ryu43o7kiyxgizyzo.py\n",
      "[2023-03-09 10:31:41,814] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 9\n",
      "[2023-03-09 10:31:41,815] torch._dynamo.output_graph: [INFO] Step 2: done compiler function debug_wrapper\n",
      "[2023-03-09 10:31:41,816] torch._dynamo.output_graph: [INFO] TRACED GRAPH\n",
      " __compiled_fn_11 <eval_with_key>.94 opcode         name         target                                    args               kwargs\n",
      "-------------  -----------  ----------------------------------------  -----------------  ----------\n",
      "placeholder    _stack0      _stack0                                   ()                 {}\n",
      "call_function  log_softmax  <function log_softmax at 0x7f363776ee50>  (_stack0,)         {'dim': 1}\n",
      "output         output       output                                    ((log_softmax,),)  {}\n",
      "\n",
      "[2023-03-09 10:31:41,816] torch._dynamo.convert_frame: [INFO] ORIGINAL BYTECODE <graph break in forward> /home/chunwei/project/explor/torch/arma.py line 54 \n",
      " 54           0 LOAD_FAST                0 (___stack0)\n",
      "              2 JUMP_ABSOLUTE           64\n",
      "              4 LOAD_GLOBAL              0 (F)\n",
      "              6 LOAD_ATTR                1 (dropout)\n",
      "              8 LOAD_FAST                2 (x)\n",
      "             10 LOAD_FAST                1 (self)\n",
      "             12 LOAD_ATTR                2 (training)\n",
      "             14 LOAD_CONST               1 (('training',))\n",
      "             16 CALL_FUNCTION_KW         2\n",
      "             18 STORE_FAST               2 (x)\n",
      "             20 LOAD_GLOBAL              0 (F)\n",
      "             22 LOAD_ATTR                3 (relu)\n",
      "             24 LOAD_FAST                1 (self)\n",
      "             26 LOAD_ATTR                4 (conv1)\n",
      "             28 LOAD_FAST                2 (x)\n",
      "             30 LOAD_FAST                3 (edge_index)\n",
      "             32 CALL_FUNCTION            2\n",
      "             34 CALL_FUNCTION            1\n",
      "             36 STORE_FAST               2 (x)\n",
      "             38 LOAD_GLOBAL              0 (F)\n",
      "             40 LOAD_ATTR                1 (dropout)\n",
      "             42 LOAD_FAST                2 (x)\n",
      "             44 LOAD_FAST                1 (self)\n",
      "             46 LOAD_ATTR                2 (training)\n",
      "             48 LOAD_CONST               1 (('training',))\n",
      "             50 CALL_FUNCTION_KW         2\n",
      "             52 STORE_FAST               2 (x)\n",
      "             54 LOAD_FAST                1 (self)\n",
      "             56 LOAD_ATTR                5 (conv2)\n",
      "             58 LOAD_FAST                2 (x)\n",
      "             60 LOAD_FAST                3 (edge_index)\n",
      "             62 CALL_FUNCTION            2\n",
      "        >>   64 STORE_FAST               2 (x)\n",
      "\n",
      " 55          66 LOAD_GLOBAL              0 (F)\n",
      "             68 LOAD_ATTR                6 (log_softmax)\n",
      "             70 LOAD_FAST                2 (x)\n",
      "             72 LOAD_CONST               2 (1)\n",
      "             74 LOAD_CONST               3 (('dim',))\n",
      "             76 CALL_FUNCTION_KW         2\n",
      "             78 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,817] torch._dynamo.convert_frame: [INFO] MODIFIED BYTECODE <graph break in forward> /home/chunwei/project/explor/torch/arma.py line 54 \n",
      " 54           0 LOAD_GLOBAL              7 (__compiled_fn_11)\n",
      "              2 LOAD_FAST                0 (___stack0)\n",
      "              4 CALL_FUNCTION            1\n",
      "              6 UNPACK_SEQUENCE          1\n",
      "              8 RETURN_VALUE\n",
      "\n",
      " \n",
      "[2023-03-09 10:31:41,818] torch._dynamo.convert_frame: [INFO] GUARDS:\n",
      " - \n",
      "            local '___stack0' TENSOR_MATCH\n",
      "            {\n",
      "                'guard_types': ['TENSOR_MATCH'],\n",
      "                'code': None,\n",
      "                'obj_weakref': <weakref at 0x7f36ac959ae0; to 'Tensor' at 0x7f36a8404450>\n",
      "                'guarded_class': <weakref at 0x7f3637ce1f90; to 'torch._C._TensorMeta' at 0x5db2180 (Tensor)>\n",
      "            }\n",
      "            \n",
      " - \n",
      "            global 'F' FUNCTION_MATCH\n",
      "            {\n",
      "                'guard_types': None,\n",
      "                'code': None,\n",
      "                'obj_weakref': None\n",
      "                'guarded_class': None\n",
      "            }\n",
      "            \n",
      "[2023-03-09 10:31:41,823] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 9\n",
      "[2023-03-09 10:31:41,836] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,839] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf1')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: f32[3, 10556, 7], primals_2: i64[10556]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:20, code: return src.view(size).expand_as(ref)\n",
      "        view: i64[1, 10556, 1] = torch.ops.aten.view.default(primals_2, [1, -1, 1]);  primals_2 = None\n",
      "        expand: i64[3, 10556, 7] = torch.ops.aten.expand.default(view, [3, 10556, 7]);  view = None\n",
      "        \n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:54, code: return src.new_zeros(size).scatter_add_(dim, index, src)\n",
      "        full: f32[3, 2708, 7] = torch.ops.aten.full.default([3, 2708, 7], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)\n",
      "        scatter_add: f32[3, 2708, 7] = torch.ops.aten.scatter_add.default(full, 1, expand, primals_1);  full = primals_1 = None\n",
      "        return [scatter_add, expand]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.int64, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[1, 10556, 1], stride=[10556, 1, 1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.int64, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.int64, size=[3, 10556, 7], stride=[0, 1, 0]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 7],\n",
      "    origins={full}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  ComputedBuffer(name='buf0', layout=FlexibleLayout('cuda', torch.float32, size=[3, 2708, 7], stride=[18956, 7, 1]), data=Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 7],\n",
      "    origins={primals_1, primals_2, full, scatter_add, expand, view}\n",
      "  ))\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[65536], filename=__file__, meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 56868\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = 0.0\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp0, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__1 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[262144], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': ['out_ptr0'], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 221676\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 7) % 10556\n",
      "    x3 = xindex\n",
      "    x0 = xindex % 7\n",
      "    x2 = (xindex // 73892)\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x3), xmask)\n",
      "    tl.atomic_add(out_ptr0 + (x0 + (7*tmp0) + (18956*x2) + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, primals_2 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 2708, 7), (18956, 7, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(buf0, 56868, grid=grid(56868), stream=stream0)\n",
      "        triton__1.run(primals_2, primals_1, buf0, 221676, grid=grid(221676), stream=stream0)\n",
      "        del primals_1\n",
      "        return (buf0, as_strided(primals_2, (3, 10556, 7), (0, 1, 0)), )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_1 = rand_strided((3, 10556, 7), (73892, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    primals_2 = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.int64)\n",
      "    print_performance(lambda: call([primals_1, primals_2]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_1: f32[2708, 7]):\n",
      "        # File: /home/chunwei/project/explor/torch/arma.py:55, code: return F.log_softmax(x, dim=1)\n",
      "        amax: f32[2708, 1] = torch.ops.aten.amax.default(primals_1, [1], True)\n",
      "        sub: f32[2708, 7] = torch.ops.aten.sub.Tensor(primals_1, amax);  primals_1 = amax = None\n",
      "        exp: f32[2708, 7] = torch.ops.aten.exp.default(sub)\n",
      "        sum_1: f32[2708, 1] = torch.ops.aten.sum.dim_IntList(exp, [1], True);  exp = None\n",
      "        log: f32[2708, 1] = torch.ops.aten.log.default(sum_1);  sum_1 = None\n",
      "        sub_1: f32[2708, 7] = torch.ops.aten.sub.Tensor(sub, log);  sub = log = None\n",
      "        return [sub_1, sub_1]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, 7 * i0)\n",
      "    tmp1 = load(primals_1, 1 + 7 * i0)\n",
      "    tmp2 = maximum(tmp0, tmp1)\n",
      "    tmp3 = load(primals_1, 2 + 7 * i0)\n",
      "    tmp4 = maximum(tmp2, tmp3)\n",
      "    tmp5 = load(primals_1, 3 + 7 * i0)\n",
      "    tmp6 = maximum(tmp4, tmp5)\n",
      "    tmp7 = load(primals_1, 4 + 7 * i0)\n",
      "    tmp8 = maximum(tmp6, tmp7)\n",
      "    tmp9 = load(primals_1, 5 + 7 * i0)\n",
      "    tmp10 = maximum(tmp8, tmp9)\n",
      "    tmp11 = load(primals_1, 6 + 7 * i0)\n",
      "    tmp12 = maximum(tmp10, tmp11)\n",
      "    return tmp12\n",
      "    ,\n",
      "    ranges=[2708, 1],\n",
      "    origins={primals_1, amax}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, i1 + 7 * i0)\n",
      "    tmp1 = load(buf0, i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[2708, 7],\n",
      "    origins={primals_1, amax, sub}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, i1 + 7 * i0)\n",
      "    tmp1 = load(buf0, i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = exp(tmp2)\n",
      "    return tmp3\n",
      "    ,\n",
      "    ranges=[2708, 7],\n",
      "    origins={exp, primals_1, amax, sub}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, 7 * i0)\n",
      "    tmp1 = load(buf0, i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = exp(tmp2)\n",
      "    tmp4 = load(primals_1, 1 + 7 * i0)\n",
      "    tmp5 = load(buf0, i0)\n",
      "    tmp6 = tmp4 - tmp5\n",
      "    tmp7 = exp(tmp6)\n",
      "    tmp8 = tmp3 + tmp7\n",
      "    tmp9 = load(primals_1, 2 + 7 * i0)\n",
      "    tmp10 = load(buf0, i0)\n",
      "    tmp11 = tmp9 - tmp10\n",
      "    tmp12 = exp(tmp11)\n",
      "    tmp13 = tmp8 + tmp12\n",
      "    tmp14 = load(primals_1, 3 + 7 * i0)\n",
      "    tmp15 = load(buf0, i0)\n",
      "    tmp16 = tmp14 - tmp15\n",
      "    tmp17 = exp(tmp16)\n",
      "    tmp18 = tmp13 + tmp17\n",
      "    tmp19 = load(primals_1, 4 + 7 * i0)\n",
      "    tmp20 = load(buf0, i0)\n",
      "    tmp21 = tmp19 - tmp20\n",
      "    tmp22 = exp(tmp21)\n",
      "    tmp23 = tmp18 + tmp22\n",
      "    tmp24 = load(primals_1, 5 + 7 * i0)\n",
      "    tmp25 = load(buf0, i0)\n",
      "    tmp26 = tmp24 - tmp25\n",
      "    tmp27 = exp(tmp26)\n",
      "    tmp28 = tmp23 + tmp27\n",
      "    tmp29 = load(primals_1, 6 + 7 * i0)\n",
      "    tmp30 = load(buf0, i0)\n",
      "    tmp31 = tmp29 - tmp30\n",
      "    tmp32 = exp(tmp31)\n",
      "    tmp33 = tmp28 + tmp32\n",
      "    return tmp33\n",
      "    ,\n",
      "    ranges=[2708, 1],\n",
      "    origins={sum_1, exp, sub, primals_1, amax}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, 7 * i0)\n",
      "    tmp1 = load(buf0, i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = exp(tmp2)\n",
      "    tmp4 = load(primals_1, 1 + 7 * i0)\n",
      "    tmp5 = load(buf0, i0)\n",
      "    tmp6 = tmp4 - tmp5\n",
      "    tmp7 = exp(tmp6)\n",
      "    tmp8 = tmp3 + tmp7\n",
      "    tmp9 = load(primals_1, 2 + 7 * i0)\n",
      "    tmp10 = load(buf0, i0)\n",
      "    tmp11 = tmp9 - tmp10\n",
      "    tmp12 = exp(tmp11)\n",
      "    tmp13 = tmp8 + tmp12\n",
      "    tmp14 = load(primals_1, 3 + 7 * i0)\n",
      "    tmp15 = load(buf0, i0)\n",
      "    tmp16 = tmp14 - tmp15\n",
      "    tmp17 = exp(tmp16)\n",
      "    tmp18 = tmp13 + tmp17\n",
      "    tmp19 = load(primals_1, 4 + 7 * i0)\n",
      "    tmp20 = load(buf0, i0)\n",
      "    tmp21 = tmp19 - tmp20\n",
      "    tmp22 = exp(tmp21)\n",
      "    tmp23 = tmp18 + tmp22\n",
      "    tmp24 = load(primals_1, 5 + 7 * i0)\n",
      "    tmp25 = load(buf0, i0)\n",
      "    tmp26 = tmp24 - tmp25\n",
      "    tmp27 = exp(tmp26)\n",
      "    tmp28 = tmp23 + tmp27\n",
      "    tmp29 = load(primals_1, 6 + 7 * i0)\n",
      "    tmp30 = load(buf0, i0)\n",
      "    tmp31 = tmp29 - tmp30\n",
      "    tmp32 = exp(tmp31)\n",
      "    tmp33 = tmp28 + tmp32\n",
      "    tmp34 = log(tmp33)\n",
      "    return tmp34\n",
      "    ,\n",
      "    ranges=[2708, 1],\n",
      "    origins={sum_1, exp, log, sub, primals_1, amax}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(primals_1, i1 + 7 * i0)\n",
      "    tmp1 = load(buf0, i0)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp3 = load(buf1, i0)\n",
      "    tmp4 = tmp2 - tmp3\n",
      "    return tmp4\n",
      "    ,\n",
      "    ranges=[2708, 7],\n",
      "    origins={sum_1, exp, log, sub, primals_1, sub_1, amax}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[4096], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 2708\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (7*x0), xmask)\n",
      "    tmp1 = tl.load(in_ptr0 + (1 + (7*x0)), xmask)\n",
      "    tmp3 = tl.load(in_ptr0 + (2 + (7*x0)), xmask)\n",
      "    tmp5 = tl.load(in_ptr0 + (3 + (7*x0)), xmask)\n",
      "    tmp7 = tl.load(in_ptr0 + (4 + (7*x0)), xmask)\n",
      "    tmp9 = tl.load(in_ptr0 + (5 + (7*x0)), xmask)\n",
      "    tmp11 = tl.load(in_ptr0 + (6 + (7*x0)), xmask)\n",
      "    tmp2 = tl.where(tmp0 != tmp0, tmp0, tl.where(tmp0 > tmp1, tmp0, tmp1))\n",
      "    tmp4 = tl.where(tmp2 != tmp2, tmp2, tl.where(tmp2 > tmp3, tmp2, tmp3))\n",
      "    tmp6 = tl.where(tmp4 != tmp4, tmp4, tl.where(tmp4 > tmp5, tmp4, tmp5))\n",
      "    tmp8 = tl.where(tmp6 != tmp6, tmp6, tl.where(tmp6 > tmp7, tmp6, tmp7))\n",
      "    tmp10 = tl.where(tmp8 != tmp8, tmp8, tl.where(tmp8 > tmp9, tmp8, tmp9))\n",
      "    tmp12 = tl.where(tmp10 != tmp10, tmp10, tl.where(tmp10 > tmp11, tmp10, tmp11))\n",
      "    tmp13 = tmp0 - tmp12\n",
      "    tmp14 = tl.exp(tmp13)\n",
      "    tmp15 = tmp1 - tmp12\n",
      "    tmp16 = tl.exp(tmp15)\n",
      "    tmp17 = tmp14 + tmp16\n",
      "    tmp18 = tmp3 - tmp12\n",
      "    tmp19 = tl.exp(tmp18)\n",
      "    tmp20 = tmp17 + tmp19\n",
      "    tmp21 = tmp5 - tmp12\n",
      "    tmp22 = tl.exp(tmp21)\n",
      "    tmp23 = tmp20 + tmp22\n",
      "    tmp24 = tmp7 - tmp12\n",
      "    tmp25 = tl.exp(tmp24)\n",
      "    tmp26 = tmp23 + tmp25\n",
      "    tmp27 = tmp9 - tmp12\n",
      "    tmp28 = tl.exp(tmp27)\n",
      "    tmp29 = tmp26 + tmp28\n",
      "    tmp30 = tmp11 - tmp12\n",
      "    tmp31 = tl.exp(tmp30)\n",
      "    tmp32 = tmp29 + tmp31\n",
      "    tmp33 = tl.log(tmp32)\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp12, xmask)\n",
      "    tl.store(out_ptr1 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp33, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__1 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[32768], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 18956\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x2 = xindex\n",
      "    x1 = (xindex // 7)\n",
      "    tmp0 = tl.load(in_ptr0 + (x2), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x1), xmask)\n",
      "    tmp3 = tl.load(in_ptr2 + (x1), xmask)\n",
      "    tmp2 = tmp0 - tmp1\n",
      "    tmp4 = tmp2 - tmp3\n",
      "    tl.store(out_ptr0 + (x2 + tl.zeros([XBLOCK], tl.int32)), tmp4, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_1, = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((2708, 1), (1, 2708), device='cuda', dtype=torch.float32)\n",
      "        buf1 = empty_strided((2708, 1), (1, 2708), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(primals_1, buf0, buf1, 2708, grid=grid(2708), stream=stream0)\n",
      "        buf2 = empty_strided((2708, 7), (7, 1), device='cuda', dtype=torch.float32)\n",
      "        triton__1.run(primals_1, buf0, buf1, buf2, 18956, grid=grid(18956), stream=stream0)\n",
      "        del buf0\n",
      "        del buf1\n",
      "        del primals_1\n",
      "        return (buf2, buf2, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_1 = rand_strided((2708, 7), (7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_1]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, sub_1: f32[2708, 7], tangents_1: f32[2708, 7]):\n",
      "        # File: /home/chunwei/project/explor/torch/arma.py:55, code: return F.log_softmax(x, dim=1)\n",
      "        exp_1: f32[2708, 7] = torch.ops.aten.exp.default(sub_1);  sub_1 = None\n",
      "        sum_2: f32[2708, 1] = torch.ops.aten.sum.dim_IntList(tangents_1, [1], True)\n",
      "        mul: f32[2708, 7] = torch.ops.aten.mul.Tensor(exp_1, sum_2);  exp_1 = sum_2 = None\n",
      "        sub_2: f32[2708, 7] = torch.ops.aten.sub.Tensor(tangents_1, mul);  tangents_1 = mul = None\n",
      "        return [sub_2]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(sub_1, i1 + 7 * i0)\n",
      "    tmp1 = exp(tmp0)\n",
      "    return tmp1\n",
      "    ,\n",
      "    ranges=[2708, 7],\n",
      "    origins={exp_1, sub_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(tangents_1, 7 * i0)\n",
      "    tmp1 = load(tangents_1, 1 + 7 * i0)\n",
      "    tmp2 = tmp0 + tmp1\n",
      "    tmp3 = load(tangents_1, 2 + 7 * i0)\n",
      "    tmp4 = tmp2 + tmp3\n",
      "    tmp5 = load(tangents_1, 3 + 7 * i0)\n",
      "    tmp6 = tmp4 + tmp5\n",
      "    tmp7 = load(tangents_1, 4 + 7 * i0)\n",
      "    tmp8 = tmp6 + tmp7\n",
      "    tmp9 = load(tangents_1, 5 + 7 * i0)\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp11 = load(tangents_1, 6 + 7 * i0)\n",
      "    tmp12 = tmp10 + tmp11\n",
      "    return tmp12\n",
      "    ,\n",
      "    ranges=[2708, 1],\n",
      "    origins={sum_2, tangents_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(sub_1, i1 + 7 * i0)\n",
      "    tmp1 = exp(tmp0)\n",
      "    tmp2 = load(buf0, i0)\n",
      "    tmp3 = tmp1 * tmp2\n",
      "    return tmp3\n",
      "    ,\n",
      "    ranges=[2708, 7],\n",
      "    origins={mul, exp_1, sum_2, tangents_1, sub_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(tangents_1, i1 + 7 * i0)\n",
      "    tmp1 = load(sub_1, i1 + 7 * i0)\n",
      "    tmp2 = exp(tmp1)\n",
      "    tmp3 = load(buf0, i0)\n",
      "    tmp4 = tmp2 * tmp3\n",
      "    tmp5 = tmp0 - tmp4\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[2708, 7],\n",
      "    origins={mul, sum_2, sub_2, exp_1, tangents_1, sub_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[4096], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 2708\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (7*x0), xmask)\n",
      "    tmp1 = tl.load(in_ptr0 + (1 + (7*x0)), xmask)\n",
      "    tmp3 = tl.load(in_ptr0 + (2 + (7*x0)), xmask)\n",
      "    tmp5 = tl.load(in_ptr0 + (3 + (7*x0)), xmask)\n",
      "    tmp7 = tl.load(in_ptr0 + (4 + (7*x0)), xmask)\n",
      "    tmp9 = tl.load(in_ptr0 + (5 + (7*x0)), xmask)\n",
      "    tmp11 = tl.load(in_ptr0 + (6 + (7*x0)), xmask)\n",
      "    tmp2 = tmp0 + tmp1\n",
      "    tmp4 = tmp2 + tmp3\n",
      "    tmp6 = tmp4 + tmp5\n",
      "    tmp8 = tmp6 + tmp7\n",
      "    tmp10 = tmp8 + tmp9\n",
      "    tmp12 = tmp10 + tmp11\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp12, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__1 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[32768], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 18956\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x2 = xindex\n",
      "    x1 = (xindex // 7)\n",
      "    tmp0 = tl.load(in_ptr0 + (x2), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x2), xmask)\n",
      "    tmp3 = tl.load(in_ptr2 + (x1), xmask)\n",
      "    tmp2 = tl.exp(tmp1)\n",
      "    tmp4 = tmp2 * tmp3\n",
      "    tmp5 = tmp0 - tmp4\n",
      "    tl.store(out_ptr0 + (x2 + tl.zeros([XBLOCK], tl.int32)), tmp5, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    sub_1, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((2708, 1), (1, 2708), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(tangents_1, buf0, 2708, grid=grid(2708), stream=stream0)\n",
      "        buf1 = empty_strided((2708, 7), (7, 1), device='cuda', dtype=torch.float32)\n",
      "        triton__1.run(tangents_1, sub_1, buf0, buf1, 18956, grid=grid(18956), stream=stream0)\n",
      "        del buf0\n",
      "        del sub_1\n",
      "        del tangents_1\n",
      "        return (buf1, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    sub_1 = rand_strided((2708, 7), (7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    tangents_1 = rand_strided((2708, 7), (7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([sub_1, tangents_1]))\n",
      "\n",
      "inductor code end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-09 10:31:41,878] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/yl/cylucuqyqb6zowhkjzko2ttzssrj5d5uiw52dpvfidn4i62t46zw.py\n",
      "[2023-03-09 10:31:41,879] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 9\n",
      "[2023-03-09 10:31:41,882] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 8\n",
      "[2023-03-09 10:31:41,887] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,912] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/vl/cvlwjotcyu34y42wb43no3b3xgcc67hjtqwj4bdnq4om7anlpon6.py\n",
      "[2023-03-09 10:31:41,912] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 8\n",
      "[2023-03-09 10:31:41,914] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 7\n",
      "[2023-03-09 10:31:41,921] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,955] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/a6/ca6hfb6dx4lya5mugay2chimrbjscmg3tflckzzsyabkk34wlc7t.py\n",
      "[2023-03-09 10:31:41,955] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 7\n",
      "[2023-03-09 10:31:41,957] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 6\n",
      "[2023-03-09 10:31:41,963] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:41,964] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf1')]\n",
      "[2023-03-09 10:31:41,992] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/sl/cslw22nt36r32rmok66oi2hqvzs6bgxv5hilnn5hnqitk7lpp5mm.py\n",
      "[2023-03-09 10:31:41,993] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 6\n",
      "[2023-03-09 10:31:41,996] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 5\n",
      "[2023-03-09 10:31:42,005] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:42,047] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/ql/cqlg6sx4xwyhrhursuovewk6digefnxil7hrbx4psrlallwhewbe.py\n",
      "[2023-03-09 10:31:42,047] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 5\n",
      "[2023-03-09 10:31:42,049] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 4\n",
      "[2023-03-09 10:31:42,053] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, expand: i64[3, 10556, 7], tangents_1: f32[3, 2708, 7]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:54, code: return src.new_zeros(size).scatter_add_(dim, index, src)\n",
      "        gather: f32[3, 10556, 7] = torch.ops.aten.gather.default(tangents_1, 1, expand);  tangents_1 = expand = None\n",
      "        return [gather, None]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(expand, i1)\n",
      "    tmp1 = load(tangents_1, i2 + 7 * (tmp0) + 18956 * i0)\n",
      "    return tmp1\n",
      "    ,\n",
      "    ranges=[3, 10556, 7],\n",
      "    origins={expand, gather, tangents_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[262144], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 221676\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 7) % 10556\n",
      "    x0 = xindex % 7\n",
      "    x2 = (xindex // 73892)\n",
      "    x3 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x0 + (7*tmp0) + (18956*x2)), xmask)\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    expand, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 7), (73892, 7, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(expand, tangents_1, buf0, 221676, grid=grid(221676), stream=stream0)\n",
      "        del expand\n",
      "        del tangents_1\n",
      "        return (buf0, None, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    expand = rand_strided((3, 10556, 7), (0, 1, 0), device='cuda:0', dtype=torch.int64)\n",
      "    tangents_1 = rand_strided((3, 2708, 7), (18956, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([expand, tangents_1]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_2: f32[10556], tangents_1: f32[3, 10556, 7]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py:144, code: return edge_weight.view(-1, 1) * x_j\n",
      "        view: f32[10556, 1] = torch.ops.aten.view.default(primals_2, [-1, 1]);  primals_2 = None\n",
      "        mul_1: f32[3, 10556, 7] = torch.ops.aten.mul.Tensor(tangents_1, view);  tangents_1 = view = None\n",
      "        return [mul_1, None]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.float32, size=[10556, 1], stride=[1, 1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(tangents_1, i2 + 7 * i1 + 73892 * i0)\n",
      "    tmp1 = load(primals_2, i1)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[3, 10556, 7],\n",
      "    origins={mul_1, view, primals_2, tangents_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[262144], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 221676\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x3 = xindex\n",
      "    x1 = (xindex // 7) % 10556\n",
      "    tmp0 = tl.load(in_ptr0 + (x3), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x1), xmask)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp2, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_2, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 7), (73892, 7, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(tangents_1, primals_2, buf0, 221676, grid=grid(221676), stream=stream0)\n",
      "        del primals_2\n",
      "        del tangents_1\n",
      "        return (buf0, None, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_2 = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "    tangents_1 = rand_strided((3, 10556, 7), (73892, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_2, tangents_1]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, select: i64[10556], tangents_1: f32[3, 10556, 7]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:239, code: return src.index_select(self.node_dim, index)\n",
      "        full: f32[3, 2708, 7] = torch.ops.aten.full.default([3, 2708, 7], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)\n",
      "        index_put: f32[3, 2708, 7] = torch.ops.aten.index_put.default(full, [None, select], tangents_1, True);  full = select = tangents_1 = None\n",
      "        return [None, index_put]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 7],\n",
      "    origins={full}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  ComputedBuffer(name='buf0', layout=FlexibleLayout('cuda', torch.float32, size=[3, 2708, 7], stride=[18956, 7, 1]), data=Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 7],\n",
      "    origins={tangents_1, full, index_put}\n",
      "  ))\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[65536], filename=__file__, meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0,), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 56868\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = 0.0\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp0, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__1 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[262144], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': ['out_ptr0'], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 221676\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 7) % 10556\n",
      "    x3 = xindex\n",
      "    x0 = xindex % 7\n",
      "    x2 = (xindex // 73892)\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x3), xmask)\n",
      "    tl.atomic_add(out_ptr0 + (x0 + (7*tmp0) + (18956*x2) + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    select, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 2708, 7), (18956, 7, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(buf0, 56868, grid=grid(56868), stream=stream0)\n",
      "        triton__1.run(select, tangents_1, buf0, 221676, grid=grid(221676), stream=stream0)\n",
      "        del select\n",
      "        del tangents_1\n",
      "        return (None, buf0, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    select = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.int64)\n",
      "    tangents_1 = rand_strided((3, 10556, 7), (73892, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([select, tangents_1]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, philox_seed_like: i32[], le: b8[2708, 16], tangents_1: f32[2708, 16]):\n",
      "        # No stacktrace found for following nodes\n",
      "        philox_rand_like_1: f32[2708, 16] = torch.ops.prims.philox_rand_like.default(tangents_1, philox_seed_like, 0);  philox_seed_like = None\n",
      "        gt_1: b8[2708, 16] = torch.ops.aten.gt.Scalar(philox_rand_like_1, 0.5);  philox_rand_like_1 = None\n",
      "        convert_element_type_1: f32[2708, 16] = torch.ops.prims.convert_element_type.default(gt_1, torch.float32);  gt_1 = None\n",
      "        mul_2: f32[2708, 16] = torch.ops.aten.mul.Tensor(convert_element_type_1, tangents_1);  convert_element_type_1 = tangents_1 = None\n",
      "        mul_3: f32[2708, 16] = torch.ops.aten.mul.Tensor(mul_2, 2.0);  mul_2 = None\n",
      "        \n",
      "        # File: /home/chunwei/project/explor/torch/arma.py:52, code: x = F.relu(self.conv1(x, edge_index))\n",
      "        scalar_tensor: f32[] = torch.ops.aten.scalar_tensor.default(0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0))\n",
      "        where: f32[2708, 16] = torch.ops.aten.where.self(le, scalar_tensor, mul_3);  le = scalar_tensor = mul_3 = None\n",
      "        return [where]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(philox_seed_like, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_rand_like_1, philox_seed_like, tangents_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.bool,\n",
      "    tmp0 = load(philox_seed_like, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    return tmp4\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_rand_like_1, philox_seed_like, tangents_1, gt_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(philox_seed_like, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    return tmp5\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_seed_like, convert_element_type_1, gt_1, philox_rand_like_1, tangents_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(philox_seed_like, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(tangents_1, i1 + 16 * i0)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    return tmp7\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_seed_like, gt_1, mul_2, philox_rand_like_1, convert_element_type_1, tangents_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(philox_seed_like, 0)\n",
      "    tmp1 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp2 = rand(tmp0, tmp1, torch.float32)\n",
      "    tmp3 = constant(0.5, torch.float32)\n",
      "    tmp4 = tmp2 > tmp3\n",
      "    tmp5 = to_dtype(tmp4, torch.float32)\n",
      "    tmp6 = load(tangents_1, i1 + 16 * i0)\n",
      "    tmp7 = tmp5 * tmp6\n",
      "    tmp8 = constant(2.0, torch.float32)\n",
      "    tmp9 = tmp7 * tmp8\n",
      "    return tmp9\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={philox_seed_like, mul_3, convert_element_type_1, mul_2, philox_rand_like_1, gt_1, tangents_1}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0.0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[],\n",
      "    origins={scalar_tensor}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(le, i1 + 16 * i0)\n",
      "    tmp1 = constant(0.0, torch.float32)\n",
      "    tmp2 = load(philox_seed_like, 0)\n",
      "    tmp3 = index_expr(i1 + 16 * i0, torch.int32)\n",
      "    tmp4 = rand(tmp2, tmp3, torch.float32)\n",
      "    tmp5 = constant(0.5, torch.float32)\n",
      "    tmp6 = tmp4 > tmp5\n",
      "    tmp7 = to_dtype(tmp6, torch.float32)\n",
      "    tmp8 = load(tangents_1, i1 + 16 * i0)\n",
      "    tmp9 = tmp7 * tmp8\n",
      "    tmp10 = constant(2.0, torch.float32)\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = where(tmp0, tmp1, tmp11)\n",
      "    return tmp12\n",
      "    ,\n",
      "    ranges=[2708, 16],\n",
      "    origins={mul_3, le, mul_2, philox_rand_like_1, scalar_tensor, philox_seed_like, where, convert_element_type_1, gt_1, tangents_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[65536], filename=__file__, meta={'signature': {0: '*i1', 1: '*i64', 2: '*fp32', 3: '*fp32', 4: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 43328\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x0), xmask)\n",
      "    tmp2_load = tl.load(in_ptr1 + (0))\n",
      "    tmp2 = tl.broadcast_to(tmp2_load, [XBLOCK])\n",
      "    tmp8 = tl.load(in_ptr2 + (x0), xmask)\n",
      "    tmp1 = 0.0\n",
      "    tmp3 = x0\n",
      "    tmp4 = tl.rand(tmp2, tmp3)\n",
      "    tmp5 = 0.5\n",
      "    tmp6 = tmp4 > tmp5\n",
      "    tmp7 = tmp6.to(tl.float32)\n",
      "    tmp9 = tmp7 * tmp8\n",
      "    tmp10 = 2.0\n",
      "    tmp11 = tmp9 * tmp10\n",
      "    tmp12 = tl.where(tmp0, tmp1, tmp11)\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp12, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    philox_seed_like, le, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((2708, 16), (16, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(le, philox_seed_like, tangents_1, buf0, 43328, grid=grid(43328), stream=stream0)\n",
      "        del le\n",
      "        del philox_seed_like\n",
      "        del tangents_1\n",
      "        return (buf0, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    philox_seed_like = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "    le = rand_strided((2708, 16), (16, 1), device='cuda:0', dtype=torch.bool)\n",
      "    tangents_1 = rand_strided((2708, 16), (16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([philox_seed_like, le, tangents_1]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, expand: i64[3, 10556, 16], tangents_1: f32[3, 2708, 16]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/utils/scatter.py:54, code: return src.new_zeros(size).scatter_add_(dim, index, src)\n",
      "        gather: f32[3, 10556, 16] = torch.ops.aten.gather.default(tangents_1, 1, expand);  tangents_1 = expand = None\n",
      "        return [gather, None]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(expand, i1)\n",
      "    tmp1 = load(tangents_1, i2 + 16 * (tmp0) + 43328 * i0)\n",
      "    return tmp1\n",
      "    ,\n",
      "    ranges=[3, 10556, 16],\n",
      "    origins={gather, tangents_1, expand}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[524288], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 506688\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 16) % 10556\n",
      "    x0 = xindex % 16\n",
      "    x2 = (xindex // 168896)\n",
      "    x3 = xindex\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x0 + (16*tmp0) + (43328*x2)), xmask)\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    expand, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 16), (168896, 16, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(expand, tangents_1, buf0, 506688, grid=grid(506688), stream=stream0)\n",
      "        del expand\n",
      "        del tangents_1\n",
      "        return (buf0, None, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    expand = rand_strided((3, 10556, 16), (0, 1, 0), device='cuda:0', dtype=torch.int64)\n",
      "    tangents_1 = rand_strided((3, 2708, 16), (43328, 16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([expand, tangents_1]))\n",
      "\n",
      "inductor code end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-09 10:31:42,082] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/a4/ca4emceeox7ck636m4kexu2fkv6kj7l6qtrtcoezxrgdp3lwr2s6.py\n",
      "[2023-03-09 10:31:42,083] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 4\n",
      "[2023-03-09 10:31:42,084] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 3\n",
      "[2023-03-09 10:31:42,088] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:42,121] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/je/cjex2cutn7t677rqtjitbivnf4nl3fnfl3y6j6roo37xqcnnmck6.py\n",
      "[2023-03-09 10:31:42,121] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 3\n",
      "[2023-03-09 10:31:42,123] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling BACKWARDS graph 2\n",
      "[2023-03-09 10:31:42,131] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf0')]\n",
      "[2023-03-09 10:31:42,133] torch._inductor.codegen.triton: [INFO] schedule: [SchedulerNode(name='buf1')]\n",
      "[2023-03-09 10:31:42,159] torch._inductor.graph: [INFO] Output code: /tmp/torchinductor_chunwei/cr/ccr2d5fh3lcei53fb5stdx5iprv6du2mhl7qu44lfdzzpv2lshar.py\n",
      "[2023-03-09 10:31:42,160] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling BACKWARDS graph 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, primals_2: f32[10556], tangents_1: f32[3, 10556, 16]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/arma_conv.py:144, code: return edge_weight.view(-1, 1) * x_j\n",
      "        view: f32[10556, 1] = torch.ops.aten.view.default(primals_2, [-1, 1]);  primals_2 = None\n",
      "        mul_1: f32[3, 10556, 16] = torch.ops.aten.mul.Tensor(tangents_1, view);  tangents_1 = view = None\n",
      "        return [mul_1, None]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(\n",
      "  ReinterpretView(\n",
      "    StorageBox(\n",
      "      InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[10556], stride=[1]))\n",
      "    ),\n",
      "    FixedLayout('cuda', torch.float32, size=[10556, 1], stride=[1, 1]),\n",
      "    no origins?\n",
      "  )\n",
      ")\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = load(tangents_1, i2 + 16 * i1 + 168896 * i0)\n",
      "    tmp1 = load(primals_2, i1)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    return tmp2\n",
      "    ,\n",
      "    ranges=[3, 10556, 16],\n",
      "    origins={view, mul_1, primals_2, tangents_1}\n",
      "  )\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[524288], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 506688\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x3 = xindex\n",
      "    x1 = (xindex // 16) % 10556\n",
      "    tmp0 = tl.load(in_ptr0 + (x3), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x1), xmask)\n",
      "    tmp2 = tmp0 * tmp1\n",
      "    tl.store(out_ptr0 + (x3 + tl.zeros([XBLOCK], tl.int32)), tmp2, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    primals_2, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 10556, 16), (168896, 16, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(tangents_1, primals_2, buf0, 506688, grid=grid(506688), stream=stream0)\n",
      "        del primals_2\n",
      "        del tangents_1\n",
      "        return (buf0, None, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    primals_2 = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "    tangents_1 = rand_strided((3, 10556, 16), (168896, 16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([primals_2, tangents_1]))\n",
      "\n",
      "inductor code end\n",
      "compile_fx_inner begin:\n",
      "class GraphModule(torch.nn.Module):\n",
      "    def forward(self, select: i64[10556], tangents_1: f32[3, 10556, 16]):\n",
      "        # File: /home/chunwei/trienv/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py:239, code: return src.index_select(self.node_dim, index)\n",
      "        full: f32[3, 2708, 16] = torch.ops.aten.full.default([3, 2708, 16], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)\n",
      "        index_put: f32[3, 2708, 16] = torch.ops.aten.index_put.default(full, [None, select], tangents_1, True);  full = select = tangents_1 = None\n",
      "        return [None, index_put]\n",
      "        \n",
      "compile_fx_inner end\n",
      "** out TensorBox(StorageBox(\n",
      "  Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 16],\n",
      "    origins={full}\n",
      "  )\n",
      "))\n",
      "** out TensorBox(StorageBox(\n",
      "  ComputedBuffer(name='buf0', layout=FlexibleLayout('cuda', torch.float32, size=[3, 2708, 16], stride=[43328, 16, 1]), data=Pointwise(\n",
      "    'cuda',\n",
      "    torch.float32,\n",
      "    tmp0 = constant(0, torch.float32)\n",
      "    return tmp0\n",
      "    ,\n",
      "    ranges=[3, 2708, 16],\n",
      "    origins={tangents_1, full, index_put}\n",
      "  ))\n",
      "))\n",
      "inductor code:\n",
      "\n",
      "from ctypes import c_void_p, c_long\n",
      "import torch\n",
      "import math\n",
      "import random\n",
      "from torch import empty_strided, as_strided, device\n",
      "from torch._inductor.codecache import AsyncCompile\n",
      "from torch._inductor.select_algorithm import extern_kernels\n",
      "\n",
      "aten = torch.ops.aten\n",
      "assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "async_compile = AsyncCompile()\n",
      "\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.triton_ops.autotune import grid\n",
      "from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "\n",
      "\n",
      "triton__0 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[131072], filename=__file__, meta={'signature': {0: '*fp32', 1: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': [], 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 129984\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x0 = xindex\n",
      "    tmp0 = 0.0\n",
      "    tl.store(out_ptr0 + (x0 + tl.zeros([XBLOCK], tl.int32)), tmp0, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "triton__1 = async_compile.triton('''\n",
      "import triton\n",
      "import triton.language as tl\n",
      "from torch._inductor.ir import ReductionHint\n",
      "from torch._inductor.ir import TileHint\n",
      "from torch._inductor.triton_ops.autotune import pointwise\n",
      "from torch._inductor.utils import instance_descriptor\n",
      "\n",
      "@pointwise(size_hints=[524288], filename=__file__, meta={'signature': {0: '*i64', 1: '*fp32', 2: '*fp32', 3: 'i32'}, 'device': 0, 'constants': {}, 'mutated_arg_names': ['out_ptr0'], 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=())]})\n",
      "@triton.jit\n",
      "def triton_(in_ptr0, in_ptr1, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "    xnumel = 506688\n",
      "    xoffset = tl.program_id(0) * XBLOCK\n",
      "    xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "    xmask = xindex < xnumel\n",
      "    x1 = (xindex // 16) % 10556\n",
      "    x3 = xindex\n",
      "    x0 = xindex % 16\n",
      "    x2 = (xindex // 168896)\n",
      "    tmp0 = tl.load(in_ptr0 + (x1), xmask)\n",
      "    tmp1 = tl.load(in_ptr1 + (x3), xmask)\n",
      "    tl.atomic_add(out_ptr0 + (x0 + (16*tmp0) + (43328*x2) + tl.zeros([XBLOCK], tl.int32)), tmp1, xmask)\n",
      "''')\n",
      "\n",
      "\n",
      "async_compile.wait(globals())\n",
      "del async_compile\n",
      "\n",
      "def call(args):\n",
      "    select, tangents_1 = args\n",
      "    args.clear()\n",
      "    with torch.cuda._DeviceGuard(0):\n",
      "        torch.cuda.set_device(0) # no-op to ensure context\n",
      "        buf0 = empty_strided((3, 2708, 16), (43328, 16, 1), device='cuda', dtype=torch.float32)\n",
      "        stream0 = get_cuda_stream(0)\n",
      "        triton__0.run(buf0, 129984, grid=grid(129984), stream=stream0)\n",
      "        triton__1.run(select, tangents_1, buf0, 506688, grid=grid(506688), stream=stream0)\n",
      "        del select\n",
      "        del tangents_1\n",
      "        return (None, buf0, )\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    from torch._dynamo.testing import rand_strided\n",
      "    from torch._inductor.utils import print_performance\n",
      "    select = rand_strided((10556, ), (1, ), device='cuda:0', dtype=torch.int64)\n",
      "    tangents_1 = rand_strided((3, 10556, 16), (168896, 16, 1), device='cuda:0', dtype=torch.float32)\n",
      "    print_performance(lambda: call([select, tangents_1]))\n",
      "\n",
      "inductor code end\n"
     ]
    }
   ],
   "source": [
    "_dynamo.reset()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9be45825b6e11033c42eb29377956e200d55264a3cce733a812afa9001a7e64f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
